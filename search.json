[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule Fall 2025",
    "section": "",
    "text": "Date\n#\nLecture\nTopic\n\n\n\n\n24/09/2025\n1\nNo Class\n\n\n\n01/10/2025  recorded\n2\nLecture 01\nIntroduction to Python\n\n\n\n\nLecture 02\nData types and structures\n\n\n08/10/2025  recorded\n3\nLecture 03\nControl structures\n\n\n\n\nLecture 04\nFunctions\n\n\n15/10/2025  recorded\n4\nLecture 05\nObject Oriented Programming\n\n\n\n\nLecture 06\nLibraries\n\n\n22/10/2025  recorded\n5\nLecture 07\nNumerical computing\n\n\n29/10/2025\n6\nNo class\n\n\n\n05/11/2025  recorded\n7\nLecture 08\nData manipulation\n\n\n\n\nLecture 09\nInput/output\n\n\n12/11/2025\n8\nLecture 10  [Guest Lecture]\nNetwork analytics\n\n\n19/11/2025\n9\nLecture 11\nTime series analysis\n\n\n26/11/2025\n10\nLecture 12\nMachine Learning\n\n\n03/12/2025\n11\nNo Class\n\n\n\n10/12/2025\n12\nLecture 13  [Guest Lecture]\nAdvanced Machine Learning\n\n\n17/12/2025\n13\nQ&A"
  },
  {
    "objectID": "lectures/lecture_03/lecture_03_problem_sets.html",
    "href": "lectures/lecture_03/lecture_03_problem_sets.html",
    "title": "Controle Structures - Problem Set",
    "section": "",
    "text": "Write a Python program that takes a user’s income and tax status as input. If the income is greater than $50,000, they should be taxed at 25%. Otherwise, they are taxed at 15%. Print the amount of tax they owe.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_03/lecture_03_problem_sets.html#more-exercises-on-list-comprehension",
    "href": "lectures/lecture_03/lecture_03_problem_sets.html#more-exercises-on-list-comprehension",
    "title": "Controle Structures - Problem Set",
    "section": "More exercises on list comprehension",
    "text": "More exercises on list comprehension\n\nExercise 1: Convert Temperatures\nGiven a list of temperatures in Celsius, use list comprehension to convert them to Fahrenheit. The formula for conversion is:\n\\[\n    F = \\frac{9}{5} \\times C + 32\n\\]\n\ncelsius = [0, 20, 37, 100]\n# Write the list comprehension to convert celsius to fahrenheit\n\n\n\nExercise 2: Filter and Square Odd Numbers\nGiven a list of numbers, use list comprehension to create a new list containing the squares of the odd numbers only.\n\nnumbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n# Write the list comprehension to filter and square odd numbers\n\n\n\nExercise 3: Extract Vowels from a String\nGiven a string, use list comprehension to create a list of all the vowels in the string.\n\ntext = \"List comprehensions are very powerful!\"\n# Write the list comprehension to extract vowels from the string\n\n\n\nExercise 4: Flatten a Nested List\nGiven a list of lists (nested list), use list comprehension to flatten it into a single list.\n\nnested_list = [[1, 2, 3], [4, 5], [6, 7, 8, 9]]\n# Write the list comprehension to flatten the nested list\n\n\n\nExercise 5: Dictionary from List\nYou have a list of tuples where the first element is a country and the second element is its population. Use list comprehension to convert the list of tuples into a dictionary.\n\ncountries = [(\"USA\", 331002651), (\"India\", 1380004385), (\"China\", 1439323776)]\n# Write the list comprehension to convert the list into a dictionary"
  },
  {
    "objectID": "lectures/lecture_04/lecture_04_problem_sets.html",
    "href": "lectures/lecture_04/lecture_04_problem_sets.html",
    "title": "Functions - Problem Set",
    "section": "",
    "text": "Exercise 1: Greeting Function\nWrite a function called greet_user(name) that takes a person’s name as a parameter and prints a greeting message.\n\n# Your code\n\n\n\nExercise 2: Sum of Two Numbers\nCreate a function called sum_two_numbers(a, b) that takes two numbers as arguments and returns their sum.\n\n# Your code\n\n\n\nExercise 3: Convert Celsius to Fahrenheit\nWrite a function celsius_to_fahrenheit(celsius) that takes a temperature in Celsius and returns the temperature in Fahrenheit. Use the formula:\n\\[\n    F = \\frac{9}{5} \\times C + 32\n\\]\n\n# Your code\n\n\n\nExercise 4: Calculate Area of Circle\nCreate a function called calculate_circle_area(radius) that takes the radius of a circle and returns the area of the circle using the formula:\n\\[\n    A = \\pi \\times r^2\n\\]\n\n# Your code\n\n\n\nExercise 5: Simple Interest\nWrite a function calculate_simple_interest(principal, rate, time) that calculates simple interest and returns it. The formula is:\n\\[\n    \\text{Interest} = \\frac{P \\times R \\times T}{100}\n\\]\n\n# Your code\n\n\n\nExercise 6: Compound Interest\nModify the function calculate_compound_interest(principal, rate, time) to return both the compound interest and the total amount (principal + interest).\n\n# Your code\n\n\n\nExercise 7: Maximum of Three Numbers\nCreate a function max_of_three(a, b, c) that takes three numbers as input and returns the largest of the three.\n\n# Your code\n\n\n\nExercise 8: Check Even or Odd with Lambda\nUse a lambda function to check whether a number is even or odd. Write a function is_even_or_odd(number) that returns “even” if the number is even and “odd” if the number is odd.\n\n# Your code\n\n\n\nExercise 9: Sum of Squares using map()\nUse map() and a lambda function to create a list of squares of numbers from 1 to 10.\n\n# Your code\n\n\n\nExercise 10: Filter Positive Numbers\nWrite a function filter_positive(numbers) that takes a list of numbers and uses the filter() function to return a list of only positive numbers.\n\n# Your code\n\n\n\nAdvanced Exercise 1: Recursive Factorial Function\nWrite a recursive function factorial(n) that takes a number n and returns the factorial of n.\n\n# Your code\n\n\n\nAdvanced Exercise 2: Higher-Order Function for Applying Functions\nCreate a higher-order function apply_function(func, x) that takes a function and a value x, and applies the function to x twice.\n\n# Your code\n\n\n\nAdvanced Exercise 3: Net Present Value (NPV) with Lambda\nWrite a function calculate_npv(cash_flows, rate) that calculates the Net Present Value (NPV) of cash flows using a lambda function inside a list comprehension. Assume cash_flows is a list and rate is a constant discount rate.\n\n# Your code\n\n\n\nAdvanced Exercise 4: Zip and Sort\nWrite a function zip_and_sort(names, scores) that takes two lists: names (list of students’ names) and scores (list of their scores). Use zip() to combine the two lists into tuples, then return the list of students sorted by their scores in descending order.\n\n# Your code\n\n\n\nAdvanced Exercise 5: Reduce for Cumulative Product\nUse the reduce() function to write a function cumulative_product(numbers) that takes a list of numbers and returns their cumulative product.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_04/lecture_04.html",
    "href": "lectures/lecture_04/lecture_04.html",
    "title": "Lecture 04 - Functions",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_04/lecture_04.html#lecture-material",
    "href": "lectures/lecture_04/lecture_04.html#lecture-material",
    "title": "Lecture 04 - Functions",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_04/lecture_04.html#recording",
    "href": "lectures/lecture_04/lecture_04.html#recording",
    "title": "Lecture 04 - Functions",
    "section": "Recording",
    "text": "Recording\n\n1. Intro\n\n \n\n\n\n2. Basics\n\n \n\n\n\n3. Functional Programming"
  },
  {
    "objectID": "lectures/lecture_04/lecture_04.html#problem-sets",
    "href": "lectures/lecture_04/lecture_04.html#problem-sets",
    "title": "Lecture 04 - Functions",
    "section": "Problem sets",
    "text": "Problem sets\n\nJupyter notebook (.ipynb)\nSolutions (.pdf)"
  },
  {
    "objectID": "lectures/lecture_05/oop.html",
    "href": "lectures/lecture_05/oop.html",
    "title": "Lecture 05 - Object-Oriented Programming",
    "section": "",
    "text": "Object-Oriented Programming (OOP) is a programming paradigm based on the concept of class and objects which can contain\n\nData (attributes)\nCode (methods)\n\nWhy does OOP matter?\nOOP allows for organizing complex programs into manageable, modular components, making the code more: - Reusable: Once a class is created, it can be used across different parts of the program without rewriting. - Scalable: Capacity to build on existing structures without rewriting them. - Maintainable: Since the code is organized into discrete components, fixing bugs and adding new features is straightforward.\nThis notebook covers: - The basics of OOP: classes and objects - Defining classes and creating objects - Attributes and methods - Inheritance and polymorphism"
  },
  {
    "objectID": "lectures/lecture_05/oop.html#overview",
    "href": "lectures/lecture_05/oop.html#overview",
    "title": "Lecture 05 - Object-Oriented Programming",
    "section": "",
    "text": "Object-Oriented Programming (OOP) is a programming paradigm based on the concept of class and objects which can contain\n\nData (attributes)\nCode (methods)\n\nWhy does OOP matter?\nOOP allows for organizing complex programs into manageable, modular components, making the code more: - Reusable: Once a class is created, it can be used across different parts of the program without rewriting. - Scalable: Capacity to build on existing structures without rewriting them. - Maintainable: Since the code is organized into discrete components, fixing bugs and adding new features is straightforward.\nThis notebook covers: - The basics of OOP: classes and objects - Defining classes and creating objects - Attributes and methods - Inheritance and polymorphism"
  },
  {
    "objectID": "lectures/lecture_05/oop.html#the-basics-of-oop-classes-and-objects",
    "href": "lectures/lecture_05/oop.html#the-basics-of-oop-classes-and-objects",
    "title": "Lecture 05 - Object-Oriented Programming",
    "section": "1. The Basics of OOP: Classes and Objects",
    "text": "1. The Basics of OOP: Classes and Objects\n\n1.1 Definitions\nWhat is a Class?\nA class is like a blueprint or template for creating objects.\nIt defines the attributes (variables) and methods (functions) that objects created from the class will have.\nWhat is an Object?\nAn object is an instance of a class. It has its own specific values for the attributes defined by the class.\nWhy use Classes and Objects?\nClasses are like cookie cutters and objects are the actual cookies.\nThe class defines the shape and structure, while each object is an independent instance that can have different values but shares the same structure.\n\n\n1.2 Syntax\n\nGeneral\nIn general, a class is alway defined by a constructor and a set of methods and attributes.\n    class NAME:\n        CONSTRUCTOR\n        OTHER METHODS\n        ATTRIBUTES\n\nThe Constructor sets up initial values for attributes when an object is created. This ensures that each object starts in a well-defined state.\nThe Methods are callable functions within and outside the class object\nThe Attributes are callable variables withing and outside the class object\n\n\n\nIn Python\n    class NAME:\n        def __init__(self, ...):\n            ACTIONS\n            \n        def METHODS (self,...):\n            ACTIONS\n        \n        self.ATTRIBUTES\n\nConstructor is defined by the function init() where self is a reference to the class object itself.\nMethods are defined like standard functions.\n\nReference to attributes that belong to the current class object in the constructor and methods are specified using the prefix self.\n\n\n\n\n\n1.3 Example\nConsider a simple example of a bank account. Each bank account will have: 1. An account holder. 2. A balance that tracks the amount of money in the account.\n\nclass BankAccount:\n    # constructor\n    def __init__(self, account_holder, balance=0):\n        self.account_holder = account_holder  # Assigning account holder name\n        self.balance = balance  # Setting initial balance (default is 0)\n\n\n# Creating an instance of BankAccount\naccount1 = BankAccount(\"John Doe\", 500)\n\n\n# Accessing attributes of the object\nprint(f\"Account Holder: {account1.account_holder}\")  # Output: John Doe\nprint(f\"Balance: {account1.balance}\")  # Output: 500\n\n\n\nStep-by-step Explanation:\n\nClass Definition: We define the BankAccount class.\nConstructor (__init__ method): This method initializes the attributes account_holder and balance when a new BankAccount object is created.\nCreating an Object: We create an object account1 of the BankAccount class.\nAccessing Object Attributes: We print the values of the object’s attributes using the dot notation (e.g., account1.balance)."
  },
  {
    "objectID": "lectures/lecture_05/oop.html#attributes-and-methods",
    "href": "lectures/lecture_05/oop.html#attributes-and-methods",
    "title": "Lecture 05 - Object-Oriented Programming",
    "section": "2. Attributes and Methods",
    "text": "2. Attributes and Methods\n\n2.1 Attributes\nAttributes are variables that hold data specific to an object.\nThey are defined within a class and belong to each instance of that class.\nWhy are attributes important?\nAttributes store the state of the object.\nIn the bank account example, the balance attribute holds the current state of the account.\n\n\n2.2 Methods\nMethods are functions defined inside a class that operate on objects of that class.\nMethods can read or modify the object’s attributes.\nWhy use Methods?\nMethods define behaviors specific to the class.\n\n\n2.3 Example\nLet’s add some functionality to our BankAccount class.\nWe want to be able to:\n\nDeposit money into the account.\nWithdraw money from the account.\n\n\nclass BankAccount:\n    # Constructor\n    def __init__(self, account_holder, balance=0):\n        self.account_holder = account_holder\n        self.balance = balance\n\n    # Method for depositing money\n    def deposit(self, amount):\n        self.balance += amount\n        print(f\"Deposited {amount}. New balance is {self.balance}\")\n\n    # Method for withdrawing money\n    def withdraw(self, amount):\n        if amount &gt; self.balance:\n            print(\"Insufficient funds.\")\n        else:\n            self.balance -= amount\n            print(f\"Withdrew {amount}. New balance is {self.balance}\")\n\n\n# Creating a new BankAccount object\naccount2 = BankAccount(\"Jane Doe\", 1000)\naccount2.deposit(200)  # Depositing 200\naccount2.withdraw(300)  # Withdrawing 300\n\n\n\n2.4 Additional examples\nDefine a Student class with the following attributes: - name - student_id - grade\nAdd methods to: 1. Update the grade. 2. Print a summary of the student’s information.\n\n# Defining the Student class\nclass Student:\n    # Constructor to initialize the attributes of the class\n    def __init__(self, name, student_id, grade):\n        self.name = name            # Student's name\n        self.student_id = student_id  # Unique student ID\n        self.grade = grade          # Current grade of the student\n\n    # Method to update the student's grade\n    def update_grade(self, new_grade):\n        self.grade = new_grade\n        print(f\"Grade updated to: {self.grade}\")\n\n    # Method to print a summary of the student's information\n    def print_summary(self):\n        print(f\"Student Name: {self.name}\")\n        print(f\"Student ID: {self.student_id}\")\n        print(f\"Current Grade: {self.grade}\")\n\n\n# Creating an instance of the Student class\nstudent1 = Student(\"Alice\", 12345, \"80\")\n\n\n# Calling the methods to test the functionality\nstudent1.print_summary()  # Printing the initial student details\n\n\n# Updating the grade and printing the updated details\nstudent1.update_grade(\"90\")\nstudent1.print_summary()  # Should show the updated grade\n\nAdditional methods to implement - has_failed() - can_retake() – cannot fail more than twice\n\n# Your code\n\nGlobal exercise\nFrom a list of objects Student, order students from highest to lowest grade\n\n# Creating a list of multiple Student objects with varying grades\nstudents = [\n    Student(\"Alice\", 12345, \"80\"),\n    Student(\"Bob\", 67890, \"40\"),\n    Student(\"Charlie\", 54321, \"60\"),\n    Student(\"David\", 98765, \"99\"),\n    Student(\"Eve\", 45678, \"21\")\n]\n\n# Function to sort the list of students by their grades\ndef sort_students_by_grade(student_list):\n    # Sort by grade in ascending order (A &gt; B &gt; C)\n    sorted_students = sorted(student_list, key=lambda student: student.grade)\n    return sorted_students\n\n# Sorting the students and printing the result\nsorted_students = sort_students_by_grade(students)\n\n# Displaying the sorted list of students\nprint(\"Students sorted by grades:\")\nfor student in sorted_students:\n    student.print_summary()"
  },
  {
    "objectID": "lectures/lecture_05/oop.html#inheritance",
    "href": "lectures/lecture_05/oop.html#inheritance",
    "title": "Lecture 05 - Object-Oriented Programming",
    "section": "3. Inheritance",
    "text": "3. Inheritance\nInheritance is a fundamental concept in object-oriented programming that allows a new class to inherit attributes and methods from an existing class.\nThis existing class is known as the parent class (or base class), while the new class is referred to as the child class (or derived class).\nWhy use inheritance?\n\nCode Reusability: Inheritance helps reduce code duplication by allowing new classes to use the features of existing classes.\nLogical Hierarchies: Model real-world relationships, such as “A Car is-a Vehicle.”\nExtendability: Add new features to the child class without modifying the parent class, making it easier to maintain the code.\n\nHow it works\nWhen creating a child class, the class automatically inherits all the attributes and methods of the parent class.\nHowever, the functionality of the parent class can also be extended or overridden within the child class.\n\n3.1 Syntax\n    class CHILD (PARENT):\n        def __init__(self,...):\n            super().__init__(...):\n            self....\n\n\n3.2 Step-by-step example\nStep 1: Create a parent class\nStart with a Person class that has basic attributes like name and age, and a method to print a summary.\n\nclass Person:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def display(self):\n        print(f\"Name: {self.name}, Age: {self.age}\")\n\n\nThe Person class has two attributes: name and age.\nIt includes a method display() that prints the name and age.\n\nStep 2: Create a child class that inherits from Person\nNow let’s create a Student class that inherits from the Person class.\nThe Student class will have an additional attribute grade and its own method to print details specific to students.\n\nclass Student(Person):\n    def __init__(self, name, age, grade):\n        # Call the constructor of the parent class\n        super().__init__(name, age)  \n        self.grade = grade  # New attribute specific to Student\n\n    def display_student(self):\n        print(f\"Student Name: {self.name}, Age: {self.age}, Grade: {self.grade}\")\n\n\nThe Student class inherits from the Person class using class Student(Person):.\nThe Student class has its own constructor (__init__) that calls the constructor of the parent class using super().__init__(name, age).\n\nThis is necessary to properly initialize attributes from the parent class.\n\nThe Student class has a new attribute grade and a new method display_student().\n\nStep 3: Creating objects and using inheritance\nNow that we have both classes, let’s create a Student object and use the inherited and new methods.\n\n# Creating an instance of the Student class\nstudent1 = Student(\"Alice\", 20, \"A\")\n\n# Calling methods\nstudent1.display()  # Inherited method from Person class\nstudent1.display_student()  # Method specific to Student class\n\n\nThe student1.display() call demonstrates inherited behavior:\n\ndisplay() is defined in Person, but student1 (an instance of Student) can use it because Student inherits from Person.\n\nThe student1.display_student() call demonstrates extended behavior:\n\ndisplay_student() is defined only in the Student class.\n\n\n\n\n3.3 Other Example\nLet’s create a new class called SavingsAccount that inherits from BankAccount.\nA savings account might have an interest rate and a method to apply interest.\n\n# Inheriting from BankAccount class\nclass SavingsAccount(BankAccount):\n    def __init__(self, account_holder, balance=0, interest_rate=0.02):\n        # Call the parent class constructor\n        super().__init__(account_holder, balance)\n        self.interest_rate = interest_rate  # Additional attribute for interest rate\n\n    # New method to apply interest\n    def apply_interest(self):\n        interest = self.balance * self.interest_rate\n        self.deposit(interest)  # Use deposit method to add interest\n        print(f\"Interest applied. New balance: {self.balance}\")\n\n\n# Creating a SavingsAccount object\nsavings = SavingsAccount(\"Alice\", 2000)\nsavings.apply_interest()"
  },
  {
    "objectID": "lectures/lecture_05/oop.html#method-overriding-and-polymorphism",
    "href": "lectures/lecture_05/oop.html#method-overriding-and-polymorphism",
    "title": "Lecture 05 - Object-Oriented Programming",
    "section": "4. Method Overriding and Polymorphism",
    "text": "4. Method Overriding and Polymorphism\n\n4.1 Method Overriding\nMethod overriding occurs when a child class provides a specific implementation for a method that is already defined in its parent class.\nThis allows the child class to define its own behavior for the inherited method.\n\nPurpose: To customize or extend the behavior of a method in the child class.\nSyntax: A method in the child class has the same name, parameters, and return type as a method in the parent class.\n\n\n# Parent class\nclass Vehicle:\n    def move(self):\n        print(\"The vehicle is moving\")\n\n# Child class overriding the move method\nclass Car(Vehicle):\n    def move(self):\n        print(\"The car is driving on the road\")\n\n# Creating instances\nv = Vehicle()\nc = Car()\n\n# Calling the move method\nv.move()  \nc.move()  \n\n\nExample\nLet’s override the display() method in the Student class to show the grade as well:\n\nclass Student(Person):\n    def __init__(self, name, age, grade):\n        super().__init__(name, age)\n        self.grade = grade\n\n    # Overriding the display method from Person class\n    def display(self):\n        print(f\"Name: {self.name}, Age: {self.age}, Grade: {self.grade}\")\n\n\nstudent1 = Student(\"Bob\", 21, \"B\")\nstudent1.display()  \n\n\n\nOther Example:\nLet’s override the withdraw() method from BankAccount to SavingsAccount.\nIf a SavingsAccount has different withdrawal rules (e.g., no withdrawals below a minimum balance), we can override the withdraw method.\n\nclass SavingsAccount(BankAccount):\n    def __init__(self, account_holder, balance=0, interest_rate=0.02):\n        super().__init__(account_holder, balance)\n        self.interest_rate = interest_rate\n\n    def withdraw(self, amount):\n        if self.balance - amount &lt; 500:  # Minimum balance of 500\n            print(\"Withdrawal denied: Balance cannot go below 500.\")\n        else:\n            super().withdraw(amount)  # Call the parent class method\n\n\n\n\n4.2 Polymorphism\nPolymorphism means “many forms” and refers to the ability of different classes to respond to the same method call in different ways.\nIt allows the same method name to be used for different types of objects.\nPurpose: To enable objects of different classes to be treated as objects of a common parent class.\n\n# Parent class\nclass Animal:\n    def sound(self):\n        raise NotImplementedError(\"Subclasses must implement this method\")\n\n# Child classes\nclass Dog(Animal):\n    def sound(self):\n        return \"Bark\"\n\nclass Cat(Animal):\n    def sound(self):\n        return \"Meow\"\n\n# Polymorphism: List of different objects\nanimals = [Dog(), Cat()]\n\n# Using polymorphism to call the same method\nfor animal in animals:\n    print(animal.sound())  # Output: Bark, Meow\n\nIn the above example: 1. Both Dog and Cat classes override the sound() method of the Animal parent class. 2. When we call sound() on each object, polymorphism ensures that the correct implementation is executed based on the type of the object (Dog or Cat).\n\n\n4.3 Take-away\n\nMethod overriding is a technique that allows polymorphism to occur.\n\nWhen a child class overrides a method, it enables polymorphism because objects of different classes can respond to the same method call in their own unique way.\n\nPolymorphism is a broader concept that encompasses method overriding as a way to implement it.\n\nVisual Analogy:\n\nMethod Overriding ~ customizing a basic recipe.\n\nIf the parent class provides a recipe for a “generic cake,” the child class can override this recipe to make a “chocolate cake.”\n\nPolymorphism ~ ability to treat both the “generic cake” and “chocolate cake” as simply “cakes” when needed.\n\nCall bake() on both and get the right result, even if the recipes are different."
  },
  {
    "objectID": "lectures/lecture_02/lecture_02_problem_sets.html",
    "href": "lectures/lecture_02/lecture_02_problem_sets.html",
    "title": "Data Types and Structures - Problem sets",
    "section": "",
    "text": "Exercise 1: Check Data Types\nWrite a Python program that prints the data types of the following variables:\na = 42\nb = 3.14\nc = \"Python\"\nd = [1, 2, 3]\ne = (1, 2, 3)\nf = {'name': 'John', 'age': 30}\ng = {1, 2, 3}\n\n# Your code\n\n\n\nExercise 2: List Operations\nCreate a list with the elements [10, 20, 30, 40, 50]. Add 60 to the list, remove 30, and reverse the list.\n\n# Your code\n\n\n\nExercise 3: Tuple Unpacking\nGiven the following tuple, unpack its elements into separate variables and print them:\nmy_tuple = (100, 200, 300)\n\n# Your code\n\n\n\nExercise 4: Dictionary Manipulation\nCreate a dictionary with keys 'name', 'age', and 'city', and values 'Alice', 25, and 'New York'. Update the age to 26 and add a new key 'profession' with value 'Engineer'.\n\n# Your code\n\n\n\nExercise 5: Set Operations\nCreate two sets, set1 with elements {1, 2, 3, 4} and set2 with elements {3, 4, 5, 6}. Find the union, intersection, and difference between these sets.\n\n# Your code\n\n\n\nExercise 6: String Slicing\nGiven the string s = \"Hello, Python!\", write code to: 1. Extract the substring \"Python\". 2. Reverse the entire string.\n\n# Your code\n\n\n\nExercise 7: Boolean Logic\nYou are given three numbers, a, b, and c. Write a Python program that returns True if a is the largest number and b is not equal to c. Otherwise, return False.\n\n# Input numbers\na = 10\nb = 5\nc = 5\n\n# Your code\n\n\n\nExercise 8: Complex Boolean Logic with Multiple Conditions\nWrite a Python program that checks the following conditions for three variables x, y, and z:\n\nx is greater than y or y is equal to z.\nThe sum of x and y is even.\nx, y, and z are all positive numbers.\n\nThe program should return True only if all three conditions are met.\n\n# Input variables\nx = 8\ny = 6\nz = 6\n\n# Your code\n\n\n\nExercise 9: Checking for Keys in a Dictionary\nGiven the dictionary person = {'name': 'Bob', 'age': 25}, check if the key 'age' exists in the dictionary and print a message.\n\n# Your code\n\n\n\nExercise 10: Nested Data Structures\nCreate a dictionary students where each key is a student’s name and each value is a dictionary containing their 'age' and a list of their 'grades'.\nEnter the following data in the dictionary: - Alice is 24 and has grades 88, 92 and 86 - Bob is 23 and had grades 75, 80, 89\nPrint Bob’s age and Alice’s grades.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_02/data_types_and_structure.html",
    "href": "lectures/lecture_02/data_types_and_structure.html",
    "title": "Lecture 02 - Data Types and Structures",
    "section": "",
    "text": "In Python, types and structures are fundamental concepts that allow the storage, manipulation, and organization of data.\nThis notebook covers:\n\nBasic data types: int, float, bool, str\nData structures: tuple, list, set, dict\nOperations and built-in methods"
  },
  {
    "objectID": "lectures/lecture_02/data_types_and_structure.html#overview",
    "href": "lectures/lecture_02/data_types_and_structure.html#overview",
    "title": "Lecture 02 - Data Types and Structures",
    "section": "",
    "text": "In Python, types and structures are fundamental concepts that allow the storage, manipulation, and organization of data.\nThis notebook covers:\n\nBasic data types: int, float, bool, str\nData structures: tuple, list, set, dict\nOperations and built-in methods"
  },
  {
    "objectID": "lectures/lecture_02/data_types_and_structure.html#basic-types",
    "href": "lectures/lecture_02/data_types_and_structure.html#basic-types",
    "title": "Lecture 02 - Data Types and Structures",
    "section": "1. Basic Types",
    "text": "1. Basic Types\nList of types\n\n\n\nObject type\nMeaning\nUsed for\n\n\n\n\nint\ninteger value\nnatural numbers\n\n\nfloat\nfloating-point number\nreal numbers\n\n\nbool\nboolean value\ntrue or false\n\n\nstr\nstring object\ncharacter, word, text\n\n\n\nuse built-in function type() to obtain the information\n\n1.1 Integers and Floats\nIntegers are whole numbers, while floats are numbers with decimal values.\n\nInt\n\na = 10\ntype(a)\n\nArithmetic operations: + - * /\n\n1 + 4 \n\n\na + 1\n\n\ntype(1+4)\n\n\n\nFloats\n\ntype (1/4)\n\n\n1/4\n\n\ntype(0.25)\n\n\ntype (0)\n\n\ntype (0.0)\n\n\n# Example: Representing account balances\nbalance = 1000  # Integer\ninterest_rate = 5.5  # Float\n\n\n# Calculating interest\ninterest = balance * interest_rate / 100\nprint(\"Interest:\", interest)\n\n\n\n\n1.2 Booleans\nBooleans represent True or False values.\n\n# Example: Checking if an account is active\naccount_active = True\nif account_active == True:\n    print(\"The account is active.\")\nelse:\n    print(\"The account is inactive.\")\n\n\n# implicit comparison\nif account_active:\n    print(\"The account is active.\")\nelse:\n    print(\"The account is inactive.\")\n\n\nConditions: &gt; &lt; &gt;= &lt;= == !=\n\n4 &gt; 3\n\n\ntype (4 &gt; 3)\n\n\ntype (False)\n\n\n4 &gt;= 3\n\n\n4 &lt; 3\n\n\n4 == 3\n\n\n4 != 3\n\n\n\nLogic operations: and or not in\n\nTrue and True\n\n\nFalse and False\n\n\nTrue or True\n\n\nTrue or False\n\n\nFalse or False\n\n\nnot True\n\n\nnot False\n\n\n\nCombinations\n\n(4 &gt; 3) and (2 &gt; 3)\n\n\n(4==3) or (2 != 3)\n\n\nnot (4 != 4)\n\n\n(not (4 != 4)) and (2 == 3)\n\nNote: Major for control condition (if while for) – see later\n\nif 4 &gt; 3:\n    print ('condition true')\nelse:\n    print ('condition not true')\n\n\ni = 0\nwhile i &lt; 4:\n    print ('condition true: i = ', i)\n    i = i + 1\n\n\n\nBoolean casting: 0,1 (and other values)\n\nint(True)\n\n\nint(False)\n\n\nfloat(True)\n\n\nfloat(False)\n\n\nbool(0)\n\n\nbool(1)\n\n\nbool(0.0)\n\n\nbool(1.0)\n\n\nbool(10.5)\n\n\nbool(-2)\n\n\n\n\n1.3 Strings\nStrings are used to represent text.\n\n# Example: Representing account holder information\naccount_holder = \"John Doe\"\naccount_number = \"1234567890\"\n\nprint(\"Account Holder:\", account_holder)\nprint(\"Account Number:\", account_number)\n\n\ntype(account_holder)\n\n\nBuilt-in methods\nstr variables come with a series of useful built-in methods.\n\n\n\nMethod\n\n\n\n\ncapitalize()\n\n\ncount()\n\n\nfind()\n\n\njoin()\n\n\nreplace()\n\n\nsplit()\n\n\nupper()\n\n\n\n\nt = 'this is a string object'\n\n\nt.capitalize()\n\n\nt.split('i')\n\n\nt.find('string')\n\n\nt.replace(' ','|')\n\n\n\nPrint method print()\n\nprint('Hello World!')\n\n\nprint (t)\n\n\ni = 0\nwhile i &lt; 4:\n    print (i)\n    i = i + 1\n\n\ni = 0\nwhile i &lt; 4:\n    print (i, end = '|')\n    i = i + 1\n\n\n\nPrinting with variables\n\na = 10\nprint('this is the value of a:', a)\n\n\ntt = 'this is the value of a: ' + str(a)\nprint (tt)"
  },
  {
    "objectID": "lectures/lecture_02/data_types_and_structure.html#basic-structures",
    "href": "lectures/lecture_02/data_types_and_structure.html#basic-structures",
    "title": "Lecture 02 - Data Types and Structures",
    "section": "2. Basic structures",
    "text": "2. Basic structures\nList of structures\n\n\n\nObject type\nMeaning\nUsed for\n\n\n\n\ntuple\nimmutable container\nfixed set of objects\n\n\nlist\nmutable container\nordered and changing set of objects\n\n\ndict\nmutable container\nkey-value store\n\n\nset\nmutable container\nunordered collection of unique objects\n\n\n\nuse built-in function type() to obtain the information\nNavigating structures\n\nIndexing: obtain item at position n s[n]\nSlicing: obtain items between position i and j s[i:j] s[i:] s[:j]\nRanging: obtain items between position i and j spaced by k s[i:j:k]\n\nNote: In Python, indexing starts at 0\n\n2.1 tuple\nTuples are immutable collections of items (i.e., cannot be changed after creation).\n\n# Example: Coordinates of a bank branch\nbranch_location = (40.7128, -74.0060)  # New York City coordinates\nprint(\"Branch Location:\", branch_location)\n\n\nt = (1, 2.5, 'data')\ntype(t)\n\n\n#also works without ()\nt = 1, 2.5, 'data'\ntype(t)\n\n\n#indexing\nt[2]\n\n\ntype(t[2])\n\n\n\n2.2 list\nLists are ordered collections of items, which can be of mixed data types.\n\n# Example: List of recent transactions\ntransactions = [100, -50, 200, -30, 400]\nprint(\"Transactions:\", transactions)\n\n# Adding a new transaction\ntransactions.append(-100)\nprint(\"Updated Transactions:\", transactions)\n\n\nl = [1, 2.5, 'data']\nl[2]\n\n\n#casting\nl = list(t)\nl\n\n\ntype (l)\n\n\nBuilt-in methods\n\n\n\nMethod\n\n\n\n\nl[i] = x\n\n\nl[i:j:k] = s\n\n\nappend()\n\n\ncount()\n\n\ndel l[i:j:k]\n\n\nindex()\n\n\nextend()\n\n\ninsert()\n\n\nremove()\n\n\npop()\n\n\nrevers()\n\n\nsort()\n\n\n\ncontrary to tuples, lists are mutable containers\n\nl.append([4,3])\nl\n\n\nl.extend([1.0, 1.5, 2.0])\nl\n\n\nl = [0, 1, 2, 3, 4, 5, 6, 7]\ns = [10, 20, 30]\n\nl[1:7:2] = s\nprint(l)\n\n\nl.insert(1,'insert')\nl\n\n\nl.remove('data')\nl\n\n\np = l.pop(3)\nprint (l, p)\n\n\n#slicing\nl[2:5]\n\nMutable vs immutable objects\n\nt = (1, [2, 3], 4)\n\n\nt[1].append(5)    \n\n\nprint(t)          \n\n\nt[0] = 9\n\n\n\n\n2.3 dict\nDictionaries store data as key-value pairs.\n\n# Example: Dictionary of account balances\naccount_balances = {\n    \"1234567890\": 1000,\n    \"0987654321\": 2500,\n    \"1122334455\": 750\n}\nprint(\"Account Balances:\", account_balances)\n\n# Accessing a balance by account number\nprint(\"Balance of account 1234567890:\", account_balances[\"1234567890\"])\n\n\nKeys and values\n\nd = {\n    'Name' : 'Iron Man',\n    'Country' : 'USA',\n    'Profession' : 'Super Hero',\n    'Age' : 36\n}\n\n\ntype(d)\n\n\nprint (d['Name'], d['Age'])\n\n\n\nBuilt-in methods\n\n\n\nMethod\n\n\n\n\nd[k]\n\n\nd[k] = x\n\n\ndel d[k]\n\n\nclear()\n\n\ncopy()\n\n\nitems()\n\n\nkeys()\n\n\nvalues()\n\n\npopitem()\n\n\nupdate()\n\n\n\n\nd.keys()\n\n\nd.values()\n\n\nd.items()\n\n\nbirthday = True\nif birthday:\n    d['Age'] += 1\nprint (d['Age'])\n\n\nfor item in d.items():\n    print (item)\n\n\nfor value in d.values():\n    print (type(value))\n\n\n\n\n2.4 set\nSets are unordered collections of unique items.\n\ns = set(['u', 'd', 'ud', 'du', 'd', 'du'])\ns\n\n\nSet operations\n\nt = set(['d', 'dd', 'uu', 'u'])\n\n\ns.union(t)\n\n\ns.intersection(t)\n\n\ns.difference(t)\n\n\nt.difference(s)\n\n\ns.symmetric_difference(t)"
  },
  {
    "objectID": "lectures/lecture_11/time_series.html",
    "href": "lectures/lecture_11/time_series.html",
    "title": "Lecture 11 - Time Series Analysis",
    "section": "",
    "text": "Time series analysis is crucial for financial data, as stock prices, economic indicators, and sales forecasts are often dependent on time.\nWhat is Time Series Data?\n\nA time series is a sequence of data points recorded at successive and equally spaced points in time.\n\nExamples in Finance: Stock prices, interest rates, GDP growth, and exchange rates.\n\n\nComponents of Time Series Data - Trend: Long-term increase or decrease in the data. - Seasonality: Repeating patterns or cycles (e.g., sales increasing during the holiday season). - Noise/Residual: Random fluctuations that are not explained by the model.\nThis notebook covers:\n\nThe basics of time series data and its components.\nHow to manipulate and visualize time series data with pandas and matplotlib.\nApply basic time series models such as moving averages and correlations.\n\n\n\n\nimport numpy as np \nimport pandas as pd\nfrom pylab import mpl, plt \nplt.style.use('seaborn-v0_8-dark') \nmpl.rcParams['font.family'] = 'serif' \n%matplotlib inline"
  },
  {
    "objectID": "lectures/lecture_11/time_series.html#overview",
    "href": "lectures/lecture_11/time_series.html#overview",
    "title": "Lecture 11 - Time Series Analysis",
    "section": "",
    "text": "Time series analysis is crucial for financial data, as stock prices, economic indicators, and sales forecasts are often dependent on time.\nWhat is Time Series Data?\n\nA time series is a sequence of data points recorded at successive and equally spaced points in time.\n\nExamples in Finance: Stock prices, interest rates, GDP growth, and exchange rates.\n\n\nComponents of Time Series Data - Trend: Long-term increase or decrease in the data. - Seasonality: Repeating patterns or cycles (e.g., sales increasing during the holiday season). - Noise/Residual: Random fluctuations that are not explained by the model.\nThis notebook covers:\n\nThe basics of time series data and its components.\nHow to manipulate and visualize time series data with pandas and matplotlib.\nApply basic time series models such as moving averages and correlations.\n\n\n\n\nimport numpy as np \nimport pandas as pd\nfrom pylab import mpl, plt \nplt.style.use('seaborn-v0_8-dark') \nmpl.rcParams['font.family'] = 'serif' \n%matplotlib inline"
  },
  {
    "objectID": "lectures/lecture_11/time_series.html#data-inspection",
    "href": "lectures/lecture_11/time_series.html#data-inspection",
    "title": "Lecture 11 - Time Series Analysis",
    "section": "2. Data inspection",
    "text": "2. Data inspection\nThe first part of the analysis is to inspect the data set containing the timeseries.\nInspection steps: 1. Import data 2. Generate summary statistics 3. Analysis changes over time 4. Adjust frequency (resampling)\n\n2.1 Data import\nFor this part, we work with a standard csv database obtained from the Thomson Reuters Eikon Data. The data contains end-of-day (EOD) price data for a selection of instruments.\nThe following parameters apply:\n    file_path = 'Data/11/'\n    file_name = 'tr_eikon_eod_data.csv'\n\nCheck file\n\n# Data from the Thomson Reuters (TR) Eikon Data API\nfile_path = 'Data/11/'\nfile_name = 'tr_eikon_eod_data.csv'\nfile = open(file_path + file_name, 'r')\n\n\nfile.readlines()[:5]\n\n['Date,AAPL.O,MSFT.O,INTC.O,AMZN.O,GS.N,SPY,.SPX,.VIX,EUR=,XAU=,GDX,GLD\\n',\n '2010-01-04,30.57282657,30.95,20.88,133.9,173.08,113.33,1132.99,20.04,1.4411,1120.0,47.71,109.8\\n',\n '2010-01-05,30.625683660000004,30.96,20.87,134.69,176.14,113.63,1136.52,19.35,1.4368,1118.65,48.17,109.7\\n',\n '2010-01-06,30.138541290000003,30.77,20.8,132.25,174.26,113.71,1137.14,19.16,1.4412,1138.5,49.34,111.51\\n',\n '2010-01-07,30.082827060000003,30.452,20.6,130.0,177.67,114.19,1141.69,19.06,1.4318,1131.9,49.1,110.82\\n']\n\n\n\nfile.close()\n\n\n\nImport into dataframe\n\n# index_col = 0: the first column shall be handled as an index.\n# parse_dates = True: the index values are of type datetime.\ndata = pd.read_csv(file_path + file_name, index_col = 0, parse_dates = True)\n\n\nUse time as label on index_col\nExplicitly interpret as datetime object on parse_dates\n\nfrom documentation: If True -&gt; try parsing the index.\n\n\n\n\nInspect dataframe\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 1972 entries, 2010-01-04 to 2017-10-31\nData columns (total 12 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   AAPL.O  1972 non-null   float64\n 1   MSFT.O  1972 non-null   float64\n 2   INTC.O  1972 non-null   float64\n 3   AMZN.O  1972 non-null   float64\n 4   GS.N    1972 non-null   float64\n 5   SPY     1972 non-null   float64\n 6   .SPX    1972 non-null   float64\n 7   .VIX    1972 non-null   float64\n 8   EUR=    1972 non-null   float64\n 9   XAU=    1972 non-null   float64\n 10  GDX     1972 non-null   float64\n 11  GLD     1972 non-null   float64\ndtypes: float64(12)\nmemory usage: 200.3 KB\n\n\n\ndata.head()\n\n\n\n\n\n\n\n\nAAPL.O\nMSFT.O\nINTC.O\nAMZN.O\nGS.N\nSPY\n.SPX\n.VIX\nEUR=\nXAU=\nGDX\nGLD\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2010-01-04\n30.572827\n30.950\n20.88\n133.90\n173.08\n113.33\n1132.99\n20.04\n1.4411\n1120.00\n47.71\n109.80\n\n\n2010-01-05\n30.625684\n30.960\n20.87\n134.69\n176.14\n113.63\n1136.52\n19.35\n1.4368\n1118.65\n48.17\n109.70\n\n\n2010-01-06\n30.138541\n30.770\n20.80\n132.25\n174.26\n113.71\n1137.14\n19.16\n1.4412\n1138.50\n49.34\n111.51\n\n\n2010-01-07\n30.082827\n30.452\n20.60\n130.00\n177.67\n114.19\n1141.69\n19.06\n1.4318\n1131.90\n49.10\n110.82\n\n\n2010-01-08\n30.282827\n30.660\n20.83\n133.52\n174.31\n114.57\n1144.98\n18.13\n1.4412\n1136.10\n49.84\n111.37\n\n\n\n\n\n\n\n\ndata.tail()\n\n\n\n\n\n\n\n\nAAPL.O\nMSFT.O\nINTC.O\nAMZN.O\nGS.N\nSPY\n.SPX\n.VIX\nEUR=\nXAU=\nGDX\nGLD\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2017-10-25\n156.41\n78.63\n40.78\n972.91\n241.71\n255.29\n2557.15\n11.23\n1.1812\n1277.01\n22.83\n121.35\n\n\n2017-10-26\n157.41\n78.76\n41.35\n972.43\n241.72\n255.62\n2560.40\n11.30\n1.1650\n1266.73\n22.43\n120.33\n\n\n2017-10-27\n163.05\n83.81\n44.40\n1100.95\n241.71\n257.71\n2581.07\n9.80\n1.1608\n1272.60\n22.57\n120.90\n\n\n2017-10-30\n166.72\n83.89\n44.37\n1110.85\n240.89\n256.75\n2572.83\n10.50\n1.1649\n1275.86\n22.76\n121.13\n\n\n2017-10-31\n169.04\n83.18\n45.49\n1105.28\n242.48\n257.15\n2575.26\n10.18\n1.1644\n1271.20\n22.48\n120.67\n\n\n\n\n\n\n\n\n\nVisualize timeseries\n\ndata.plot(figsize = (10,12), subplots = True);\n\n\n\n\n\n\n\n\n\n\nAdd labels\nLabeling from Reuters Instrument Codes (RICs)\n\ninstruments = ['Apple Stock', 'Microsoft Stock',\n                           'Intel Stock', 'Amazon Stock', 'Goldman Sachs Stock',\n                           'SPDR S&P 500 ETF Trust', 'S&P 500 Index',\n                           'VIX Volatility Index', 'EUR/USD Exchange Rate',\n                           'Gold Price', 'VanEck Vectors Gold Miners ETF',\n                           'SPDR Gold Trust']\n\n\nfor ric, name in zip(data.columns, instruments):\n    print('{:8s} | {}'.format(ric, name))\n\nAAPL.O   | Apple Stock\nMSFT.O   | Microsoft Stock\nINTC.O   | Intel Stock\nAMZN.O   | Amazon Stock\nGS.N     | Goldman Sachs Stock\nSPY      | SPDR S&P 500 ETF Trust\n.SPX     | S&P 500 Index\n.VIX     | VIX Volatility Index\nEUR=     | EUR/USD Exchange Rate\nXAU=     | Gold Price\nGDX      | VanEck Vectors Gold Miners ETF\nGLD      | SPDR Gold Trust\n\n\n\n\n\n2.2 Summary statistics\n\nBuilt-in tools\n\ndata.describe().round(2)\n\n\n\n\n\n\n\n\nAAPL.O\nMSFT.O\nINTC.O\nAMZN.O\nGS.N\nSPY\n.SPX\n.VIX\nEUR=\nXAU=\nGDX\nGLD\n\n\n\n\ncount\n1972.00\n1972.00\n1972.00\n1972.00\n1972.00\n1972.00\n1972.00\n1972.00\n1972.00\n1972.00\n1972.00\n1972.00\n\n\nmean\n86.53\n40.59\n27.70\n401.15\n163.61\n172.84\n1727.54\n17.21\n1.25\n1352.47\n34.50\n130.60\n\n\nstd\n34.04\n14.39\n5.95\n257.12\n37.17\n42.33\n424.35\n5.92\n0.12\n195.38\n15.44\n19.46\n\n\nmin\n27.44\n23.01\n17.66\n108.61\n87.70\n102.20\n1022.58\n9.19\n1.04\n1051.36\n12.47\n100.50\n\n\n25%\n57.57\n28.12\n22.23\n202.66\n144.23\n132.64\n1325.53\n13.25\n1.13\n1214.56\n22.22\n116.77\n\n\n50%\n84.63\n36.54\n26.41\n306.42\n162.09\n178.80\n1783.81\n15.65\n1.29\n1288.82\n26.59\n123.90\n\n\n75%\n111.87\n50.08\n33.74\n559.45\n184.11\n208.01\n2080.15\n19.20\n1.35\n1491.98\n49.77\n145.43\n\n\nmax\n169.04\n83.89\n45.49\n1110.85\n252.89\n257.71\n2581.07\n48.00\n1.48\n1897.10\n66.63\n184.59\n\n\n\n\n\n\n\n\ndata.mean()\n\nAAPL.O      86.530152\nMSFT.O      40.586752\nINTC.O      27.701411\nAMZN.O     401.154006\nGS.N       163.614625\nSPY        172.835399\n.SPX      1727.538342\n.VIX        17.209498\nEUR=         1.252613\nXAU=      1352.471593\nGDX         34.499391\nGLD        130.601856\ndtype: float64\n\n\n\n\nCustomized satistics\n\ndata.aggregate(['min', 'mean', 'std', 'median', 'max']).round(2)\n\n\n\n\n\n\n\n\nAAPL.O\nMSFT.O\nINTC.O\nAMZN.O\nGS.N\nSPY\n.SPX\n.VIX\nEUR=\nXAU=\nGDX\nGLD\n\n\n\n\nmin\n27.44\n23.01\n17.66\n108.61\n87.70\n102.20\n1022.58\n9.19\n1.04\n1051.36\n12.47\n100.50\n\n\nmean\n86.53\n40.59\n27.70\n401.15\n163.61\n172.84\n1727.54\n17.21\n1.25\n1352.47\n34.50\n130.60\n\n\nstd\n34.04\n14.39\n5.95\n257.12\n37.17\n42.33\n424.35\n5.92\n0.12\n195.38\n15.44\n19.46\n\n\nmedian\n84.63\n36.54\n26.41\n306.42\n162.09\n178.80\n1783.81\n15.65\n1.29\n1288.82\n26.59\n123.90\n\n\nmax\n169.04\n83.89\n45.49\n1110.85\n252.89\n257.71\n2581.07\n48.00\n1.48\n1897.10\n66.63\n184.59\n\n\n\n\n\n\n\n\n\n\n2.3 Changes over time\nStatistical analysis methods are often based on changes over time and not the absolute values themselves.\nThere are multiple options to calculate the changes in a time series over time: - Absolute differences - Percentage changes - Logarithmic (log) returns.\n\nAbsolute differences\n.diff(): subtracts each row’s value from the value in the previous row.\n\nIt reveals the exact change in values from one time step to the next.\nThe method returns a dataframe\n\n\ndata.diff().head()\n\n\n\n\n\n\n\n\nAAPL.O\nMSFT.O\nINTC.O\nAMZN.O\nGS.N\nSPY\n.SPX\n.VIX\nEUR=\nXAU=\nGDX\nGLD\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2010-01-04\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-05\n0.052857\n0.010\n-0.01\n0.79\n3.06\n0.30\n3.53\n-0.69\n-0.0043\n-1.35\n0.46\n-0.10\n\n\n2010-01-06\n-0.487142\n-0.190\n-0.07\n-2.44\n-1.88\n0.08\n0.62\n-0.19\n0.0044\n19.85\n1.17\n1.81\n\n\n2010-01-07\n-0.055714\n-0.318\n-0.20\n-2.25\n3.41\n0.48\n4.55\n-0.10\n-0.0094\n-6.60\n-0.24\n-0.69\n\n\n2010-01-08\n0.200000\n0.208\n0.23\n3.52\n-3.36\n0.38\n3.29\n-0.93\n0.0094\n4.20\n0.74\n0.55\n\n\n\n\n\n\n\n\ndata.diff(periods=2)\n\n\n\n\n\n\n\n\nAAPL.O\nMSFT.O\nINTC.O\nAMZN.O\nGS.N\nSPY\n.SPX\n.VIX\nEUR=\nXAU=\nGDX\nGLD\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2010-01-04\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-05\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-06\n-0.434285\n-0.180\n-0.08\n-1.65\n1.18\n0.38\n4.15\n-0.88\n0.0001\n18.5000\n1.63\n1.71\n\n\n2010-01-07\n-0.542857\n-0.508\n-0.27\n-4.69\n1.53\n0.56\n5.17\n-0.29\n-0.0050\n13.2500\n0.93\n1.12\n\n\n2010-01-08\n0.144286\n-0.110\n0.03\n1.27\n0.05\n0.86\n7.84\n-1.03\n0.0000\n-2.4000\n0.50\n-0.14\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2017-10-25\n0.240000\n-0.200\n-0.05\n6.61\n-0.42\n-0.82\n-7.83\n0.16\n0.0065\n-4.6701\n-0.31\n-0.45\n\n\n2017-10-26\n0.310000\n-0.100\n0.40\n-3.47\n-3.12\n-0.94\n-8.73\n0.14\n-0.0109\n-9.6000\n-0.52\n-1.00\n\n\n2017-10-27\n6.640000\n5.180\n3.62\n128.04\n0.00\n2.42\n23.92\n-1.43\n-0.0204\n-4.4100\n-0.26\n-0.45\n\n\n2017-10-30\n9.310000\n5.130\n3.02\n138.42\n-0.83\n1.13\n12.43\n-0.80\n-0.0001\n9.1300\n0.33\n0.80\n\n\n2017-10-31\n5.990000\n-0.630\n1.09\n4.33\n0.77\n-0.56\n-5.81\n0.38\n0.0036\n-1.4000\n-0.09\n-0.23\n\n\n\n\n1972 rows × 12 columns\n\n\n\n\ndata.diff().mean()\n\nAAPL.O    0.070252\nMSFT.O    0.026499\nINTC.O    0.012486\nAMZN.O    0.492836\nGS.N      0.035211\nSPY       0.072968\n.SPX      0.731745\n.VIX     -0.005003\nEUR=     -0.000140\nXAU=      0.076712\nGDX      -0.012801\nGLD       0.005515\ndtype: float64\n\n\n\n\nPercentage changes\n.pct_change(): calculates the percentage change between consecutive rows\n\nIt reveals the relative change in values from one time step to the next.\nThe method returns a dataframe\n\n\ndata.pct_change().round(3).head()\n\n\n\n\n\n\n\n\nAAPL.O\nMSFT.O\nINTC.O\nAMZN.O\nGS.N\nSPY\n.SPX\n.VIX\nEUR=\nXAU=\nGDX\nGLD\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2010-01-04\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-05\n0.002\n0.000\n-0.000\n0.006\n0.018\n0.003\n0.003\n-0.034\n-0.003\n-0.001\n0.010\n-0.001\n\n\n2010-01-06\n-0.016\n-0.006\n-0.003\n-0.018\n-0.011\n0.001\n0.001\n-0.010\n0.003\n0.018\n0.024\n0.016\n\n\n2010-01-07\n-0.002\n-0.010\n-0.010\n-0.017\n0.020\n0.004\n0.004\n-0.005\n-0.007\n-0.006\n-0.005\n-0.006\n\n\n2010-01-08\n0.007\n0.007\n0.011\n0.027\n-0.019\n0.003\n0.003\n-0.049\n0.007\n0.004\n0.015\n0.005\n\n\n\n\n\n\n\n\ndata.pct_change(periods = 7).round(3).head(10)\n\n\n\n\n\n\n\n\nAAPL.O\nMSFT.O\nINTC.O\nAMZN.O\nGS.N\nSPY\n.SPX\n.VIX\nEUR=\nXAU=\nGDX\nGLD\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2010-01-04\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-05\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-06\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-07\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-08\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-11\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-12\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-13\n-0.016\n-0.019\n0.004\n-0.036\n-0.023\n0.011\n0.011\n-0.109\n0.007\n0.016\n0.024\n0.016\n\n\n2010-01-14\n-0.023\n0.000\n0.029\n-0.054\n-0.043\n0.011\n0.011\n-0.089\n0.009\n0.022\n0.009\n0.021\n\n\n2010-01-15\n-0.024\n0.003\n0.000\n-0.039\n-0.052\n-0.001\n-0.001\n-0.065\n-0.002\n-0.008\n-0.039\n-0.006\n\n\n\n\n\n\n\n\ndata.pct_change().mean().plot(kind = 'bar', figsize = (10,6));\n\n\n\n\n\n\n\n\n\n\nLog Returns\nLogarithmic (log) returns of time series data are the standard means to analyze returns on investments over time.\nThe formula is given by \\[\n\\text{Log Return} = \\ln\\left(\\frac{P_t}{P_{t-1}}\\right)\n\\]\nIn pandas, the denominator naturally obtains by shifting data by one row using the .shift() method.\n\nrets = np.log(data / data.shift(1))\n\n\nrets.head().round(2)\n\n\n\n\n\n\n\n\nAAPL.O\nMSFT.O\nINTC.O\nAMZN.O\nGS.N\nSPY\n.SPX\n.VIX\nEUR=\nXAU=\nGDX\nGLD\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2010-01-04\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-05\n0.00\n0.00\n-0.00\n0.01\n0.02\n0.0\n0.0\n-0.04\n-0.00\n-0.00\n0.01\n-0.00\n\n\n2010-01-06\n-0.02\n-0.01\n-0.00\n-0.02\n-0.01\n0.0\n0.0\n-0.01\n0.00\n0.02\n0.02\n0.02\n\n\n2010-01-07\n-0.00\n-0.01\n-0.01\n-0.02\n0.02\n0.0\n0.0\n-0.01\n-0.01\n-0.01\n-0.00\n-0.01\n\n\n2010-01-08\n0.01\n0.01\n0.01\n0.03\n-0.02\n0.0\n0.0\n-0.05\n0.01\n0.00\n0.01\n0.00\n\n\n\n\n\n\n\nCumulative returns over a period are obtained by summing up the log returns for each interval and then exponentiate the result:\n\\[\n\\text{Cumulative Return} = e^{\\sum \\text{Log Returns}}\n\\]\n\nrets.cumsum().apply(np.exp).plot(figsize = (10,6));\n\n\n\n\n\n\n\n\n\n\n\n2.4 Resampling\nResampling of financial time series data refers to the process of converting the frequency of data points in a time series.\nThe resample() method in pandas is used to change the frequency of time series data.\n    data.resample(rule, label='right', closed='right', kind='timestamp')\nParameters:\n\nrule: This is a required parameter and specifies the new frequency for resampling. Some common time-based frequency strings are:\n\n'D': Day\n'W': Week\n'M': Month\n'Q': Quarter\n'A': Year One can also specify intervals like ‘5min’, ‘15T’ (15 minutes), ‘3H’ (3 hours), etc.\n\nlabel: Determines how the timestamp labels in the resulting data are aligned:\n\n'right': Assigns the label to the end of the resampling period (e.g., a week ending on Sunday will be labeled as Sunday).\n'left': Assigns the label to the beginning of the resampling period (e.g., the first day of the week).\n\nclosed: Specifies which side of each interval is closed:\n\n'right': The interval includes the right endpoint.\n'left': The interval includes the left endpoint.\n\nkind: Defines the type of index used:\n\n'timestamp': Generates a DatetimeIndex.\n'period': Generates a PeriodIndex.\n\n\nAggregation functions: After resampling, you can apply an aggregation method directly, like mean(), sum(), last(), first(), count(), etc. These specify how to aggregate data within each new time interval.\n\ndata.resample('1W', label='right').last().head()\n\n\n\n\n\n\n\n\nAAPL.O\nMSFT.O\nINTC.O\nAMZN.O\nGS.N\nSPY\n.SPX\n.VIX\nEUR=\nXAU=\nGDX\nGLD\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2010-01-10\n30.282827\n30.66\n20.83\n133.52\n174.31\n114.57\n1144.98\n18.13\n1.4412\n1136.10\n49.84\n111.37\n\n\n2010-01-17\n29.418542\n30.86\n20.80\n127.14\n165.21\n113.64\n1136.03\n17.91\n1.4382\n1129.90\n47.42\n110.86\n\n\n2010-01-24\n28.249972\n28.96\n19.91\n121.43\n154.12\n109.21\n1091.76\n27.31\n1.4137\n1092.60\n43.79\n107.17\n\n\n2010-01-31\n27.437544\n28.18\n19.40\n125.41\n148.72\n107.39\n1073.87\n24.62\n1.3862\n1081.05\n40.72\n105.96\n\n\n2010-02-07\n27.922829\n28.02\n19.47\n117.39\n154.16\n106.66\n1066.19\n26.11\n1.3662\n1064.95\n42.41\n104.68\n\n\n\n\n\n\n\n\n# Resample to quarterly data, labeling periods at the start of the quarter\ndata.resample('QE', label='left').mean().head()\n\n\n\n\n\n\n\n\nAAPL.O\nMSFT.O\nINTC.O\nAMZN.O\nGS.N\nSPY\n.SPX\n.VIX\nEUR=\nXAU=\nGDX\nGLD\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2009-12-31\n30.122098\n29.254115\n20.850836\n125.804541\n164.081639\n112.546607\n1123.593607\n20.149672\n1.382338\n1109.900820\n44.881902\n108.738459\n\n\n2010-03-31\n36.391239\n27.977135\n21.917363\n130.020095\n148.985873\n113.694198\n1134.584921\n26.391429\n1.271935\n1196.456190\n49.862546\n117.159690\n\n\n2010-06-30\n37.129258\n24.790383\n19.658259\n130.454059\n146.242969\n109.856767\n1096.246875\n24.283594\n1.293530\n1226.698906\n51.520945\n120.021523\n\n\n2010-09-30\n44.500887\n26.330313\n20.678320\n169.520000\n161.686406\n120.645516\n1204.585625\n19.318437\n1.358853\n1369.649375\n59.041938\n133.778188\n\n\n2010-12-31\n49.383274\n26.989895\n21.107540\n176.948145\n164.398387\n130.385081\n1302.528871\n18.614839\n1.370015\n1386.920645\n57.362411\n135.333395\n\n\n\n\n\n\n\n\ndata.resample('1ME', label = 'right').last().head()\n\n\n\n\n\n\n\n\nAAPL.O\nMSFT.O\nINTC.O\nAMZN.O\nGS.N\nSPY\n.SPX\n.VIX\nEUR=\nXAU=\nGDX\nGLD\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2010-01-31\n27.437544\n28.1800\n19.40\n125.41\n148.72\n107.3900\n1073.87\n24.62\n1.3862\n1081.05\n40.72\n105.960\n\n\n2010-02-28\n29.231399\n28.6700\n20.53\n118.40\n156.35\n110.7400\n1104.49\n19.50\n1.3625\n1116.10\n43.89\n109.430\n\n\n2010-03-31\n33.571395\n29.2875\n22.29\n135.77\n170.63\n117.0000\n1169.43\n17.59\n1.3510\n1112.80\n44.41\n108.950\n\n\n2010-04-30\n37.298534\n30.5350\n22.84\n137.10\n145.20\n118.8125\n1186.69\n22.05\n1.3295\n1178.25\n50.51\n115.360\n\n\n2010-05-31\n36.697106\n25.8000\n21.42\n125.46\n144.26\n109.3690\n1089.41\n32.07\n1.2267\n1213.81\n49.86\n118.881\n\n\n\n\n\n\n\n\nrets.cumsum().apply(np.exp).resample('1ME', label='right').last().plot(figsize=(10, 6));"
  },
  {
    "objectID": "lectures/lecture_11/time_series.html#rolling-statistics",
    "href": "lectures/lecture_11/time_series.html#rolling-statistics",
    "title": "Lecture 11 - Time Series Analysis",
    "section": "3. Rolling statistics",
    "text": "3. Rolling statistics\nA rolling window is a technique used to apply a calculation to a specific, fixed-size subset of data, which “rolls” or moves across a dataset as a window.\nThe purpose of a rolling window is to compute statistics, like the mean or standard deviation, for consecutive subsets of data points, creating a dynamic, time-dependent view of trends, averages, or variability.\nThis technique is commonly used in time series analysis, especially in finance, to understand patterns over time while smoothing out short-term fluctuations.\nIn Python, the .rolling() method in pandas is used to apply a rolling window to a DataFrame or Series.\nThis method returns a “rolling” object that can apply various aggregation functions, like .mean(), .std(), .min(), etc., over the rolling window.\n    data.rolling(window=window_size).function()\n\n# Let's focus on a single financial time series\nsym = 'AAPL.O'\ndata = pd.DataFrame(data[sym]).dropna()\ndata.tail()\n\n\n\n\n\n\n\n\nAAPL.O\n\n\nDate\n\n\n\n\n\n2017-10-25\n156.41\n\n\n2017-10-26\n157.41\n\n\n2017-10-27\n163.05\n\n\n2017-10-30\n166.72\n\n\n2017-10-31\n169.04\n\n\n\n\n\n\n\n\nwindow = 20\n\n- Calculate rolling minimum (min) and maximum (max): identify the range of prices over the past 20 days.\n\ndata['min'] = data[sym].rolling(window=window).min()\n\n\ndata['max'] = data[sym].rolling(window=window).max()\n\n- Calculate rolling mean (mean) and standard deviation (std): The rolling mean provides a smoothed version of the price series. It smooths out short-term fluctuations, highlighting the medium-term trend. The standard deviation statistic shows the volatility of the stock price over each 20-day period.\n\ndata['mean'] = data[sym].rolling(window=window).mean()\n\n\ndata['std'] = data[sym].rolling(window=window).std()\n\n\ndata['median'] = data[sym].rolling(window=window).median()\n\n- Calculate Exponentially Weighted Moving Average (ewma): Unlike a simple moving average, which weights all points equally, the EWMA gives more importance to recent observations, allowing it to react faster to recent price changes. The halflife parameter controls how quickly the weights decay, with a shorter halflife emphasizing more recent data.\n\ndata['ewma'] = data[sym].ewm(halflife=0.5, min_periods=window).mean()\n\n\ndata.head(25)\n\n\n\n\n\n\n\n\nAAPL.O\nmin\nmax\nmean\nstd\nmedian\newma\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n2010-01-04\n30.572827\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-05\n30.625684\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-06\n30.138541\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-07\n30.082827\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-08\n30.282827\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-11\n30.015684\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-12\n29.674256\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-13\n30.092827\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-14\n29.918542\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-15\n29.418542\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-19\n30.719969\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-20\n30.246398\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-21\n29.724542\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-22\n28.249972\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-25\n29.010685\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-26\n29.419971\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-27\n29.697685\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-28\n28.469972\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-01-29\n27.437544\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2010-02-01\n27.818544\n27.437544\n30.719969\n29.580892\n0.933650\n29.821542\n27.805432\n\n\n2010-02-02\n27.979972\n27.437544\n30.719969\n29.451249\n0.968048\n29.711113\n27.936337\n\n\n2010-02-03\n28.461400\n27.437544\n30.719969\n29.343035\n0.950665\n29.685970\n28.330134\n\n\n2010-02-04\n27.435687\n27.435687\n30.719969\n29.207892\n1.021129\n29.547113\n27.659299\n\n\n2010-02-05\n27.922829\n27.435687\n30.719969\n29.099892\n1.037811\n29.419256\n27.856947\n\n\n2010-02-08\n27.731401\n27.435687\n30.719969\n28.972321\n1.041556\n29.214614\n27.762787\n\n\n\n\n\n\n\n\ndata.dropna().head()\n\n\n\n\n\n\n\n\nAAPL.O\nmin\nmax\nmean\nstd\nmedian\newma\n\n\nDate\n\n\n\n\n\n\n\n\n\n\n\n2010-02-01\n27.818544\n27.437544\n30.719969\n29.580892\n0.933650\n29.821542\n27.805432\n\n\n2010-02-02\n27.979972\n27.437544\n30.719969\n29.451249\n0.968048\n29.711113\n27.936337\n\n\n2010-02-03\n28.461400\n27.437544\n30.719969\n29.343035\n0.950665\n29.685970\n28.330134\n\n\n2010-02-04\n27.435687\n27.435687\n30.719969\n29.207892\n1.021129\n29.547113\n27.659299\n\n\n2010-02-05\n27.922829\n27.435687\n30.719969\n29.099892\n1.037811\n29.419256\n27.856947\n\n\n\n\n\n\n\n- Plotting the Rolling Statistics:\n\nax = data[['min', 'mean', 'max']].iloc[-200:].plot(\n    figsize = (10,6), style = ['g--', 'r--', 'g--'], lw = 0.8)\ndata[sym].iloc[-200:].plot(ax = ax, lw = 2.0) ;\n\n\n\n\n\n\n\n\n\nTechnical Analysis Example: SMAs\nA decades-old trading strategy based on technical analysis is using two simple moving averages (SMAs):\nTrading strategy - Go long on a stock (or financial instrument in general) when the shorter-term SMA is above the longer-term SMA - Go short when the opposite holds true.\n\ndata['SMA1'] = data[sym].rolling(window=42).mean()\ndata['SMA2'] = data[sym].rolling(window=252).mean()\n\n\ndata[[sym, 'SMA1', 'SMA2']].tail()\n\n\n\n\n\n\n\n\nAAPL.O\nSMA1\nSMA2\n\n\nDate\n\n\n\n\n\n\n\n2017-10-25\n156.41\n157.610952\n139.862520\n\n\n2017-10-26\n157.41\n157.514286\n140.028472\n\n\n2017-10-27\n163.05\n157.517619\n140.221210\n\n\n2017-10-30\n166.72\n157.597857\n140.431528\n\n\n2017-10-31\n169.04\n157.717857\n140.651766\n\n\n\n\n\n\n\n\ndata[[sym, 'SMA1', 'SMA2']].plot(figsize=(10, 6));\n\n\n\n\n\n\n\n\nSMAs are then used to derive positions to implement a trading strategy.\nDenote - a long position by a value of 1 - a short position by a value of -1.\nThe change in the position is triggered by a crossover of the two lines representing the SMA time series:\n\ndata.dropna(inplace = True)\n\n\ndata['positions'] = np.where(data['SMA1'] &gt; data['SMA2'], 1, -1)\n\n\nax = data[[sym, 'SMA1', 'SMA2', 'positions']].plot(\n    figsize = (10,6), secondary_y = 'positions')\nax.get_legend().set_bbox_to_anchor((0.25,0.85));"
  },
  {
    "objectID": "lectures/lecture_11/time_series.html#correlation-analysis",
    "href": "lectures/lecture_11/time_series.html#correlation-analysis",
    "title": "Lecture 11 - Time Series Analysis",
    "section": "4. Correlation analysis",
    "text": "4. Correlation analysis\n\n4.1 Inspection of 2 timeseries\nLet us consider the correlation analysis between two financial time series: the S&P 500 Index (.SPX) and the VIX volatility index (.VIX). - The S&P 500 is a benchmark index for U.S. stocks - the VIX measures market volatility expectations.\nTypically, these indices have an inverse relationship: when the S&P 500 falls, the VIX tends to rise, indicating higher market fear or uncertainty.\n\nraw = pd.read_csv(file_path + file_name, index_col=0, parse_dates=True)\n\n\ndata = raw[['.SPX', '.VIX']].dropna()\n\n\ndata.tail()\n\n\n\n\n\n\n\n\n.SPX\n.VIX\n\n\nDate\n\n\n\n\n\n\n2017-10-25\n2557.15\n11.23\n\n\n2017-10-26\n2560.40\n11.30\n\n\n2017-10-27\n2581.07\n9.80\n\n\n2017-10-30\n2572.83\n10.50\n\n\n2017-10-31\n2575.26\n10.18\n\n\n\n\n\n\n\n\nVisual inspection\n\ndata.plot(subplots=True, figsize=(10, 6));\n\n\n\n\n\n\n\n\n\ndata.loc[:'2012-12-31'].plot(secondary_y='.VIX', figsize=(10, 6));\n\n\n\n\n\n\n\n\n\n\n\n4.2 Logarithmic Returns\n\nProducing and processing output\n\nrets = np.log(data / data.shift(1))\n\n\nrets.head()\n\n\n\n\n\n\n\n\n.SPX\n.VIX\n\n\nDate\n\n\n\n\n\n\n2010-01-04\nNaN\nNaN\n\n\n2010-01-05\n0.003111\n-0.035038\n\n\n2010-01-06\n0.000545\n-0.009868\n\n\n2010-01-07\n0.003993\n-0.005233\n\n\n2010-01-08\n0.002878\n-0.050024\n\n\n\n\n\n\n\n\nrets.dropna(inplace=True)\n\n\n\nVisual inspection\n\nrets.plot(subplots=True, figsize=(10, 6));\n\n\n\n\n\n\n\n\nThe .plotting.scatter_matrix() produces correlation analysis plots within and across timeseries.\n\npd.plotting.scatter_matrix(rets,\n                           alpha=0.2,\n                           diagonal='hist',\n                           hist_kwds={'bins': 35},\n                           figsize=(10, 6));\n\n\n\n\n\n\n\n\n\n\n\n4.3 OLS Regression\nOrdinary Least Square regression provide a formal way to inspect the correlation between two variables.\nnp.polyfit() is a function in NumPy that fits a polynomial to a set of data points using least squares regression and returns the coeficient.\nIn other words, it finds the polynomial function of a specified degree that best fits the data in terms of minimizing the sum of squared errors between the fitted polynomial values and the actual data points\n    np.polyfit(x, y, deg, rcond=None, full=False, w=None, cov=False)\nParameters: - x: The x-coordinates (independent variable) of the data points. - y: The y-coordinates (dependent variable) of the data points. - deg: Degree of the polynomial to be fit to the data. For example: - deg=1 fits a line (linear regression), - deg=2 fits a quadratic curve, and so on. - cov (optional): If True, the function also returns the covariance matrix of the polynomial coefficients.\n\nreg, cov_matrix = np.polyfit(rets['.SPX'], rets['.VIX'], deg=1, cov=True)\nprint (f\"The regression results in: VIX = {reg[0].round(2)} SPX + {reg[1].round(4)}\")\n# print (cov_matrix)\n\nThe regression results in: VIX = -6.45 SPX + 0.0023\n\n\n\nVisual inspection\n\nax = rets.plot(kind='scatter', x='.SPX', y='.VIX', figsize=(10, 6))\nax.plot(rets['.SPX'], np.polyval(reg, rets['.SPX']), 'r', lw=2);\n\n\n\n\n\n\n\n\nwhere np.polyval() is a function in NumPy used to evaluate (calculate) the value of a polynomial for a given set of values. Essentially, given a polynomial’s coefficients, np.polyval compute the y-values for corresponding x-values on that polynomial.\n    np.polyval(p, x)\n\np: Array of polynomial coefficients in decreasing order of power.\n\nFor example, for a polynomial equation of the form \\(y = ax^2 + bx + c\\) , the coefficients array should be [\\(a, b, c\\)].\n\nx: Value(s) at which to evaluate the polynomial. This can be a single number or an array of x-values.\n\n\n\n\n4.4 Correlation\n.corr() computes the Pearson correlation coefficient between pairs of columns in a DataFrame, a measure of the strength and direction of their linear relationship. - Values range from -1 (perfect negative correlation) to +1 (perfect positive correlation). - For .SPX and .VIX, a strong negative correlation is expected.\n\nCalling the method can be\n\napplied directly to a DataFrame to calculate correlations between each column pair.\nused with one column to calculate correlation with another column, e.g., df['col1'].corr(df['col2']).\n\n\n\nrets.corr()\n\n\n\n\n\n\n\n\n.SPX\n.VIX\n\n\n\n\n.SPX\n1.000000\n-0.808372\n\n\n.VIX\n-0.808372\n1.000000\n\n\n\n\n\n\n\n\nax = rets['.SPX'].rolling(window=252).corr(\n    rets['.VIX']).plot(figsize=(10, 6))\nax.axhline(rets.corr().iloc[0, 1], c='r');"
  },
  {
    "objectID": "lectures/lecture_11/time_series.html#a-glimpse-into-high-frequency-data",
    "href": "lectures/lecture_11/time_series.html#a-glimpse-into-high-frequency-data",
    "title": "Lecture 11 - Time Series Analysis",
    "section": "5. A glimpse into high-frequency data",
    "text": "5. A glimpse into high-frequency data\nHigh-frequency data in finance refers to data captured at very short time intervals, often seconds or milliseconds, typically related to trades, bids, and asks.\nIt provides detailed insights into market activity but requires careful handling due to its high volume and potential noise. Such data is commonly used in trading, market analysis, and to identify short-term price movements or anomalies.\nFor this part, we’re loading tick data from a csv file for EUR/USD, which contains high-frequency information, like bid and ask prices, captured by the FXCM broker.\nThe following parameters apply:\n    file_path = 'Data/11/'\n    file_name = 'fxcm_eur_usd_tick_data.csv'\n\nCheck file\n\nfile_path = 'Data/11/'\nfile_name = 'fxcm_eur_usd_tick_data.csv'\nfile = open(file_path + file_name, 'r')\n\n\nfile.readlines()[:10]\n\n[',Bid,Ask\\n',\n '2017-11-10 12:00:00.007,1.16395,1.16394\\n',\n '2017-11-10 12:00:00.053,1.16394,1.16394\\n',\n '2017-11-10 12:00:00.740,1.16394,1.16393\\n',\n '2017-11-10 12:00:00.746,1.16394,1.16391\\n',\n '2017-11-10 12:00:00.756,1.16394,1.16392\\n',\n '2017-11-10 12:00:00.761,1.16393,1.16392\\n',\n '2017-11-10 12:00:00.772,1.16393,1.16391\\n',\n '2017-11-10 12:00:00.783,1.16391,1.16391\\n',\n '2017-11-10 12:00:00.819,1.16391,1.16392\\n']\n\n\n\nfile.close()\n\n\n\nImport and inspect data\n\ntick = pd.read_csv(file_path + file_name,\n                   index_col=0, parse_dates=True)\n\n\ntick.head()\n\n\n\n\n\n\n\n\nBid\nAsk\n\n\n\n\n2017-11-10 12:00:00.007\n1.16395\n1.16394\n\n\n2017-11-10 12:00:00.053\n1.16394\n1.16394\n\n\n2017-11-10 12:00:00.740\n1.16394\n1.16393\n\n\n2017-11-10 12:00:00.746\n1.16394\n1.16391\n\n\n2017-11-10 12:00:00.756\n1.16394\n1.16392\n\n\n\n\n\n\n\n\ntick.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nDatetimeIndex: 17352 entries, 2017-11-10 12:00:00.007000 to 2017-11-10 14:00:00.131000\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   Bid     17352 non-null  float64\n 1   Ask     17352 non-null  float64\ndtypes: float64(2)\nmemory usage: 406.7 KB\n\n\n\n\nCompute mid-prices\n\\[\n\\text{Mid Price} = \\frac{\\text{Bid} + \\text{Ask}}{2}\n\\]\n\ntick['Mid'] = tick.mean(axis = 1)\n\n\ntick['Mid'].plot(figsize = (10,6));\n\n\n\n\n\n\n\n\n\n\nResampling to 5-minute intervals\n\ntick_resam = tick.resample(rule='5min', label='right').last()\n\n\ntick_resam.head()\n\n\n\n\n\n\n\n\nBid\nAsk\nMid\n\n\n\n\n2017-11-10 12:05:00\n1.16425\n1.16427\n1.164260\n\n\n2017-11-10 12:10:00\n1.16454\n1.16455\n1.164545\n\n\n2017-11-10 12:15:00\n1.16449\n1.16449\n1.164490\n\n\n2017-11-10 12:20:00\n1.16437\n1.16437\n1.164370\n\n\n2017-11-10 12:25:00\n1.16429\n1.16430\n1.164295\n\n\n\n\n\n\n\n\ntick_resam['Mid'].plot(figsize=(10, 6));"
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_network.html",
    "href": "lectures/lecture_10/Problem_set_network.html",
    "title": "Problem set",
    "section": "",
    "text": "You will analyze a dataset representing payments between agents. Each row represents a payment with the following columns:"
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_network.html#preprocessing",
    "href": "lectures/lecture_10/Problem_set_network.html#preprocessing",
    "title": "Problem set",
    "section": "1. Preprocessing",
    "text": "1. Preprocessing\n\nLoad the dataset into a pandas DataFrame and inspect the first few rows. Rename columns to source, target, and weight for consistency.\nOnly keep edges where the weight is greater than or equal to 1000. This helps focus on significant payments.\nUsing NetworkX, create a directed graph from the filtered data. Each row should represent an edge from source to target with a weight.\nCreate an initial visualization of the full graph with spring_layout, where node sizes are proportional to their degree centrality. Set edge thickness proportional to the weight.\n\nQ1: Based on the visualization, do you observe any highly connected nodes? How would you interpret these nodes in the context of payment flows?\nQ2: Are there any isolated clusters or communities that stand out visually? What might these clusters represent in real-world terms?"
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_network.html#basic-analysis",
    "href": "lectures/lecture_10/Problem_set_network.html#basic-analysis",
    "title": "Problem set",
    "section": "2. Basic Analysis",
    "text": "2. Basic Analysis\nCompute the following properties of the graph: - Number of nodes - Number of edges - Average degree - Create a histogram of node degrees (number of edges connected to each node). First calculate the degree (in-degree + out-degree) for each node, then plot the histogram. - Calculate the density of the graph. - Calculate the reciprocity, which measures the proportion of edges that are bidirectional (if an edge exists from node A to node B, does one also exist from B to A?). Hint: Use nx.reciprocity() for directed graphs. - Find nodes that have no incoming edges (in-degree = 0) and those with no outgoing edges (out-degree = 0). Print their IDs and counts.\nQ3: What does the average degree tell you about the structure of the network?\nQ4: If a node has a high degree, what might that indicate about its role in this payment network?\nQ5: How might having a few high-degree nodes affect the network’s resilience? Would the network be more vulnerable if these high-degree nodes were removed?\nQ6: Is there a high level of reciprocity? How does this relate to the nature of payment flows between nodes?\nQ7: If many nodes have no incoming or outgoing edges, what might that suggest about the connectivity of the network?"
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_network.html#weighted-analysis",
    "href": "lectures/lecture_10/Problem_set_network.html#weighted-analysis",
    "title": "Problem set",
    "section": "3. Weighted Analysis",
    "text": "3. Weighted Analysis\n\nCalculate the in-strength and out-strength of each node, and find the top 8 nodes with the highest total strength\nCalculate the average in-strength and average out-strength of the nodes.\nCalculate the standard deviation of the edge weights. A higher standard deviation indicates more variability in payment amounts. Comment on whether the payments are relatively uniform or highly variable.\nSelect the top 10 nodes by out-strength and visualize them as a subgraph. Color these nodes differently and show the edge weights.\n\nQ8: Nodes with high in-strength or out-strength represent significant “payment hubs” or “payment distributors.” Can you identify these nodes? What real-world roles might they play?"
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_network.html#centrality-measures",
    "href": "lectures/lecture_10/Problem_set_network.html#centrality-measures",
    "title": "Problem set",
    "section": "4. Centrality Measures",
    "text": "4. Centrality Measures\nAlternative Centrality Measures\nCalculate the following centrality measures and list the top 5 nodes for each: - Degree centrality - Closeness Centrality - Eigenvector Centrality: shows nodes that are connected to other important nodes. - Load Centrality: Measures the fraction of all shortest paths passing through a node, emphasizing the node’s role in connecting different parts of the network.\nCreate a scatter plot comparing degree centrality and eigenvector centrality for each node. Highlight the top 5 nodes for each centrality measure and label them.\nQ9: Which centrality measure do you think best reflects the “influence” of a node in a payment network? Why?\nQ10: How does the correlation between degree centrality and eigenvector centrality help you understand the network’s structure?"
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_network.html#community-and-core-periphery-structure",
    "href": "lectures/lecture_10/Problem_set_network.html#community-and-core-periphery-structure",
    "title": "Problem set",
    "section": "5. Community and Core-Periphery Structure",
    "text": "5. Community and Core-Periphery Structure\n\nConvert the directed graph to an undirected graph and apply the Louvain method for community detection. List the number of communities detected and the size of each.\n\nHint: You can use community_louvain.best_partition() from the python-louvain package.\n\nFind the k-core of the network for k=2 and determine the core and periphery nodes.\nCalculate the average clustering coefficient for the core nodes and compare it with that of the periphery nodes.\nFind the node with the maximum clustering coefficient.\n\nHint: Use nx.k_core() and nx.clustering()."
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_network.html#bonus-questions",
    "href": "lectures/lecture_10/Problem_set_network.html#bonus-questions",
    "title": "Problem set",
    "section": "6. Bonus Questions",
    "text": "6. Bonus Questions\nAnalyze Network Robustness\n\nRemove the top 5 nodes by betweenness centrality and analyze how the graph’s structure changes.\nCalculate the new number of nodes and edges, as well as the network density, after these nodes are removed.\nlook at the size of the new SCC and compare it with the old one.\n\nQ11: After removing the top 5 nodes by betweenness centrality, how has the network changed in terms of node count, edge count, and density?\nQ12: How did the SCC changed? What is your interpretation?"
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_solutions.html",
    "href": "lectures/lecture_10/Problem_set_solutions.html",
    "title": "Problem set",
    "section": "",
    "text": "You will analyze a dataset representing payments between agents. Each row represents a payment with the following columns:"
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_solutions.html#preprocessing",
    "href": "lectures/lecture_10/Problem_set_solutions.html#preprocessing",
    "title": "Problem set",
    "section": "1. Preprocessing",
    "text": "1. Preprocessing\n\nLoad the dataset into a pandas DataFrame and inspect the first few rows. Rename columns to source, target, and weight for consistency.\nOnly keep edges where the weight is greater than or equal to 1000. This helps focus on significant payments.\nUsing NetworkX, create a directed graph from the filtered data. Each row should represent an edge from source to target with a weight.\nCreate an initial visualization of the full graph with spring_layout, where node sizes are proportional to their degree centrality. Set edge thickness proportional to the weight.\n\nQ1: Based on the visualization, do you observe any highly connected nodes? How would you interpret these nodes in the context of payment flows?\nQ2: Are there any isolated clusters or communities that stand out visually? What might these clusters represent in real-world terms?\n\nimport pandas as pd\nimport networkx as nx\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndf = pd.read_csv('payments_dataset.csv', delimiter=';')\n\ndf.columns = df.columns.str.strip()\ndf.rename(columns={'Sourceid': 'source', 'Targetid': 'target', 'Weights': 'weight'}, inplace=True)\nprint(df.head())\n\ndf = df[df['weight'] &gt;= 1000]\nprint(df)\n\nG = nx.DiGraph()\nG.add_weighted_edges_from(df[['source', 'target', 'weight']].values)\n\npos = nx.spring_layout(G, seed=42)\nplt.figure(figsize=(10, 8))\nnx.draw(G, pos, node_size=[100 + 1000 * nx.degree_centrality(G)[n] for n in G], \n        edge_color='gray', width=[0.5 + 2 * d['weight']/max(df['weight']) for u, v, d in G.edges(data=True)],\n        with_labels=False, node_color='skyblue', alpha=0.7)\nplt.title(\"Initial Visualization of Payment Network\")\nplt.show()\n\n   source  target   weight\n0       0       1   4440.0\n1       0       2   3809.0\n2       0       3  16011.0\n3       0       4  16674.0\n4       0       5   2779.0\n       source  target   weight\n0           0       1   4440.0\n1           0       2   3809.0\n2           0       3  16011.0\n3           0       4  16674.0\n4           0       5   2779.0\n...       ...     ...      ...\n11621    4547    2937   9295.0\n11623    4547    3091   3147.0\n11625    4547    3428   2000.0\n11626    4547    3459  21293.0\n11629    4547    4073   1001.0\n\n[10303 rows x 3 columns]"
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_solutions.html#basic-analysis",
    "href": "lectures/lecture_10/Problem_set_solutions.html#basic-analysis",
    "title": "Problem set",
    "section": "2. Basic Analysis",
    "text": "2. Basic Analysis\nCompute the following properties of the graph: - Number of nodes - Number of edges - Average degree - Create a histogram of node degrees (number of edges connected to each node). First calculate the degree (in-degree + out-degree) for each node, then plot the histogram. - Calculate the density of the graph. - Calculate the reciprocity, which measures the proportion of edges that are bidirectional (if an edge exists from node A to node B, does one also exist from B to A?). Hint: Use nx.reciprocity() for directed graphs. - Find nodes that have no incoming edges (in-degree = 0) and those with no outgoing edges (out-degree = 0). Print their IDs and counts.\nQ3: What does the average degree tell you about the structure of the network?\nQ4: If a node has a high degree, what might that indicate about its role in this payment network?\nQ5: How might having a few high-degree nodes affect the network’s resilience? Would the network be more vulnerable if these high-degree nodes were removed?\nQ6: Is there a high level of reciprocity? How does this relate to the nature of payment flows between nodes?\nQ7: If many nodes have no incoming or outgoing edges, what might that suggest about the connectivity of the network?\n\nnum_nodes = G.number_of_nodes()\nnum_edges = G.number_of_edges()\navg_degree = num_edges / num_nodes\n\nprint(f\"Number of nodes: {num_nodes}\")\nprint(f\"Number of edges: {num_edges}\")\nprint(f\"Average degree: {avg_degree}\")\n\n# histogram\ndegrees = [deg for _, deg in G.degree()]\nplt.figure(figsize=(6, 4))\nplt.hist(degrees, bins=10, color='skyblue', edgecolor='black')\nplt.xlabel('Degree')\nplt.ylabel('Frequency')\nplt.title('Histogram of Node Degrees')\nplt.show()\n\n# density\ndensity = nx.density(G)\nprint(f\"Density of the graph: {density}\")\n\n# reciprocity\nreciprocity = nx.reciprocity(G)\nprint(f\"Reciprocity of the graph: {reciprocity}\")\n\n# no in- out-\nno_incoming = [node for node in G.nodes if G.in_degree(node) == 0]\nno_outgoing = [node for node in G.nodes if G.out_degree(node) == 0]\n\nprint(f\"Count of nodes with no incoming edges: {len(no_incoming)}\")\nprint(f\"Count of nodes with no outgoing edges: {len(no_outgoing)}\")\n\nNumber of nodes: 4243\nNumber of edges: 10303\nAverage degree: 2.4282347395710584\n\n\n\n\n\n\n\n\n\nDensity of the graph: 0.0005724268598705937\nReciprocity of the graph: 0.14015335339221585\nCount of nodes with no incoming edges: 3089\nCount of nodes with no outgoing edges: 106"
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_solutions.html#weighted-analysis",
    "href": "lectures/lecture_10/Problem_set_solutions.html#weighted-analysis",
    "title": "Problem set",
    "section": "3. Weighted Analysis",
    "text": "3. Weighted Analysis\n\nCalculate the in-strength and out-strength of each node, and find the top 8 nodes with the highest total strength\nCalculate the average in-strength and average out-strength of the nodes.\nCalculate the standard deviation of the edge weights. A higher standard deviation indicates more variability in payment amounts. Comment on whether the payments are relatively uniform or highly variable.\nSelect the top 10 nodes by out-strength and visualize them as a subgraph. Color these nodes differently and show the edge weights.\n\nQ8: Nodes with high in-strength or out-strength represent significant “payment hubs” or “payment distributors.” Can you identify these nodes? What real-world roles might they play?\n\n# in and out strength top 8\nin_strength = {node: G.in_degree(node, weight='weight') for node in G.nodes()}\nout_strength = {node: G.out_degree(node, weight='weight') for node in G.nodes()}\ntotal_strength = {node: in_strength[node] + out_strength[node] for node in G.nodes()}\n\ntop_8_strength = sorted(total_strength.items(), key=lambda x: x[1], reverse=True)[:8]\nprint(\"Top 8 nodes by total strength:\", top_8_strength)\n\n# avarage in and out strength\navg_in_strength = np.mean(list(in_strength.values()))\navg_out_strength = np.mean(list(out_strength.values()))\n\nprint(f\"Average in-strength: {avg_in_strength}\")\nprint(f\"Average out-strength: {avg_out_strength}\")\n\n# standard deviation\nweight_std_dev = df['weight'].std()\nprint(f\"Standard deviation of edge weights: {weight_std_dev}\")\n\nif weight_std_dev &gt; df['weight'].mean():\n    print(\"Payments are highly variable.\")\nelse:\n    print(\"Payments are relatively uniform.\")\n\n# top 10 nodes out-strength\ntop_10_out = sorted(out_strength.items(), key=lambda x: x[1], reverse=True)[:10]\ntop_10_nodes = [node for node, _ in top_10_out]\nsubgraph = G.subgraph(top_10_nodes)\n\npos = nx.spring_layout(subgraph)\nplt.figure(figsize=(8, 6))\nnx.draw(subgraph, pos, with_labels=True, node_color='orange', node_size=700, edge_color='gray', font_weight='bold')\nedge_labels = nx.get_edge_attributes(subgraph, 'weight')\nnx.draw_networkx_edge_labels(subgraph, pos, edge_labels=edge_labels)\nplt.title(\"Subgraph of Top 10 Nodes by Out-Strength\")\nplt.show()\n\nTop 8 nodes by total strength: [(0.0, 341240571.23096794), (4547.0, 246131338.89006302), (5.0, 207905240.60187095), (17.0, 169594421.02847004), (6.0, 148151943.737947), (4.0, 147665662.56326798), (2.0, 144216823.908849), (8.0, 132960659.041529)]\nAverage in-strength: 426277.93115615525\nAverage out-strength: 426277.9311561553\nStandard deviation of edge weights: 1668397.7113857793\nPayments are highly variable."
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_solutions.html#centrality-measures",
    "href": "lectures/lecture_10/Problem_set_solutions.html#centrality-measures",
    "title": "Problem set",
    "section": "4. Centrality Measures",
    "text": "4. Centrality Measures\nAlternative Centrality Measures\nCalculate the following centrality measures and list the top 5 nodes for each: - Degree centrality - Closeness Centrality - Eigenvector Centrality: shows nodes that are connected to other important nodes. - Load Centrality: Measures the fraction of all shortest paths passing through a node, emphasizing the node’s role in connecting different parts of the network.\nCreate a scatter plot comparing degree centrality and eigenvector centrality for each node. Highlight the top 5 nodes for each centrality measure and label them.\nQ9: Which centrality measure do you think best reflects the “influence” of a node in a payment network? Why?\nQ10: How does the correlation between degree centrality and eigenvector centrality help you understand the network’s structure?\n\ndegree_centrality = nx.degree_centrality(G)\ncloseness_centrality = nx.closeness_centrality(G)\neigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000)\nload_centrality = nx.load_centrality(G)\n\ntop_5_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\ntop_5_closeness = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\ntop_5_eigenvector = sorted(eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\ntop_5_load = sorted(load_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\n\nprint(\"Top 5 by Degree Centrality:\", top_5_degree)\nprint(\"Top 5 by Closeness Centrality:\", top_5_closeness)\nprint(\"Top 5 by Eigenvector Centrality:\", top_5_eigenvector)\nprint(\"Top 5 by Load Centrality:\", top_5_load)\n\nTop 5 by Degree Centrality: [(0.0, 0.2927864214992928), (8.0, 0.1885902876001886), (17.0, 0.1848184818481848), (4547.0, 0.14285714285714285), (6.0, 0.14144271570014144)]\nTop 5 by Closeness Centrality: [(0.0, 0.5176010211858625), (4547.0, 0.48314477178724247), (8.0, 0.4808583203736152), (3.0, 0.4780737626009124), (2.0, 0.4750933243254961)]\nTop 5 by Eigenvector Centrality: [(0.0, 0.21819153554982326), (17.0, 0.20128193274517905), (4547.0, 0.19747698103328284), (8.0, 0.18946179339723365), (6.0, 0.18797000353623358)]\nTop 5 by Load Centrality: [(0.0, 0.08197213283976615), (17.0, 0.043855567430209005), (2.0, 0.042420294803678045), (8.0, 0.04229906449172407), (6.0, 0.03396755011671321)]\n\n\n\nimport matplotlib.pyplot as plt\ndegree_vals = list(degree_centrality.values())\neigenvector_vals = list(eigenvector_centrality.values())\n\nplt.figure(figsize=(10, 6))\nplt.scatter(degree_vals, eigenvector_vals, color='skyblue', edgecolor='black')\nplt.xlabel(\"Degree Centrality\")\nplt.ylabel(\"Eigenvector Centrality\")\nplt.title(\"Degree vs. Eigenvector Centrality\")\n\n# Highlight and label top 5 nodes in both metrics\nfor node, centrality in top_5_degree:\n    plt.annotate(node, (degree_centrality[node], eigenvector_centrality[node]), color='red')\nfor node, centrality in top_5_eigenvector:\n    plt.annotate(node, (degree_centrality[node], eigenvector_centrality[node]), color='blue')\n\nplt.show()"
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_solutions.html#community-and-core-periphery-structure",
    "href": "lectures/lecture_10/Problem_set_solutions.html#community-and-core-periphery-structure",
    "title": "Problem set",
    "section": "5. Community and Core-Periphery Structure",
    "text": "5. Community and Core-Periphery Structure\n\nConvert the directed graph to an undirected graph and apply the Louvain method for community detection. List the number of communities detected and the size of each.\n\nHint: You can use community_louvain.best_partition() from the python-louvain package.\n\nFind the k-core of the network for k=2 and determine the core and periphery nodes.\nCalculate the average clustering coefficient for the core nodes and compare it with that of the periphery nodes.\nFind the node with the maximum clustering coefficient.\n\nHint: Use nx.k_core() and nx.clustering().\n\npip install python-louvain\n\n\nfrom community import community_louvain\n\nG_undirected = G.to_undirected()\npartition = community_louvain.best_partition(G_undirected)\nnum_communities = len(set(partition.values()))\ncommunity_sizes = {community: list(partition.values()).count(community) for community in set(partition.values())}\n\nprint(f\"Number of communities: {num_communities}\")\nprint(\"Sizes of each community:\", community_sizes)\n\nNumber of communities: 10\nSizes of each community: {0: 1202, 1: 267, 2: 372, 3: 444, 4: 364, 5: 520, 6: 305, 7: 254, 8: 97, 9: 418}\n\n\n\nk_core = nx.k_core(G, k=2)\ncore_nodes = set(k_core.nodes())\nperiphery_nodes = set(G.nodes()) - core_nodes\n\ncore_clustering = np.mean([nx.clustering(G, node) for node in core_nodes])\nperiphery_clustering = np.mean([nx.clustering(G, node) for node in periphery_nodes])\n\nprint(f\"Core Nodes clustering coefficient (average): {core_clustering}\")\nprint(f\"Periphery nodes clustering coefficient (average): {periphery_clustering}\")\n\nclustering_coefficients = nx.clustering(G)\nmax_clustering_node = max(clustering_coefficients, key=clustering_coefficients.get)\nmax_clustering_value = clustering_coefficients[max_clustering_node]\n\nprint(f\"Node with maximum clustering coefficient: {int(max_clustering_node)} (value: {max_clustering_value})\")\n\nCore Nodes clustering coefficient (average): 0.7536314883581225\nPeriphery nodes clustering coefficient (average): 0.0\nNode with maximum clustering coefficient: 42 (value: 1.0)"
  },
  {
    "objectID": "lectures/lecture_10/Problem_set_solutions.html#bonus-questions",
    "href": "lectures/lecture_10/Problem_set_solutions.html#bonus-questions",
    "title": "Problem set",
    "section": "6. Bonus Questions",
    "text": "6. Bonus Questions\nAnalyze Network Robustness\n\nRemove the top 5 nodes by betweenness centrality and analyze how the graph’s structure changes.\nCalculate the new number of nodes and edges, as well as the network density, after these nodes are removed.\nlook at the size of the new SCC and compare it with the old one.\n\nQ11: After removing the top 5 nodes by betweenness centrality, how has the network changed in terms of node count, edge count, and density?\nQ12: How did the SCC changed? What is your interpretation?\n\nbetweenness_centrality = nx.betweenness_centrality(G)\ntop_5_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:5]\nnodes_to_remove = [node for node, _ in top_5_betweenness]\n\noriginal_sccs = list(nx.strongly_connected_components(G))\noriginal_num_scc = len(original_sccs)\noriginal_largest_scc = len(max(original_sccs, key=len))\n\nprint(\"Original Graph:\")\nprint(f\"Number of strongly connected components: {original_num_scc}\")\nprint(f\"Size of the largest strongly connected component: {original_largest_scc}\")\n\n# Remove the top 5 nodes by betweenness centrality\nG_removed = G.copy()\nG_removed.remove_nodes_from(nodes_to_remove)\n\n# Analyze the modified directed graph\nnew_nodes = G_removed.number_of_nodes()\nnew_edges = G_removed.number_of_edges()\nnew_density = nx.density(G_removed)\n\n# Calculate SCCs for the modified graph\nnew_sccs = list(nx.strongly_connected_components(G_removed))\nnew_num_scc = len(new_sccs)\nnew_largest_scc = len(max(new_sccs, key=len))\n\nprint(\"\\nAfter removing top 5 nodes by betweenness centrality:\")\nprint(f\"New number of nodes: {new_nodes}\")\nprint(f\"New number of edges: {new_edges}\")\nprint(f\"New network density: {new_density:.4f}\")\nprint(f\"Number of strongly connected components after removal: {new_num_scc}\")\nprint(f\"Size of the largest strongly connected component after removal: {new_largest_scc}\")\n\nOriginal Graph:\nNumber of strongly connected components: 3211\nSize of the largest strongly connected component: 1033\n\nAfter removing top 5 nodes by betweenness centrality:\nNew number of nodes: 4238\nNew number of edges: 6301\nNew network density: 0.0004\nNumber of strongly connected components after removal: 3858\nSize of the largest strongly connected component after removal: 381"
  },
  {
    "objectID": "lectures/lecture_09/lecture_09.html",
    "href": "lectures/lecture_09/lecture_09.html",
    "title": "Lecture 09 - Input and Output (I/O) Operations",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\n\nData: .zip\n\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_09/lecture_09.html#lecture-material",
    "href": "lectures/lecture_09/lecture_09.html#lecture-material",
    "title": "Lecture 09 - Input and Output (I/O) Operations",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\n\nData: .zip\n\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_09/lecture_09.html#recording",
    "href": "lectures/lecture_09/lecture_09.html#recording",
    "title": "Lecture 09 - Input and Output (I/O) Operations",
    "section": "Recording",
    "text": "Recording\n\n1. Intro\n\n \n\n\n\n2. Live inputs and outputs\n\n \n\n\n\n3. File inputs and outputs\n\n \n\n\n\n4. CSV\n\n \n\n\n\n5. Excel"
  },
  {
    "objectID": "lectures/lecture_09/lecture_09.html#problem-sets",
    "href": "lectures/lecture_09/lecture_09.html#problem-sets",
    "title": "Lecture 09 - Input and Output (I/O) Operations",
    "section": "Problem sets",
    "text": "Problem sets\n\nJupyter notebook (.ipynb)\nSolutions (.pdf)"
  },
  {
    "objectID": "lectures/lecture_09/lecture_09_problem_set.html",
    "href": "lectures/lecture_09/lecture_09_problem_set.html",
    "title": "Input and Output Operations - Problem set",
    "section": "",
    "text": "Exercise 1\nWrite a program that takes two integers as input and prints their sum, product, and division as output, ensuring division by zero is handled.\n\n\nExercise 2\nWrite a Python script that asks the user to input a sentence and then counts the number of vowels in the sentence.\n\n\nExercise 3\nWrite a program that reads a text file, counts the number of words in the file, and prints the result.\n\n\nExercise 4\nUsing the with statement, write a program that appends five random integers (one per line) to an existing text file called random_numbers.txt.\n\n\nExercise 5\nWrite a program that reads a CSV file containing two columns: name and score. Calculate the average score and print names with scores above the average.\n\n\nExercise 6\nCreate a program that takes user input for a name and a balance amount. Save the input into a new CSV file called balance_data.csv, appending each new entry without overwriting the file.\n\n\nExercise 7\nWrite a Python script that reads a CSV file, performs a transformation by multiplying all numerical values by 1.1, and saves the modified data into a new CSV file.\n\n\nExercise 8\nWrite a program that reads data from an Excel file with multiple sheets. Calculate the average of values in each sheet and save these results in a new Excel file with the averages on different sheets.\n\n\nExercise 9\nCreate a program that reads an Excel file, extracts rows where a particular column has values above a user-defined threshold, and saves the filtered data to a new sheet in the same Excel file.\n\n\nExercise 10\nWrite a program that uses the pandas library to create a DataFrame from scratch with columns Name, Age, and Grade, then writes this DataFrame to both a CSV and an Excel file."
  },
  {
    "objectID": "lectures/lecture_07/numerical_computing.html",
    "href": "lectures/lecture_07/numerical_computing.html",
    "title": "Lecture 07 - Numerical Computing (NumPy)",
    "section": "",
    "text": "NumPy (Numerical Python) is a fundamental library for scientific computing in Python. It provides support for arrays, matrices, and many mathematical functions that operate on these data structures.\nThis notebook covers: - Creating and manipulating NumPy arrays - Basic mathematical operations with NumPy - Statistic calculations using NumPy - Finance applications\nWhy Use NumPy?\nNumPy offers significant advantages when working with numerical data: - Performance: NumPy is much faster than traditional Python lists for numerical operations. - Functionality: NumPy provides a wide range of mathematical functions and operations. - Convenience: NumPy arrays are more convenient to work with, especially for large datasets."
  },
  {
    "objectID": "lectures/lecture_07/numerical_computing.html#overview",
    "href": "lectures/lecture_07/numerical_computing.html#overview",
    "title": "Lecture 07 - Numerical Computing (NumPy)",
    "section": "",
    "text": "NumPy (Numerical Python) is a fundamental library for scientific computing in Python. It provides support for arrays, matrices, and many mathematical functions that operate on these data structures.\nThis notebook covers: - Creating and manipulating NumPy arrays - Basic mathematical operations with NumPy - Statistic calculations using NumPy - Finance applications\nWhy Use NumPy?\nNumPy offers significant advantages when working with numerical data: - Performance: NumPy is much faster than traditional Python lists for numerical operations. - Functionality: NumPy provides a wide range of mathematical functions and operations. - Convenience: NumPy arrays are more convenient to work with, especially for large datasets."
  },
  {
    "objectID": "lectures/lecture_07/numerical_computing.html#arrays-of-data",
    "href": "lectures/lecture_07/numerical_computing.html#arrays-of-data",
    "title": "Lecture 07 - Numerical Computing (NumPy)",
    "section": "1. Arrays of data",
    "text": "1. Arrays of data\n\n1.1 Definitions\nGeneral data structures in Python, especially list, are flexible but can be inefficient in terms of memory and performance.\nFor scientific and financial applications that demand high-performance operations on specialized data structures, arrays are crucial.\nWhat are Arrays?\nArrays organize elements of the same data type in rows and columns, typically representing numbers like real values.\n\nA one-dimensional array represents a vector\nA multi-dimensional array forms matrices, cubes, etc.\n\nTo efficiently handle arrays, NumPy works with its ndarray class which provides powerful and specialized functionality.\n\n\n1.2 Using list to handle arrays\n\nDimensionality\nPython list can be of multiple dimensions: vector, matrices, cubes\n\n# 1-dimension list\nv = [0.5, 0.75, 1.0, 1.5, 2.0]\n\n# 2-dimensions list = matrix\nm = [v, v, v]\n\n\n\nIndexing\nReminder: list are indexed from 0 for each of their dimensions\n\nm\n\n\nm[1]\n\n\nm[1][0]\n\n\n\nn-dimensions & deep copies\nlist of n-dimensions can be constructed as vectors of other lists.\n\nv1 = [0.5, 1.5]\nv2 = [1, 2]\nm = [v1, v2]\nc = [m, m]\nc\n\nHowever, such construction leads to dependencies in terms of references and memory.\nBy default, a copy of a vector in a list points to the same original values.\nOperations on the copy therefore also apply to the origin.\n\nv = [0.5, 0.75, 1.0, 1.5, 2.0]\nm = [v, v, v]\nv[0] = 'Python'\nm\n\nDeep copies allow to decouple origins and copies by creating different references in the memory.\n\nfrom copy import deepcopy\nv = [0.5, 0.75, 1.0, 1.5, 2.0]\nm = 3 * [deepcopy(v)]\nm\n\n\nv[0] = 'Python'\nm\n\n\nv"
  },
  {
    "objectID": "lectures/lecture_07/numerical_computing.html#regular-numpy-arrays",
    "href": "lectures/lecture_07/numerical_computing.html#regular-numpy-arrays",
    "title": "Lecture 07 - Numerical Computing (NumPy)",
    "section": "2. Regular NumPy arrays",
    "text": "2. Regular NumPy arrays\n\n2.1 The basics\nUsing list objects to compose array structures is possible, but not very convenient since the list class is designed for broader, general purposes.\nA truly dedicated class for handling array-type structures is far more beneficial.\nnumpy.array is such a class, built with the specific goal of handling n-dimensional arrays both conveniently and efficiently.\n\nimport numpy as np\na = np.array([0, 0.5, 1.0, 1.5, 2.0])\na\n\n\ntype(a)\n\n\na = np.array(['a', 'b', 'c'])\na\n\n\narange()\nSimilar to the range function\n\na = np.arange(2, 20, 2)\na\n\n\na = np.arange(8, dtype=float)\na\n\n\n\nIndexing\nIndexing works like in list.\n\na[5:]\n\n\na[:2]\n\n\n\nndarray built-in methods\n\na.sum()\n\n\na.std()\n\n\na.cumsum()\n\n(Vectorized) Math operations\n\n2 * a\n\n\na ** 2\n\n\na ** a\n\nUniversal functions\n“Universal” because they operate on ndarray objects as well as on basic Python data types.\n\nnp.exp(a)\n\n\nnp.sqrt(a)\n\n\nnp.sqrt(2.5)\n\n\n\nMatrices\n\nb = np.array([a, a * 2])\nb\n\n\nb[0]\n\n\nb[0,2]\n\n\nb[:,1]\n\n\nb.sum()\n\n\n# column-wise operation\nb.sum(axis = 0)\n\n\n# row-wise operation\nb.sum(axis = 1)\n\n\n\n\n2.2 Initialization\nInitialization functions allow to construct n-dimensional arrays with pre-instructed procedures to fill each data point: - np.zeros(), np.zeros_like() - np.ones(), np.ones_like() - np.empty(), np.empty_like() - np.eye() - np.linspace()\nFor initialization functions, one can provide the following parameters: - shape: Either an int, a sequence of int objects, or a reference to another ndarray - dtype (optional): A dtype—these are NumPy-specific data types for ndarray objects\n\n\n\ndtype\nDescription\n\n\n\n\n?\nBoolean\n\n\ni\nSigned integer\n\n\nu\nUnsigned integer\n\n\nf\nFloating point\n\n\nc\nComplex floating point\n\n\nm\ntimedelta\n\n\nM\ndatetime\n\n\nO\nObject\n\n\nU\nUnicode\n\n\nV\nRaw data (void)\n\n\n\n\nnp.zeros()\nThe np.zeros() function creates a 2-dimensional array of zeros with specific characteristics.\n\nc = np.zeros((2, 3), dtype='i')\nc\n\n\nd = np.zeros_like(c, dtype='f')\nd\n\n\n\nnp.ones()\nThe np.ones() function creates a 2-dimensional array of ones with specific characteristics.\n\nc = np.ones((2, 3, 4), dtype='i')\nc\n\nThis example generates an array filled with ones. The shape of the array is (2, 3, 4), which means it will have: - 2 blocks (first dimension), - each block contains 3 rows (second dimension), - and each row contains 4 elements (third dimension).\nThe result is a 3D array like:\n[\n  [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],  # First block (2x3x4)\n  [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]   # Second block (2x3x4)\n]\n\nd = np.ones_like(c, dtype='f')\nd\n\n\n\nnp.empty()\nUnlike np.ones() or np.zeros(), np.empty() does not initialize the array with any specific values like 1 or 0.\nInstead, it leaves the array filled with whatever data is already in memory at that location. This means the array will have arbitrary values, often referred to as “garbage” values. This makes np.empty() faster than functions that initialize the array with specific values because it skips that step.\nEmpty view\n[\n  [[?, ?], [?, ?], [?, ?]],  # First block (2x3x2)\n  [[?, ?], [?, ?], [?, ?]]   # Second block (2x3x2)\n]\nWhere the ? symbols represent random or garbage values, because the array is uninitialized.\n\ne = np.empty((2, 3, 2))\ne\n\n\nf = np.empty_like(c)\nf\n\n\n\nnp.eye()\nThe np.eye(n) function creates a 2D identity matrix of size nxn\n\nnp.eye(5)\n\n\n\nnp.linspace()\nThe np.linspace() function creates a 1-dimensional array of evenly spaced numbers.\n\ng = np.linspace(5, 15, 12)\ng\n\n\n\n\n2.3 Metainformation\nArrays deliver several meta-information.\n\nsize returns the total number of elements in the array\n\n\ng.size\n\n\nitemsize returns the size (in bytes) of each element in the array\n\n\ng.itemsize\n\n\nndim returns the number of dimensions of the array\n\n\ng\n\n\ng.ndim\n\n\nshape returns the shape of the array\n\n\ng.shape\n\n\ndtype returns the data type of the elements in the array\n\n\ng.dtype\n\n\nnbytes returns the total number of bytes consumed by the elements of the array\n\n\ng.nbytes\n\n\n\n2.4 Structural operations\n\n# Initialise an array\ng = np.arange(15)\nprint (g)\nprint (g.shape)\n\n\nReshaping\nReshaping provides another view on the same data.\nDuring a reshaping operation, the total number of elements in the ndarray object is unchanged.\n\nnp.reshape(a, newshape)\n\n\ng.reshape((3,5))\n\n\nh = g.reshape((5,3))\nh\n\n\n\nTransposing\nTransposing creates a view of the original array (i.e., it does not create a new object unless explicitly copied).\nThe dimensions (axes) of the ndarray object are swapped.\nFor 2D arrays, this means rows become columns and columns become rows. For higher-dimensional arrays, the axes are reordered according to the shape.\n\na.transpose(*axes)\na.T\nnp.transpose(a, axes)\n\n\nh\n\n\nh.transpose()\n\n\nh.T\n\n\n\nResizing\nResizing creates a new (temporary) object.\nDuring a resizing operation, the total number of elements in the ndarray object changes: it either decreases (“down-sizing”) or increases (“up-sizing”). - np.resize(a, newshape)\n\ng\n\n\ng.size\n\n\nnp.resize(g,(3,1))\n\n\nnp.resize(g, (1, 5))\n\n\nnp.resize(g, (2, 5))\n\n\nn = np.resize(g, (5, 4))\nn\n\n\n\nStacking\nStacking joins a sequence of arrays along a new axis.\nThis is used to combine arrays into a single array with a new dimension. The arrays must have the same shape, except along the axis being stacked.\n\nnp.stack(arrays, axis=0)\nnp.hstack(tuple) (for horizontal stacking)\nnp.vstack(tuple) (for vertical stacking)\n\n\na = np.array([1, 2])\nb = np.array([3, 4])\n\n\n# Stacking along a new axis\nnp.stack((a, b), axis=0)\n\n\nnp.stack((a, b), axis=1)  \n\n\n# Horizontal and vertical stacking\nnp.hstack((a, b))\n\n\nnp.vstack((a, b)) \n\n\nh\n\n\n# horizontal stacking\nnp.hstack((h,2*h))\n\n\n# vertical stacking\nnp.vstack((h, 0.5 * h))\n\n\n\nFlattening\nFlattening refers to converting a multi-dimensional array into a 1-dimensional array. This is useful when processing the array as a sequence of elements, regardless of its original shape. - a.flatten() - np.ravel(a)\n\na = np.array([[1, 2], [3, 4]])\n\n# Flattening the array\na.flatten()\n\n\nnp.ravel(a)\n\n\nh\n\n\nh.flatten()\n\n\nfor i in h.flat:\n    print(i, end=',')\n\n\n\n\n2.5 Boolean arrays\nLogical operations work on ndarray objects the same way, element-wise, as on standard Python data types.\n\nh\n\n\nBasics\n\nh &gt; 8\n\n\nh &lt;= 7\n\n\nh == 5\n\n\n(h == 5).astype(int)\n\n\n(h &gt; 4 ) & (h &lt;= 12)\n\n\n\nBoolean filtering\n\nh[h &gt; 8]\n\n\nh[(h &gt; 4) & (h &lt;= 12)]\n\n\nh[(h &lt; 4) | (h &gt;= 12)]\n\nnp.where() returns the indices of elements in an input array that satisfy a given condition.\nIt can also be used to return values from one of two arrays, depending on a condition (conditional selection).\n\nnp.where(condition, [x, y]):\n\nIf only condition is provided, np.where() returns the indices where the condition is True.\nIf x and y are also provided, np.where() returns elements from x where the condition is True, and from y where the condition is False.\n\n\n\na = np.array([1, 2, 3, 4, 5])\nnp.where(a &gt; 3)\n\n\nnp.where(np.eye(10)&gt;0)\n\n\n# use the np.where() function\nnp.where(h &gt; 7, 1, 0)\n\n\nnp.where(h % 2 == 0, 'even', 'odd')\n\n\nnp.where(h &lt;= 7, h * 2, h / 2)"
  },
  {
    "objectID": "lectures/lecture_07/numerical_computing.html#structured-numpy-arrays",
    "href": "lectures/lecture_07/numerical_computing.html#structured-numpy-arrays",
    "title": "Lecture 07 - Numerical Computing (NumPy)",
    "section": "3. Structured NumPy arrays",
    "text": "3. Structured NumPy arrays\nStructured ndarray objects allow to have a different dtype per column.\nThe construction is similar to the operation for initializing tables in a database (e.g., SQL): one has column names and column data types, with maybe some additional information (e.g., maximum number of characters per str object).\n\ndt = np.dtype([('Name', 'S10'), ('Age', 'i'),\n                             ('Height', 'f'), ('Children/Pets', 'i', 2)])\ndt\n\n\n# alternative\ndt = np.dtype({'names': ['Name', 'Age', 'Height', 'Children/Pets'],\n                       'formats':'O int float int,int'.split()})\ndt\n\n\ns = np.array([('Smith', 45, 1.83, (0, 1)),\n                        ('Jones', 53, 1.72, (2, 2))], dtype=dt)\ns\n\n\ntype(s)\n\nIndexing\nThe single columns can now be easily accessed by their names and the rows by their index values.\n\ns['Name']\n\n\ns['Height'].mean()\n\n\ns[0]\n\n\ns[1]['Age']"
  },
  {
    "objectID": "lectures/lecture_07/numerical_computing.html#vectorized-programming",
    "href": "lectures/lecture_07/numerical_computing.html#vectorized-programming",
    "title": "Lecture 07 - Numerical Computing (NumPy)",
    "section": "4. Vectorized programming",
    "text": "4. Vectorized programming\nVectorization is a strategy to get more compact code that is possibly executed faster by simplifying the treatment and operations over array (vector) objects.\nThe fundamental idea is to conduct an operation on or to apply a function to a complex array object “at once” and not by looping over the single elements of the object.\nNumPy has vectorization built in deep down in its core.\n\nOperations\n\nr = np.arange(12).reshape((4, 3))\ns = np.arange(12).reshape((4, 3)) * 0.5\n\n\nr\n\n\ns\n\n\nr + s\n\n\nr + 3\n\n\n2 * r\n\n\n2 * r + 3\n\n\n\nRole of shapes\n\nr.shape\n\n\nr\n\n\ns = np.arange(0, 12, 4)\ns\n\n\ns.shape\n\n\nr + s\n\n\ns = np.arange(0, 12, 3)\n\n\ns.shape\n\n\nr + s\n\n\nr.transpose() + s\n\n\n\nApplying functions\n\ndef f(x):\n    return 3 * x + 5\n\n\nf(0.5)\n\n\nf(r)"
  },
  {
    "objectID": "lectures/lecture_07/numerical_computing.html#random-number-generation",
    "href": "lectures/lecture_07/numerical_computing.html#random-number-generation",
    "title": "Lecture 07 - Numerical Computing (NumPy)",
    "section": "5. Random number generation",
    "text": "5. Random number generation\nRandom number generation is often essential, particularly in simulations like Monte Carlo methods.\nNumPy provides a convenient and powerful way to generate random numbers through the np.random module.\n\nrand(): generates numbers between 0 and 1.\n\n\nnp.random.rand(5)\n\n\nrandn(): generates numbers with a mean of 0 and a standard deviation of 1 by default.\n\n\nnp.random.randn(5)\n\n\nnormal(mean, std, n): generates random n numbers from a normal distribution with mean and std\n\n\n# Simulate 10 days of daily returns with a mean of 0.001 and std deviation of 0.02\ndaily_returns = np.random.normal(0.001, 0.02, 10)\ndaily_returns\n\n\nrandint(): generates random integers\n\n\nnp.random.randint(1, 100, 5)"
  },
  {
    "objectID": "lectures/lecture_07/numerical_computing.html#applications",
    "href": "lectures/lecture_07/numerical_computing.html#applications",
    "title": "Lecture 07 - Numerical Computing (NumPy)",
    "section": "6. Applications",
    "text": "6. Applications\n\n6.1 Stock price simulations\n\nGeometric brownian motion\nIn finance, the Geometric Brownian Motion model is commonly used to simulate the future path of stock prices. The model is represented by the following equation:\n\\[\nS_{t+1} = S_t \\times e^{(\\mu - 0.5 \\times \\sigma^2) \\Delta t + \\sigma \\times \\epsilon \\times \\sqrt{\\Delta t}}\n\\]\nWhere: - $ S_t $ is the stock price at time $ t $ - $ $ is the expected return (mean) - $ $ is the volatility (standard deviation) - $ t $ is the time step (in days, for example) - $ $ is a random variable from a normal distribution\nExpressing as Log Returns\nTaking logs makes this additive:\n\\[\\ln\\frac{S_{t+\\Delta t}}{S_t}\n= (\\mu - 0.5\\sigma^2)\\Delta t + \\sigma \\epsilon_t \\sqrt{\\Delta t} = r_t\\]\nThis shows that log returns are normally distributed with: - Mean: \\((\\mu - 0.5\\sigma^2)\\Delta t\\) - Std. deviation: \\(\\sigma \\sqrt{\\Delta t}\\)\nPrice path\nThen, cumulative summation and exponentiation reconstruct the price path from \\(t=0\\) to \\(t=T\\):\n\\[S_T = S_0 \\, e^{\\sum r_t}\\]\n\n\nSimulating daily returns with NumPy\nLet’s simulate daily stock price returns over a one-year period (252 trading days).\nUsing NumPy, we can generate random normal values for the stock price fluctuations and compute the simulated prices.\n\nimport numpy as np\n\n# Parameters\nS0 = 100  # Initial stock price\nmu = 0.05  # Expected annual return\nsigma = 0.2  # Annual volatility\nT = 1  # Time horizon (in years)\nN = 252  # Number of trading days\ndt = T / N  # Time step (1 day)\n\n# Simulate random daily returns\ndaily_returns = np.random.normal((mu - 0.5 * sigma**2) * dt, sigma * np.sqrt(dt), N)\n\n# Simulate stock prices\nprices = S0 * np.exp(np.cumsum(daily_returns))\n\ndaily_returns = np.random.normal((mu - 0.5 * sigma**2) * dt, sigma * np.sqrt(dt), N)\nThis line generates random daily returns based on a normal distribution. - The mean of the distribution is adjusted by the term \\(\\mu - 0.5 \\sigma^2\\) to account for the fact that stock prices follow a geometric Brownian motion. - The standard deviation of the returns is \\(\\sigma \\sqrt{dt}\\) , which scales the annual volatility to daily volatility.\nprices = S0 * np.exp(np.cumsum(daily_returns))\nThis line calculates the simulated stock prices using the exponential function.\nIt does this by: - Using np.cumsum(daily_returns) to get the cumulative returns over time. The cumulative sum allows for the aggregation of daily returns into total returns. - The np.exp() function then exponentiates these cumulative returns, which translates them into price levels. - Finally, the initial stock price S0 is multiplied by the exponentiated cumulative returns to get the actual stock prices.\n\n# Plot the simulated stock prices\nimport matplotlib.pyplot as plt\nplt.plot(prices)\nplt.title('Simulated Stock Price Using Geometric Brownian Motion')\nplt.xlabel('Day')\nplt.ylabel('Price')\nplt.show()\n\n\n\n\n6.2 Portfolio optimization\nIn portfolio management, finance professionals must calculate the returns, risks, and correlations of assets to construct optimal portfolios.\nNumPy makes this task efficient and straightforward by offering matrix operations and linear algebra functions.\nLet’s assume a portfolio with three assets. We can calculate the expected portfolio return and risk using NumPy.\n\nThe function np.dot() returns the product of matrices.\n\nDefining the portfolio\n\n# Asset returns (annualized)\nasset_returns = np.array([0.08, 0.12, 0.15])\n\n# Covariance matrix of asset returns\ncov_matrix = np.array([[0.005, -0.002, 0.004],\n                       [-0.002, 0.010, -0.003],\n                       [0.004, -0.003, 0.015]])\n\n# Portfolio weights\nweights = np.array([0.4, 0.3, 0.3])\n\nComputing risk and return\n\n# Calculate portfolio return\nportfolio_return = np.dot(weights, asset_returns)\n\n# Calculate portfolio risk (standard deviation)\nportfolio_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n\nprint(f\"Expected Portfolio Return: {portfolio_return:.2%}\")\nprint(f\"Portfolio Risk (Standard Deviation): {portfolio_risk:.2%}\")\n\nportfolio_return = np.dot(weights, asset_returns)\nThe expected portfolio return is calculated using the dot product of the portfolio weights and the asset returns.\nThis calculation effectively gives the weighted average return of the assets in the portfolio.\nThe formula is:\n\\[\\text{Portfolio Return} = w_1 \\cdot r_1 + w_2 \\cdot r_2 + w_3 \\cdot r_3\\]\nIn this case:\n\\[\\text{Portfolio Return} = (0.4 \\times 0.08) + (0.3 \\times 0.12) + (0.3 \\times 0.15) = 0.104 \\text{ or } 10.4\\%\\]\nportfolio_risk = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\nThe portfolio risk is calculated using the covariance matrix and the portfolio weights.\nThis formula computes the standard deviation of the portfolio, reflecting its total risk:\n\\[\\text{Portfolio Risk} = \\sqrt{W^T \\Sigma W}\\]\nwhere: - \\(W\\) is the vector of weights. - \\(\\Sigma\\) is the covariance matrix. - The inner product np.dot(cov_matrix, weights) calculates the weighted covariance for each asset, and then the outer product with weights.T provides the total variance of the portfolio. The square root of this value gives the standard deviation.\n\n\n6.3 Risk analysis\nMonte Carlo simulations are widely used in finance to model the probability of different outcomes in uncertain environments.\nNumPy can be used to run a Monte Carlo simulation for portfolio returns.\n\n# Parameters for simulation\nn_simulations = 10000  # Number of simulations\nn_days = 252  # One year of trading days\nmean_return = 0.001  # Mean daily return\nstd_dev = 0.02  # Daily standard deviation\n\n# Simulate random daily returns for one year\nsimulated_returns = np.random.normal(mean_return, std_dev, (n_simulations, n_days))\n\n# Calculate cumulative returns for each simulation\ncumulative_returns = np.cumprod(1 + simulated_returns, axis=1)\n\n# Final value of each simulation\nfinal_values = cumulative_returns[:, -1]\n\nsimulated_returns = np.random.normal(mean_return, std_dev, (n_simulations, n_days))\nThis line generates a 2D array of random daily returns using a normal distribution. - Each row represents a separate simulation (one potential outcome for the year), and each column represents the daily returns for that simulation across 252 trading days. - The np.random.normal function takes the mean and standard deviation, generating random returns for each day in each simulation.\ncumulative_returns = np.cumprod(1 + simulated_returns, axis=1)\nThe cumulative returns are calculated by taking the product of the daily returns over time. - The expression 1 + simulated_returns adjusts the returns to represent growth factors (e.g., if the return is 0.01, the growth factor is 1.01). - The np.cumprod function computes the cumulative product along the specified axis (here, axis=1, which means across each simulation).\nfinal_values = cumulative_returns[:, -1]\nThis line extracts the final value of the portfolio at the end of the simulation period (after 252 days) for each of the 10,000 simulations. - cumulative_returns[:, -1] retrieves the last column of the cumulative returns matrix, representing the portfolio value after one year of trading.\n\n# Plot distribution of final values\nplt.hist(final_values, bins=50, edgecolor='k')\nplt.title('Monte Carlo Simulation of Portfolio Returns')\nplt.xlabel('Final Portfolio Value')\nplt.ylabel('Frequency')\nplt.show()"
  },
  {
    "objectID": "lectures/lecture_01/introduction_to_python.html",
    "href": "lectures/lecture_01/introduction_to_python.html",
    "title": "Lecture 01 - Introduction to Python",
    "section": "",
    "text": "Python is a high-level, interpreted programming language known for its simplicity and readability.\nKey Features of Python\n\nEasy to Learn: Python’s syntax is straightforward.\nInterpreted Language: Python code is executed line by line, which makes debugging easier.\nDynamically Typed: You don’t need to declare variable types explicitly; Python handles it automatically.\nVersatile: Python is used in web development, data analysis, automation, and much more.\nHuge Ecosystem: Python has a large standard library and third-party modules for a wide variety of applications.\n\n\n\n\n\nData Handling: In finance, you often work with large datasets—Python’s libraries like pandas and NumPy are designed to handle and analyze financial data efficiently.\nAutomation: Python can automate repetitive tasks like data retrieval, report generation, and portfolio analysis.\nFinancial Modeling: Python is a great tool for building complex models such as forecasting, risk management, and pricing.\nIntegration with Data Science: Python is the most popular language for data science, offering extensive support for statistical analysis, machine learning, and data visualization."
  },
  {
    "objectID": "lectures/lecture_01/introduction_to_python.html#what-is-python",
    "href": "lectures/lecture_01/introduction_to_python.html#what-is-python",
    "title": "Lecture 01 - Introduction to Python",
    "section": "",
    "text": "Python is a high-level, interpreted programming language known for its simplicity and readability.\nKey Features of Python\n\nEasy to Learn: Python’s syntax is straightforward.\nInterpreted Language: Python code is executed line by line, which makes debugging easier.\nDynamically Typed: You don’t need to declare variable types explicitly; Python handles it automatically.\nVersatile: Python is used in web development, data analysis, automation, and much more.\nHuge Ecosystem: Python has a large standard library and third-party modules for a wide variety of applications."
  },
  {
    "objectID": "lectures/lecture_01/introduction_to_python.html#why-python-for-finance",
    "href": "lectures/lecture_01/introduction_to_python.html#why-python-for-finance",
    "title": "Lecture 01 - Introduction to Python",
    "section": "",
    "text": "Data Handling: In finance, you often work with large datasets—Python’s libraries like pandas and NumPy are designed to handle and analyze financial data efficiently.\nAutomation: Python can automate repetitive tasks like data retrieval, report generation, and portfolio analysis.\nFinancial Modeling: Python is a great tool for building complex models such as forecasting, risk management, and pricing.\nIntegration with Data Science: Python is the most popular language for data science, offering extensive support for statistical analysis, machine learning, and data visualization."
  },
  {
    "objectID": "lectures/lecture_01/introduction_to_python.html#installing-a-python-environment",
    "href": "lectures/lecture_01/introduction_to_python.html#installing-a-python-environment",
    "title": "Lecture 01 - Introduction to Python",
    "section": "2.1 Installing a Python environment",
    "text": "2.1 Installing a Python environment\n\nPython\n\nDownload Python from the official website.\nInstallation includes the Python interpreter and Integrated Development Environment (IDLE) for coding.\n\n\n\nInstalling Anaconda\n\nAnaconda is a suite of useful tools and packages for Python development.\nDownload Anaconda from the official website\nOnce it is installed, confirm the following environments and packages are available:\n\nSpyder\nJupyter Notebook"
  },
  {
    "objectID": "lectures/lecture_01/introduction_to_python.html#running-python-code",
    "href": "lectures/lecture_01/introduction_to_python.html#running-python-code",
    "title": "Lecture 01 - Introduction to Python",
    "section": "2.2 Running Python Code",
    "text": "2.2 Running Python Code\nThere are multiple ways to run Python.\nConsider the following code line which instructs to simply print out “Hello World!”\n    print (\"Hello World!\")\n\nPython Shell\n\nUse the Python IDLE (from terminal of from any IDE setting like Spyder)\nType the code and press Enter\nCheck the output\n\n\n\nPython Script\n\nOpen an empty file (Spyder, Sublime Text Editor, etc.)\nWrite the code\nSave file as helloworld.py\nRun the script\n\nFrom the terminal, run the script by typing\n\n    python helloworld.py\n\nFrom the IDE (like Spyder), launch the run\n\nCheck the output\n\n\n\nNotebook\n\nThis is a Notebook\n\nPlatforms like Jupyter Notebooks are widely used in data science for documenting and running code interactively. - Open Jupyter Notebook by typing in the terminal\n    Jupyter Notebook\n\nCreat a new notebook with a Python environment\nWrite the code in the first cell\nRun the cell\nCheck the output (see below)\n\n\nprint ('Hello World!')"
  },
  {
    "objectID": "lectures/lecture_01/introduction_to_python.html#syntax",
    "href": "lectures/lecture_01/introduction_to_python.html#syntax",
    "title": "Lecture 01 - Introduction to Python",
    "section": "3.1 Syntax",
    "text": "3.1 Syntax\n\n3.1.1 Python as a calculator\n\n5000 + 250\n\n\n10000 * 1.05\n\n\n10000 / 2\n\nComments: Use comments (#) to explain code, particularly useful for documenting underlying logic.\n\n# Basic financial arithmetic\nprint(5000 + 250)    # Adding investment returns\nprint(10000 * 1.05)  # Calculating interest (5% growth)\nprint(10000 / 2) # Splitting an investment\n\n\n# This is a comment\nprint(\"Welcome to Python for Finance!\")  # This prints a message\n\n\n\n3.1.2 Variables and Data Types\n\nVariables\nVariables are store data for calculations\nThe operation = assigns a value to a variable.\n\n# Variable assignment in a financial scenario\nstock_price = 150.25  # Price of a stock\ninvestment_amount = 10000  # Amount invested\nshares = investment_amount / stock_price  # Number of shares\n\n\nshares\n\n\n\nData types\nVariables can be of different types.\n\nStrings (str): Text\nIntegers (int): Integer value\nFloats (float): Real value\nBooleans (bool): True or False\n\nBecause Python is dynamically typed, there is no need to explicitly mention the type of the variable. Yet, in some cases, it may be important to cast variables from one type to another.\nMore on this in the next lecture."
  },
  {
    "objectID": "lectures/lecture_01/introduction_to_python.html#control-structures",
    "href": "lectures/lecture_01/introduction_to_python.html#control-structures",
    "title": "Lecture 01 - Introduction to Python",
    "section": "3.2 Control structures",
    "text": "3.2 Control structures\nControl structures allow to condition the sequence of action of a code on the particular value a variable exhibits at the time of execution.\n\nConditional statements\nLoops\n\nNote: tabs are organizational pillars of the Python code structure\n\n3.2.1 Conditional statements\nConditional statements consider the specific value of a variable at the time of execution and determine the outcome based on a logical operation.\nStructure\n    If CONDITON HOLDS:\n        OUTCOME 1\n    Elif OTHER CONDITION HOLDS:\n        OUTCOME 2\n    Else:\n        OUTCOME 3\nNote: check the tabs\n\nbalance = 5000\nif balance &gt;= 10000:\n    print(\"You are eligible for premium services.\")\nelse:\n    print(\"Standard services apply.\")\n\n\n\n3.2.2 Loops\nLoops repeat a sequence of actions until a condition is satisfied. There are two types of loops:\n\nwhile\nfor\n\n\nWhile\nStructure\n    While CONDITION HOLDS:\n        ACTION(s)\n\n# Use case: Simulating monthly deposit growth\nbalance = 1000\nmonths = 0\nwhile balance &lt; 2000:\n    balance += 100  # Monthly deposit\n    months += 1\nprint(f\"It took {months} months to double the balance.\")\n\n\n\nFor\nStructure\n    For CONDITION HOLDS | Increment action:\n        ACTION(s)\n\n# Use case: Summing up daily returns from a list\ndaily_returns = [0.01, -0.02, 0.03, 0.02, -0.01]\ntotal_return = 0\nfor r in daily_returns:\n    total_return += r\nprint(\"Total return for the week:\", total_return)"
  },
  {
    "objectID": "lectures/lecture_01/introduction_to_python.html#functions",
    "href": "lectures/lecture_01/introduction_to_python.html#functions",
    "title": "Lecture 01 - Introduction to Python",
    "section": "3.3 Functions",
    "text": "3.3 Functions\nA function is a reusable block of code that is saved up and can be called at multiple places in the main script.\nStructure\n    def my_function (parameters):\n        ACTION(s)\n        return VALUE\n\n# Function to calculate compound interest\ndef calculate_compound_interest(principal, rate, time):\n    return principal * (1 + rate) ** time\n\n\n# Example usage\nresult = calculate_compound_interest(1000, 0.05, 5)\nprint(\"Compound Interest:\", result)"
  },
  {
    "objectID": "lectures/lecture_01/introduction_to_python.html#data-structures",
    "href": "lectures/lecture_01/introduction_to_python.html#data-structures",
    "title": "Lecture 01 - Introduction to Python",
    "section": "3.4 Data structures",
    "text": "3.4 Data structures\n\n3.4.1 Lists\nLists allow to store and treat mutliple data points into one variable\n\n# Example: List of daily stock prices\nstock_prices = [150.25, 153.50, 152.00, 155.00]\nprint(stock_prices[0])  # Accessing the first day's price\nstock_prices.append(157.25)  # Adding a new day's price\nprint(stock_prices)\n\n\n\n3.4.2 Dictionaries\nDictionnaries allow store and treat multiple pairs of data point associating keys and values.\n\n# Example: Dictionary to store portfolio allocation\nportfolio = {\n    \"AAPL\": 5000,\n    \"GOOGL\": 3000,\n    \"AMZN\": 2000\n}\nprint(portfolio[\"AAPL\"])  # Accessing allocation for AAPL\nportfolio[\"GOOGL\"] += 1000  # Updating allocation for GOOGL\nprint(portfolio)"
  },
  {
    "objectID": "lectures/lecture_01/introduction_to_python.html#libraries",
    "href": "lectures/lecture_01/introduction_to_python.html#libraries",
    "title": "Lecture 01 - Introduction to Python",
    "section": "3.5 Libraries",
    "text": "3.5 Libraries\nLibraries are pre-built packages of functions for tasks like data analysis and visualization.\n\nKey Libraries for Finance\n\nNumPy: For numerical computations matrix operations in portfolio analysis\npandas: Used for data manipulation handling financial datasets\nmatplotlib: For data visualization plotting stock prices\n\n\nimport numpy \n\nprint(numpy.sqrt(16))  # Square root\nprint(numpy.pi)        # Value of pi\n\n\n\nDocumentation\nLibraries come with documentation.\nOn Notebooks, they can be directly accessed from the cell pressing maj + tab after the function.\n\nExample of documentation numpy.sqrt()\n    Call signature:  numpy.sqrt(*args, **kwargs)\nType:            ufunc\nString form:     &lt;ufunc 'sqrt'&gt;\nFile:            ~/opt/anaconda3/lib/python3.9/site-packages/numpy/__init__.py\nDocstring:      \nsqrt(x, /, out=None, *, where=True, casting='same_kind', order='K', dtype=None, subok=True[, signature, extobj])\n\nReturn the non-negative square-root of an array, element-wise.\n\nParameters\n----------\nx : array_like\n    The values whose square-roots are required.\nout : ndarray, None, or tuple of ndarray and None, optional\n    A location into which the result is stored. If provided, it must have\n    a shape that the inputs broadcast to. If not provided or None,\n    a freshly-allocated array is returned. A tuple (possible only as a\n    keyword argument) must have length equal to the number of outputs.\nwhere : array_like, optional\n    This condition is broadcast over the input. At locations where the\n    condition is True, the `out` array will be set to the ufunc result.\n    Elsewhere, the `out` array will retain its original value.\n    Note that if an uninitialized `out` array is created via the default\n    ``out=None``, locations within it where the condition is False will\n    remain uninitialized.\n**kwargs\n    For other keyword-only arguments, see the\n    :ref:`ufunc docs &lt;ufuncs.kwargs&gt;`.\n\nReturns\n-------\ny : ndarray\n    An array of the same shape as `x`, containing the positive\n    square-root of each element in `x`.  If any element in `x` is\n    complex, a complex array is returned (and the square-roots of\n    negative reals are calculated).  If all of the elements in `x`\n    are real, so is `y`, with negative elements returning ``nan``.\n    If `out` was provided, `y` is a reference to it.\n    This is a scalar if `x` is a scalar.\n\nSee Also\n--------\nlib.scimath.sqrt\n    A version which returns complex numbers when given negative reals.\n\nNotes\n-----\n*sqrt* has--consistent with common convention--as its branch cut the\nreal \"interval\" [`-inf`, 0), and is continuous from above on it.\nA branch cut is a curve in the complex plane across which a given\ncomplex function fails to be continuous.\n\nExamples\n--------\n&gt;&gt;&gt; np.sqrt([1,4,9])\narray([ 1.,  2.,  3.])\n\n&gt;&gt;&gt; np.sqrt([4, -1, -3+4J])\narray([ 2.+0.j,  0.+1.j,  1.+2.j])\n\n&gt;&gt;&gt; np.sqrt([4, -1, np.inf])\narray([ 2., nan, inf])\nClass docstring:\nFunctions that operate element by element on whole arrays.\n\nTo see the documentation for a specific ufunc, use `info`.  For\nexample, ``np.info(np.sin)``.  Because ufuncs are written in C\n(for speed) and linked into Python with NumPy's ufunc facility,\nPython's help() function finds this page whenever help() is called\non a ufunc.\n\nA detailed explanation of ufuncs can be found in the docs for :ref:`ufuncs`.\n\n**Calling ufuncs:** ``op(*x[, out], where=True, **kwargs)``\n\nApply `op` to the arguments `*x` elementwise, broadcasting the arguments.\n\nThe broadcasting rules are:\n\n* Dimensions of length 1 may be prepended to either array.\n* Arrays may be repeated along dimensions of length 1.\n\nParameters\n----------\n*x : array_like\n    Input arrays.\nout : ndarray, None, or tuple of ndarray and None, optional\n    Alternate array object(s) in which to put the result; if provided, it\n    must have a shape that the inputs broadcast to. A tuple of arrays\n    (possible only as a keyword argument) must have length equal to the\n    number of outputs; use None for uninitialized outputs to be\n    allocated by the ufunc.\nwhere : array_like, optional\n    This condition is broadcast over the input. At locations where the\n    condition is True, the `out` array will be set to the ufunc result.\n    Elsewhere, the `out` array will retain its original value.\n    Note that if an uninitialized `out` array is created via the default\n    ``out=None``, locations within it where the condition is False will\n    remain uninitialized.\n**kwargs\n    For other keyword-only arguments, see the :ref:`ufunc docs &lt;ufuncs.kwargs&gt;`.\n\nReturns\n-------\nr : ndarray or tuple of ndarray\n    `r` will have the shape that the arrays in `x` broadcast to; if `out` is\n    provided, it will be returned. If not, `r` will be allocated and\n    may contain uninitialized values. If the function has more than one\n    output, then the result will be a tuple of arrays."
  },
  {
    "objectID": "lectures/lecture_06/lecture_06.html",
    "href": "lectures/lecture_06/lecture_06.html",
    "title": "Lecture 06 - Libraries",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_06/lecture_06.html#lecture-material",
    "href": "lectures/lecture_06/lecture_06.html#lecture-material",
    "title": "Lecture 06 - Libraries",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_06/lecture_06.html#recording",
    "href": "lectures/lecture_06/lecture_06.html#recording",
    "title": "Lecture 06 - Libraries",
    "section": "Recording",
    "text": "Recording"
  },
  {
    "objectID": "lectures/lecture_08/lecture_08_problem_set.html",
    "href": "lectures/lecture_08/lecture_08_problem_set.html",
    "title": "Data Manipulation (Pandas) - Problem set",
    "section": "",
    "text": "Create a DataFrame representing a portfolio of stocks with the following data: - Stock: [‘AAPL’, ‘GOOGL’, ‘MSFT’, ‘AMZN’] - Shares: [50, 30, 100, 10] - Price: [150.0, 2800.5, 299.0, 3500.75] - Sector: [‘Tech’, ‘Tech’, ‘Tech’, ‘Retail’]\nAdd a new column Total_Value representing the total value of each stock holding (Shares * Price).\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_08/lecture_08_problem_set.html#dataframe-creation-and-manipulation",
    "href": "lectures/lecture_08/lecture_08_problem_set.html#dataframe-creation-and-manipulation",
    "title": "Data Manipulation (Pandas) - Problem set",
    "section": "",
    "text": "Create a DataFrame representing a portfolio of stocks with the following data: - Stock: [‘AAPL’, ‘GOOGL’, ‘MSFT’, ‘AMZN’] - Shares: [50, 30, 100, 10] - Price: [150.0, 2800.5, 299.0, 3500.75] - Sector: [‘Tech’, ‘Tech’, ‘Tech’, ‘Retail’]\nAdd a new column Total_Value representing the total value of each stock holding (Shares * Price).\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_08/lecture_08_problem_set.html#advanced-selection",
    "href": "lectures/lecture_08/lecture_08_problem_set.html#advanced-selection",
    "title": "Data Manipulation (Pandas) - Problem set",
    "section": "2. Advanced Selection",
    "text": "2. Advanced Selection\nGiven a DataFrame of loan transactions with the following data: - Loan_Amount: [8000, 15000, 20000, 5000] - Interest_Rate: [0.06, 0.045, 0.03, 0.07]\nSelect all transactions where the loan amount is greater than $10,000 and the interest rate is below 5%.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_08/lecture_08_problem_set.html#missing-data-handling",
    "href": "lectures/lecture_08/lecture_08_problem_set.html#missing-data-handling",
    "title": "Data Manipulation (Pandas) - Problem set",
    "section": "3. Missing Data Handling",
    "text": "3. Missing Data Handling\nCreate a DataFrame with the following data: - Price: [100, None, 250, None] - Stock: [10, 20, None, 5]\nReplace all missing values in Price with the average price, and drop rows where Stock is missing.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_08/lecture_08_problem_set.html#groupby-and-aggregation",
    "href": "lectures/lecture_08/lecture_08_problem_set.html#groupby-and-aggregation",
    "title": "Data Manipulation (Pandas) - Problem set",
    "section": "4. GroupBy and Aggregation",
    "text": "4. GroupBy and Aggregation\nYou are given sales data for a company with the following data: - Region: [‘North’, ‘South’, ‘North’, ‘South’] - Salesperson: [‘John’, ‘Anna’, ‘John’, ‘Anna’] - Product: [‘A’, ‘B’, ‘C’, ‘A’] - Revenue: [500, 700, 800, 600]\nUse the GroupBy function to calculate the total revenue per region and per salesperson.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_08/lecture_08_problem_set.html#custom-functions-with-apply",
    "href": "lectures/lecture_08/lecture_08_problem_set.html#custom-functions-with-apply",
    "title": "Data Manipulation (Pandas) - Problem set",
    "section": "5. Custom Functions with Apply",
    "text": "5. Custom Functions with Apply\nCreate a DataFrame of customers with the following data: - Customer_ID: [‘C001’, ‘C002’, ‘C003’] - Transaction_Amount: [500, 2000, 1500] - Age: [22, 30, 45]\nUse the .apply() function to create a new column Eligibility that assigns ‘Eligible’ if the Transaction_Amount is greater than 1000 and the Age is above 25."
  },
  {
    "objectID": "lectures/lecture_08/lecture_08_problem_set.html#concatenation",
    "href": "lectures/lecture_08/lecture_08_problem_set.html#concatenation",
    "title": "Data Manipulation (Pandas) - Problem set",
    "section": "6. Concatenation",
    "text": "6. Concatenation\nYou have two DataFrames representing different departments’ sales figures: - df1: {‘Department’: [‘Sales’, ‘HR’], ‘Revenue’: [1000, 500]} - df2: {‘Department’: [‘IT’, ‘Finance’], ‘Revenue’: [1200, 800]}\nConcatenate the two DataFrames to create a combined dataset, ensuring no index duplication.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_08/lecture_08_problem_set.html#merging-dataframes",
    "href": "lectures/lecture_08/lecture_08_problem_set.html#merging-dataframes",
    "title": "Data Manipulation (Pandas) - Problem set",
    "section": "7. Merging DataFrames",
    "text": "7. Merging DataFrames\nYou are provided two DataFrames, one with customer details: - Customer_ID: [‘C001’, ‘C002’, ‘C003’] - Name: [‘John’, ‘Anna’, ‘Paul’] - Location: [‘NY’, ‘LA’, ‘SF’]\nAnd another with purchase details: - Customer_ID: [‘C001’, ‘C003’] - Purchase_Amount: [500, 700]\nMerge the two DataFrames on Customer_ID to analyze customer purchases.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_08/lecture_08_problem_set.html#datetime-manipulation",
    "href": "lectures/lecture_08/lecture_08_problem_set.html#datetime-manipulation",
    "title": "Data Manipulation (Pandas) - Problem set",
    "section": "8. DateTime Manipulation",
    "text": "8. DateTime Manipulation\nCreate a DataFrame with the following sales transaction data: - Date: [‘2023-01-01’, ‘2023-01-15’, ‘2023-02-01’] - Sales: [500, 700, 900]\nExtract the month and year from the Date column, and then group the sales data by month to calculate total monthly sales.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_08/lecture_08_problem_set.html#string-operations-with-series",
    "href": "lectures/lecture_08/lecture_08_problem_set.html#string-operations-with-series",
    "title": "Data Manipulation (Pandas) - Problem set",
    "section": "9. String Operations with Series",
    "text": "9. String Operations with Series\nGiven a Series of customer feedback comments: - [‘The service was excellent!’, ‘Poor response’, ‘Excellent work’]\nIdentify how many comments contain the word “excellent” (case-insensitive), and replace the word “poor” with “unsatisfactory”.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_08/lecture_08_problem_set.html#advanced-sorting",
    "href": "lectures/lecture_08/lecture_08_problem_set.html#advanced-sorting",
    "title": "Data Manipulation (Pandas) - Problem set",
    "section": "10. Advanced Sorting",
    "text": "10. Advanced Sorting\nCreate a `DataFrame` with the following product data:\n- `Product`: ['A', 'B', 'C']\n- `Price`: [10, 50, 30]\n- `Stock`: [100, 50, 200]\n\nSort the `DataFrame` first by `Stock` in descending order and then by `Price` in ascending order. What is the most expensive product with the highest stock?\n\n# Your code"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Course Information",
    "section": "",
    "text": "Professor: Tarik Roukny (tarik.roukny@kuleuven.be)\nLectures: Wednesdays\n\nTime blocks for sessions\n\n08.30 AM - 10.30 AM\n10.30 PM - 12.30 PM\n\nRoom HER1 - 04.4207\n\nOffice hours: by email appointment."
  },
  {
    "objectID": "syllabus.html#prerequisites",
    "href": "syllabus.html#prerequisites",
    "title": "Course Information",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis is a beginner’s course for programming: no prior computer skills are required\n\nKnowledge of statistics and basic econometrics is required\nKnowledge of Financial Markets and Institutions and Corporate Finance is advised"
  },
  {
    "objectID": "syllabus.html#content",
    "href": "syllabus.html#content",
    "title": "Course Information",
    "section": "Content",
    "text": "Content\n\nIntroduction to Scientific Programming\n\nProgramming Environment\nNotebooks\nBasics of Python Programming Language\n\nData Manipulation\n\nData Analytics\nData Treatment\nData Visualization\n\nApplying Data Science in Finance\n\nTime series\nNetwork Analysis\nMachine Learning"
  },
  {
    "objectID": "syllabus.html#delivery",
    "href": "syllabus.html#delivery",
    "title": "Course Information",
    "section": "Delivery",
    "text": "Delivery\nMaterial is delivered through Jupyter Notebooks. The presentation format of files is ‘.ipynb’ and can be read from the Jupyter interface or other services. Notebooks are interactive and can be used off-the-shell to run code. Static and printable version in pdf and HTML of the material are also available."
  },
  {
    "objectID": "syllabus.html#reference",
    "href": "syllabus.html#reference",
    "title": "Course Information",
    "section": "Reference",
    "text": "Reference\nPython for Finance, 2nd Edition by Yves Hilpisch"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science For Finance",
    "section": "",
    "text": "This website accompanies the course of Data Science For Finance (B-KUL-HMA99A)."
  },
  {
    "objectID": "index.html#news-announcements",
    "href": "index.html#news-announcements",
    "title": "Data Science For Finance",
    "section": "News & Announcements",
    "text": "News & Announcements\n\n18/11/2025\n\nRecordings for Lecture 11 are available\nSolutions to Problem set of Lecture 10 are available\n\n\n\n\n11/11/2025\n\nMaterial for Guest Lecture 10 is available\n\nNo Recording for Guest Lectures\n\n\n\n\n\n04/11/2025\n\nRecordings for Lecture 09 are available\n\n\n\n\n04/11/2025\n\nRecordings for Lecture 08 are available\nSolutions to Problem set of Lecture 07 are available\n\n\n\n\n20/10/2025\n\nRecordings for Lecture 07 are available\nSolutions to Problem set of Lecture 05 are available\n\n\n\n\n14/10/2025\n\nRecordings for Lecture 05 and 06 are available\nSolutions to Problem set of Lecture 03 and 04 are available\n\n\n\n\n07/10/2025\n\nRecordings for Lecture 03 and 04 are available\nSolutions to Problem set of Lecture 02 are available\nNew: A beta test All Day TA is available for the course.\n\nAll Day TA is an interactive AI tutor trained on the course material and synced with the course schedule for learning support.\n\n\n\n\n\n01/10/2025\n\nRecordings for Introduction, and Lecture 01 and 02 are available\nSolutions to Problem set of Lecture 02 will be available next week\n\n\n\n\n25/09/2025\n\nThe course is live\nMaterial for Lecture 01 and 02 is available"
  },
  {
    "objectID": "lectures/lecture_08/data_manipulation.html",
    "href": "lectures/lecture_08/data_manipulation.html",
    "title": "Lecture 08 - Data Manipulation (Pandas)",
    "section": "",
    "text": "What is pandas?\n\nPandas is a powerful Python library used for data manipulation and analysis.\nIt provides two main data structures: Series (1D) and DataFrame (2D), which are ideal for working with structured data, similar to Excel spreadsheets or SQL tables.\n\nWhy pandas for Finance?\n\nExploratory Data Analysis (EDA): large and structured financial datasets that require cleaning, manipulation, and analysis.\nEfficiency: Pandas can handle millions of rows of financial data efficiently.\nIntegration with Data Science: Pandas works seamlessly with other libraries like NumPy and matplotlib for numerical operations and visualization, essential for financial modeling.\n\nThis notebook covers: - DataFrame and Series classes - Basic operations with Pandas - GroupBy, complex selection and data combinations\n\nimport pandas as pd\nimport numpy as np"
  },
  {
    "objectID": "lectures/lecture_08/data_manipulation.html#overview",
    "href": "lectures/lecture_08/data_manipulation.html#overview",
    "title": "Lecture 08 - Data Manipulation (Pandas)",
    "section": "",
    "text": "What is pandas?\n\nPandas is a powerful Python library used for data manipulation and analysis.\nIt provides two main data structures: Series (1D) and DataFrame (2D), which are ideal for working with structured data, similar to Excel spreadsheets or SQL tables.\n\nWhy pandas for Finance?\n\nExploratory Data Analysis (EDA): large and structured financial datasets that require cleaning, manipulation, and analysis.\nEfficiency: Pandas can handle millions of rows of financial data efficiently.\nIntegration with Data Science: Pandas works seamlessly with other libraries like NumPy and matplotlib for numerical operations and visualization, essential for financial modeling.\n\nThis notebook covers: - DataFrame and Series classes - Basic operations with Pandas - GroupBy, complex selection and data combinations\n\nimport pandas as pd\nimport numpy as np"
  },
  {
    "objectID": "lectures/lecture_08/data_manipulation.html#the-dataframe-class",
    "href": "lectures/lecture_08/data_manipulation.html#the-dataframe-class",
    "title": "Lecture 08 - Data Manipulation (Pandas)",
    "section": "1. The DataFrame Class",
    "text": "1. The DataFrame Class\nAt the core of Pandas is the DataFrame, a class designed to efficiently handle data in tabular form —i.e., data characterized by a columnar organization.\n\nA DataFrame in pandas is a two-dimensional, labeled data structure that organizes and manipulates structured data\nDataFrames consist of rows and columns, where each column can contain different types of data (integers, floats, strings, etc.).\n\nLike a table in a relational database or an Excel sheet.\n\n\n\n1.1 Creating a DataFrame\nThe pd.DataFrame() function in pandas creates DataFrames.\npd.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)\n\ndata: Data to populate the DataFrame\nindex: Index labels for the rows (optional).\ncolumns: Column labels (optional).\ndtype: Data type for the elements (optional).\ncopy: Whether to copy the input data (optional).\n\nThere are several ways to create a DataFrame. - from scratch using lists or dictionaries - from reading external files (CSV, Excel, SQL databases).\n\nFrom a list\n\n# Creating a DataFrame from a list\ndata = [10, 20, 30, 40]\ndf = pd.DataFrame(data, columns=['numbers'], index=['a', 'b', 'c', 'd'])\n\n\n# Displaying the DataFrame\nprint(df)\n\nIn this example:\n\nThe data list contains values for a single column.\nThe columns parameter labels the column, and the index parameter sets row labels.\n\nOnce a DataFrame is instantiated, one can observe its meta structure.\n\ndf.index\n\n\ndf.columns\n\n\n\nFrom a dictionary\nA DataFrame can be sourced from a dictionary, where keys are column names and values are lists of column data.\n\ndata = {\n    'Product': ['A', 'B', 'C', 'D'],\n    'Price': [100, 150, 200, 250],\n    'Stock': [50, 60, 70, 80]\n}\n\ndf = pd.DataFrame(data)\n\n# Displaying the DataFrame\nprint(df)\n\n\n\nFrom external sources\nDataFrames can also be created by reading data from external files such as CSVs, Excel files, or databases.\n# Reading from a CSV file\ndf = pd.read_csv('file.csv')\n\n# Reading from an Excel file\ndf = pd.read_excel('file.xlsx')\nMore on this in next lecture…\n\n\n\n1.2 Accessing a DataFrame\nOnce a DataFrame is created, one can access\n- columns - rows - specific subsets of data\n\nAccessing columns\nAccess to columns can be done directly by referring the column like in a dictionary.\n\n# Accessing a single column\ndf['Product']\n\n\n# Accessing multiple columns\ndf[['Product', 'Price']]\n\n\n\nAccessing rows\nAccess to rows can be done by index (.loc[]) or position (.iloc[])\n\ndf\n\n\n# Accessing by label\ndf.loc[1]  # Retrieves the row with index 1\n\n\n# Accessing by position\ndf.iloc[2]  # Retrieves the third row (index 2)\n\n\n\nSelecting multiple rows\nA range of rows or a specific set of rows can be selected by combining .loc[] or .iloc[] with slicing or lists.\n\n# Accessing multiple rows by label\ndf.loc[1:3]\n\n\n# Accessing multiple rows by position\ndf.iloc[0:2]  \n\n\n# Accessing multiple rows by list\nindeces = [1,3]\ndf.loc[indeces]\n\n\n\n\n1.3 Editing a DataFrame\nDataFrames are live objects which allow for adding, deleting or modifying data (columns or rows) on the fly.\n\nInitialization\n\ndata = {\n    'Product': ['A', 'B', 'C', 'D'],\n    'Price': [110, 160, 210, 260],\n    'Stock': [50, 60, 70, 80],\n}\ndf = pd.DataFrame(data)\n\n\n\nEditing columns\n\nAdding\nModifying\nDeleting\n\n\nAdding columns\n\nInternal product\n\n\n# Adding a new column\ndf['Discounted_Price'] = df['Price'] * 0.9\nprint(df)\n\n\nfrom list\n\nThe length of the list should match the number of rows in the DataFrame.\n\n\n\n# Adding a new column 'Tax' using a list\ndf['Tax'] = [10.5, 15.0, 19.5, 24.0]\nprint(df)\n\n\n# Displaying the 'Tax' column\nprint(df['Tax'])\n\n\nfrom DataFrame\n\nIndices must match between the original DataFrame and the new column.\n\n\n\n# Adding a new column 'Supplier' based on another DataFrame\ndf['Supplier'] = pd.DataFrame(['Supplier1', 'Supplier2', 'Supplier3', 'Supplier4'], \n                              index=[0, 1, 2, 3])\nprint(df)\n\nAfter enlarging a DataFrame, it’s also essential to check the data types of each column to ensure everything is in order.\n\n# Checking the data types of the DataFrame columns\nprint(df.dtypes)\n\n\n\nModifying columns\n\n# Modifying an existing column\ndf['Price'] = df['Price'] + 10\nprint(df)\n\n\n\nDeleting columns\nRemoving columns can be done using the .drop() method.\n\n# Dropping the 'Discounted_Price' column\ndf_dropped = df.drop(columns=['Discounted_Price'])\nprint(df_dropped)\n\n\n\n\nEditing rows\n\nAdding\nModifying\nDeleting\n\n\nAdding rows\n\nappend()\n\nSingle row\nHowever, note that append() is deprecated, and should be replaced using pd.concat() instead in future pandas versions.\n\n\n\n# Appending a new row to the DataFrame\ndf_appended = df.append({'Product': 'E', 'Price': 300, 'Stock': 90, \n                'Discounted_Price': 270.0, 'Tax': 30.0, 'Supplier': 'Supplier5'}, \n               ignore_index=True)\nprint(df_appended)\n\n\nconcat()\n\n\n# New row as a DataFrame\nnew_row = pd.DataFrame({\n    'Product': ['E'],\n    'Price': [300],\n    'Stock': [90],\n    'Discounted_Price': [270.0],\n    'Tax': [30.0],\n    'Supplier': ['Supplier5']\n})\n\n# Using pd.concat() to append the new row\ndf_concated = pd.concat([df, new_row], ignore_index=True)\n\n# Display the updated DataFrame\nprint(df_concated)\n\nMore on concat() in section 6. Concatenation, Join, Merge and below on indexing\n\n\nModifying rows\n\n# Modifying an existing row\ndf.loc[1, 'Price'] = 180\ndf.loc[1, 'Stock'] = 200\n\n\nprint(df)\n\n\n\nDeleting rows\n\nRows can be removed from a DataFrame using the .drop() method either by index or by condition.\n\n\n# Dropping a row by index\ndf_dropped = df.drop(index=2)  # Dropping the row with index 2 (Product C)\nprint(df_dropped)\n\n\n# Dropping rows where Stock is greater than 80\ndf_dropped = df[df['Stock'] &lt;= 80]\nprint(df_dropped)\n\n\n\n\nIndexing\nWhen appending rows to a DataFrame, it’s important to pay attention to the treatment of indices.\n\nIndexing with concat()\n\nWhen concatenating two or more DataFrames, the default behavior is to retain the original index of the DataFrames, which can lead to duplicate indices.\nThe ignore_index=True parameter resets the index for the concatenated DataFrame to ensure a continuous sequence.\n\n\n\n# New DataFrame to concatenate\ndf_new = pd.DataFrame({\n    'Product': ['F', 'G'],\n    'Price': [350, 400],\n    'Stock': [95, 100],\n    'Discounted_Price': [315.0, 360.0],\n    'Tax': [35.0, 40.0],\n    'Supplier': ['Supplier6', 'Supplier7']\n})\n\n\n# Concatenating the two DataFrames without resetting the index\ndf_concat = pd.concat([df, df_new])\nprint(df_concat)\n\n\n# Concatenating with index reset\ndf_concat_reset = pd.concat([df, df_new], ignore_index=True)\nprint(df_concat_reset)\n\n\nIndexing with append()\n\nWhen appending, the new row needs to adopt the next available index by default (ignore_index = True), else does not proceed.\n\n\n\n# Appending a single row with a new product using append()\nnew_row = {\n    'Product': 'H', \n    'Price': 450, \n    'Stock': 105, \n    'Price_Squared': 202500, \n    'Discounted_Price': 405.0, \n    'Tax': 45.0, \n    'Supplier': 'Supplier8'\n}\n\ndf_appended = df.append(new_row, ignore_index = True)\n\nprint(df_appended)\n\n\n\n\n1.4 Handling missing data\nMissing data is common in real-world datasets, and pandas provides tools to handle them.\n\n# Adding missing values (NaN) to some cells\ndf.loc[1, 'Price'] = np.nan  # Missing price for product B\ndf.loc[2, 'Discounted_Price'] = np.nan  # Missing discounted price for product C\ndf.loc[3, 'Stock'] = np.nan  # Missing stock for product D\n\n\nprint (df)\n\n\ndf.isna(): Detects missing values\n\n\ndf.isna()\n\n\ndf.fillna(a): Fils missing values with a default\n\n\ndf.fillna(0)\n\n\ndf.dropna(): Drops rows with missing values\n\n\ndf.dropna()\n\n\nOperations with missing data\nPandas method calls handle missing data\n\ndf\n\n\ndf[['Price', 'Stock']].mean()\n\n\ndf[['Price', 'Stock']].std()\n\n\n\n\n1.5 Sorting Data\nDataFrame can be sorted based on any column using the .sort_values() method.\n\n# Sorting by 'Price' in ascending order\ndf_sorted = df.sort_values(by='Price')\n\n\nprint (df_sorted)\n\n\n# Sorting by sequence of multiple columns: first stock, than price\ndf.loc[3,'Stock'] = df.loc[2,'Stock']\ndf_sorted = df.sort_values(by=['Stock', 'Price'], ascending=[False, True])\n\n\nprint (df_sorted)\n\n\n\n1.6 Libraries integration\nPandas integrates the manipulation of objects from other classes such as numpy and datetime objects.\n\nNumPy\n\n\nimport numpy as np\nnp.random.seed(100)\na = np.random.standard_normal((9,4))\na\n\n\ndf_n = pd.DataFrame(a)\ndf_n.columns = ['No1', 'No2', 'No3', 'No4']\ndf_n\n\n\ndf_n['No2'].mean()\n\n\nDateTime\n\n\ndates = pd.date_range('2019-1-1', periods = 9, freq = 'M')\ndates\n\n\ndf_n.index = dates\ndf_n\n\n\ndf_n.values"
  },
  {
    "objectID": "lectures/lecture_08/data_manipulation.html#checkpoint",
    "href": "lectures/lecture_08/data_manipulation.html#checkpoint",
    "title": "Lecture 08 - Data Manipulation (Pandas)",
    "section": "🚦Checkpoint",
    "text": "🚦Checkpoint\nTask: 1. Create a DataFrame with the following columns: Item, Price, Quantity using the following dictionary\n    data = {\n    'Item': ['Apple', 'Banana', 'Orange'],\n    'Price': [1.0, 0.5, 0.75],\n    'Quantity': [10, 5, 8]\n        }\n\nAdd a new column Total that calculates the total price by multiplying Price and Quantity.\nAdd a column called Discount with values [0.1, 0.05, 0.2] to the existing DataFrame.\nUpdate the Total column to apply the discount to the total price."
  },
  {
    "objectID": "lectures/lecture_08/data_manipulation.html#basic-analytics",
    "href": "lectures/lecture_08/data_manipulation.html#basic-analytics",
    "title": "Lecture 08 - Data Manipulation (Pandas)",
    "section": "2. Basic Analytics",
    "text": "2. Basic Analytics\nWhen working with data in pandas, the library provides several built-in methods that make data exploration and analysis efficient.\nThese methods help with - Inspection - Summaries - Statistics - Data operations - Visualization\n\n2.1 Inspection and summary\n\ndf.info(): Provides a concise summary of the DataFrame, including the number of entries, column names, data types, and memory usage.\n\n\ndf.info()\n\n\ndf.head(): Returns the first few rows of the DataFrame (by default, the first 5 rows).\n\n\ndf.head()  # By default, displays the first 5 rows\n\n\ndf.head(10)  # Displays the first 10 rows\n\n\ndf.tail(): Similar to df.head(), but returns the last few rows of the DataFrame.\n\n\ndf.tail()  # By default, displays the last 5 rows\n\n\ndf.describe(): Generates descriptive statistics for numerical columns, including count, mean, standard deviation, minimum, and maximum values, as well as the 25th, 50th, and 75th percentiles.\n\n\ndf\n\n\ndf.describe()\n\n\n\n2.2 Statistics and operations\n\ndf.sum()\ndf.mean()\n\n\ndf[['Price','Stock']].mean()  # By default, computes the mean of each column\n\n\ndf[['Price','Stock']].mean(axis=0)  # Mean across columns (default behavior)\n\n\ndf[['Price','Stock']].mean(axis=1)  # Mean across rows\n\n\ndf.cumsum()\n\n\ndf.cumsum()\n\n\ndf.apply(): Custom functions can be applied to columns or rows using the .apply() method.\n\n\n# Applying a lambda function to square the values in 'Price' column\ndf['Price'].apply(lambda x: x ** 2)\n\n\n\n2.3 Integrated NumPy Functions\nPandas integrates with NumPy, allowing the use of NumPy functions directly on DataFrames.\n\nnp.mean(df)\n\n\nnp.mean(df[['Price','Stock']])\n\n\nnp.log(df)\n\n\nnp.log(df)\n\n\nnp.sqrt(abs(df))\n\n\nnp.sqrt(abs(df))\n\n\nnp.sqrt(abs(df)).sum()\n\n\n\n2.4 Basic Visualization\nPandas integrates with visualization libraries like matplotlib to enable quick visualizations of data.\n\nSetting up Matplotlib for Visualization\n\nfrom pylab import plt, mpl\n\n# Setting the style to 'seaborn' for better aesthetics\nplt.style.use('seaborn')\n\n# Setting the default font to 'serif' for a clean look\nmpl.rcParams['font.family'] = 'serif'\n\n# Ensure plots are displayed inline in Jupyter notebooks\n%matplotlib inline\n\n\n\nExamples\n\ndf.cumsum().plot(lw=2.0, figsize=(10, 6))  # Line width set to 2.0 and figure size to 10x6\n\n\ndf.plot(kind='bar', figsize=(10, 6))  # Generates a bar plot with a figure size of 10x6"
  },
  {
    "objectID": "lectures/lecture_08/data_manipulation.html#the-series-class",
    "href": "lectures/lecture_08/data_manipulation.html#the-series-class",
    "title": "Lecture 08 - Data Manipulation (Pandas)",
    "section": "3. The Series Class",
    "text": "3. The Series Class\nThe Series class in pandas is a one-dimensional labeled array capable of holding any data type.\nA Series is essentially a single column of data, making it a simpler, more specialized version of the DataFrame class. It shares many characteristics and methods with DataFrame and adds more specifics techniques.\n\n3.1 Creating a Series\nA Series object can be created directly or obtained by selecting a single column from a DataFrame.\n\nFrom list\n\n\n# Creating a Series with evenly spaced numbers between 0 and 15\ns = pd.Series(np.linspace(0, 15, 7), name='series')\nprint(s)\n\n\n# Checking the type of the Series\ntype(s)\n\n\nFrom DataFrame\n\nSelecting a single column from a DataFrame result in a Series.\n\n# Selecting a column from the DataFrame as a Series\ns = df_n['No1']\nprint(s)\n\n\n# Checking the type\ntype(s)\n\n\n\n3.2 Methods for Series\n\nInherited methods\nMost of the methods available for DataFrame are also available for Series, such as mean(), or plot().\n\n# Calculating the mean of the Series\ns.mean()\n\n\n# Plotting the Series\ns.plot(lw=2.0, figsize=(10, 6))  # Line width set to 2.0 and figure size to 10x6\n\n\n\nSeries specific methods\nThere are several methods that are specific to Series objects.\nThese methods are designed to leverage the one-dimensional nature of a Series and simplify certain operations that are less intuitive or applicable in a two-dimensional DataFrame.\n\nSeries.value_counts(): Returns the count of unique values in a Series.\n\nUseful when working with categorical data or needing to understand the frequency of certain values.\n\n\n\n# Example of value_counts\ns = pd.Series(['A', 'B', 'A', 'C', 'B', 'A'])\ns.value_counts()\n\n\nSeries.unique(): Returns an array of the unique values in a Series.\n\nIt helps identify distinct values in a column of data.\n\n\n\n# Example of unique\ns = pd.Series([1, 2, 2, 3, 4, 4, 4])\ns.unique()\n\n\nSeries.nunique(): Returns the number of unique values in a Series.\n\nSimilar to value_counts() but only provides the total number of unique elements, not their frequency.\n\n\n\n# Example of nunique\ns = pd.Series([1, 2, 2, 3, 4, 4, 4])\ns.nunique()\n\n\nSeries.str accessor: performs string operations.\n\nThis feature is unique to Series and makes it easy to manipulate text data in bulk.\nThese include .str.upper(), .str.contains(), .str.replace(), and .str.len()\n\n\n\n# Sample Series of strings\ns = pd.Series(['apple', 'banana', 'pear'])\n\n\n# Convert all strings to uppercase\ns_upper = s.str.upper()\nprint(s_upper)\n\n\n# Check if each string contains the letter 'a'\ns_contains = s.str.contains('a')\nprint(s_contains)\n\n\n# Replace 'a' with 'o' in each string\ns_replace = s.str.replace('a', 'o')\nprint(s_replace)\n\n\n# Get the length of each string\ns_len = s.str.len()\nprint(s_len)\n\n\nSeries.dt accessor: performs datetime-specific operations.\n\nThis makes it easy to extract year, month, day, or other components from a datetime Series.\nThese include dt.day, .dt.year, .dt.month, and .dt.weekday.\n\n\n\n# Example of dt accessor\ns = pd.Series(pd.date_range('2023-01-01', periods=3, freq='D'))\ns.dt.day  # Extract the day from the datetime\n\n\nSeries.isin(): Checks whether each element of the Series is in a given list of values and returns a boolean Series.\n\n\n# Example of isin\ns = pd.Series(['A', 'B', 'C', 'D'])\ns.isin(['B', 'C', 'E'])\n\n\nSeries.idxmax() and Series.idxmin(): Return the index of the maximum or minimum value in the Series, respectively.\n\n\n# Example of idxmax and idxmin\ns = pd.Series([1, 5, 3, 9, 2])\nprint(s.idxmax())  # Index of the maximum value\nprint(s.idxmin())  # Index of the minimum value"
  },
  {
    "objectID": "lectures/lecture_08/data_manipulation.html#checkpoint-1",
    "href": "lectures/lecture_08/data_manipulation.html#checkpoint-1",
    "title": "Lecture 08 - Data Manipulation (Pandas)",
    "section": "🚦Checkpoint",
    "text": "🚦Checkpoint\nTask: 1. Create a pandas Series from a list of stock prices: [150.25, 153.50, 2800.50, 2830.75, 3400.00, 3450.50] and name the Series Stock_Prices.\n\nUsing the Stock_Prices series:\n\nFind the maximum price in the series.\nFind the minimum price in the series.\nCalculate the mean (average) price.\nFind how many stock prices are above the mean.\nCreate a new Series where each stock price is increased by 5%.\nNormalize the Series so that all values are between 0 and 1 (i.e., subtract the minimum and divide by the range).\n\nCreate another pandas Series from the list [0.05, 0.03, 0.02, 0.04, 0.01, 0.06] and name it Stock_Changes.\nThis series represents the daily percentage changes for each stock (assume all changes are positive and range between 0.01 to 0.10).\n\nMultiply the Stock_Prices by the Stock_Changes Series.\nCreate a new Series called Updated_Prices which contains the new stock prices after applying the percentage changes.\n\nCreate a new Series that categorizes stock prices in Updated_Prices as either “High” if the price is above 3000, or “Low” if the price is below 3000.\nCheck if any of the original Stock_Prices are in this list: [153.50, 2830.75, 5000.00] and return a boolean Series indicating whether each price is present in this list.\nCount how many times each category (“High” or “Low”) appears in the price_categories Series from step 4."
  },
  {
    "objectID": "lectures/lecture_08/data_manipulation.html#groupby-operations",
    "href": "lectures/lecture_08/data_manipulation.html#groupby-operations",
    "title": "Lecture 08 - Data Manipulation (Pandas)",
    "section": "4. GroupBy Operations",
    "text": "4. GroupBy Operations\nPandas provides powerful and flexible grouping capabilities that function similarly to SQL groupings and pivot tables in Excel.\nGrouping is often used when performing aggregations or applying specific operations to subsets of data.\n\nInitialization\n\n# Creating a sample financial DataFrame\ndata = {\n    'Stock': ['AAPL', 'AAPL', 'GOOGL', 'GOOGL', 'AMZN', 'AMZN', 'AAPL', 'GOOGL', 'AMZN'],\n    'Quarter': ['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2', 'Q3', 'Q3', 'Q3'],\n    'Price': [150.25, 153.50, 2800.50, 2830.75, 3400.00, 3450.50, 155.30, 2900.75, 3500.75],\n    'Volume': [1000, 1100, 1500, 1600, 1700, 1800, 1200, 1700, 2000],\n    'Market_Cap': [2.41e12, 2.45e12, 1.78e12, 1.82e12, 1.71e12, 1.75e12, 2.50e12, 1.85e12, 1.80e12]\n}\n\ndf = pd.DataFrame(data)\ndf \n\n\n\n4.1 Simple grouping\nSimple grouping of a DataFrame using .groupby() is done on a specific column which then allows to perform basic operations on each group.\n\ngroups = df.groupby('Quarter')\n\n\nInspection\n\n.size(): checks how many records belong to each group\n\n\ngroups.size()\n\n\n\nBasic Operations on Groups\nGroups can perform simple aggregate functions - .mean(): compute the average value of given columns for each group.\n\ngroups[['Price', 'Volume']].mean()\n\n\n.max(): shows the maximum for given columns for each group.\n\n\ngroups[['Price', 'Volume']].max()\n\n\n\nAggregating Multiple Functions at Once\nThe .aggregate() methods obtains multiple aggregate functions to summarize data.\n\ngroups[['Price', 'Volume']].aggregate(['min', 'max']).round(2)\n\n\n\n\n4.2 Grouping by multiple columns\n\ngroups = df.groupby(['Quarter', 'Stock'])\n\n\ngroups.size()\n\n\n\n4.3 Advanced grouping example\n\nAggregations on Multiple Groups\nAfter grouping by multiple column, one can perform multiple operations, such as summing and calculating the mean for specific columns\n\ngroups[['Price', 'Volume']].aggregate(['sum', 'mean'])\n\n\n\nCalculating market share\nGoal: calculate each stock’s market share in a specific quarter. - Compute the market share of each stock by dividing its market cap by the total market cap of all stocks in that quarter.\n\ndf['Market_Share'] = df.groupby('Quarter')['Market_Cap'].transform(lambda x: x / x.sum())\ndf[['Stock', 'Quarter', 'Market_Share']]\n\n\nStep by step\n\nStep 1: Grouping by Quarter\n\nWe are using the groupby() function to group the data by the Quarter column:\ndf.groupby('Quarter')\nThis groups the rows in the DataFrame based on the values in the Quarter column. This means that all stocks from the same quarter will be grouped together.\n\nStep 2: Applying the Aggregation\n\nNext, we focus on the Market_Cap column within each quarter. This is done using:\ndf.groupby('Quarter')['Market_Cap']\nHere, we are selecting the Market_Cap values for each group (each quarter). We now want to calculate the market share for each stock within its respective quarter.\n\nStep 3: Calculating Market Share with transform()\n\nThe custom operation is a lambda function that computes the market share:\nlambda x: x / x.sum()\nThis lambda function divides each stock’s market capitalization (x) by the total market capitalization of all stocks in the same quarter (x.sum()).\n\nx represents the Market_Cap values for the group (all stocks in a given quarter).\nx.sum() calculates the total market capitalization for that quarter.\nThe lambda function then divides each stock’s market capitalization by the total, which gives the proportion (or market share) of that stock relative to the total market capitalization in the quarter.\nStep 4: Assigning the Market Share to a New Column\n\nThe result of this operation is assigned to a new column in the DataFrame called Market_Share:\ndf['Market_Share'] = ...\nNow, each row in the DataFrame will have a Market_Share value representing the percentage of the total market capitalization that each stock holds within its respective quarter."
  },
  {
    "objectID": "lectures/lecture_08/data_manipulation.html#checkpoint-2",
    "href": "lectures/lecture_08/data_manipulation.html#checkpoint-2",
    "title": "Lecture 08 - Data Manipulation (Pandas)",
    "section": "🚦Checkpoint",
    "text": "🚦Checkpoint\nTask: 1. Create a DataFrame with columns: Employee, Department, Salary from\n    data = {\n    'Employee': ['John', 'Jane', 'Peter', 'Lucy'],\n    'Department': ['HR', 'HR', 'IT', 'IT'],\n    'Salary': [50000, 60000, 70000, 80000]\n    }\n\nCalculate the average salary per department."
  },
  {
    "objectID": "lectures/lecture_08/data_manipulation.html#complex-selection",
    "href": "lectures/lecture_08/data_manipulation.html#complex-selection",
    "title": "Lecture 08 - Data Manipulation (Pandas)",
    "section": "5. Complex Selection",
    "text": "5. Complex Selection\nIn pandas, data selection involves formulating conditions based on column values and combining multiple conditions logically.\n\nInitialization\n\nimport numpy as np\n\n# Creating a DataFrame with random financial data\ndata = {\n    'Transaction_Amount': np.random.uniform(-500, 1500, 10),  # Random transaction amounts between -500 and 1500\n    'Interest_Rate': np.random.uniform(0.01, 0.15, 10),       # Random interest rates between 1% and 15%\n    'Loan_Amount': np.random.uniform(1000, 20000, 10),         # Random loan amounts between 1000 and 20000\n}\n\ndf = pd.DataFrame(data)\n\n\ndf.info()  # Display information about the DataFrame\n\n\ndf.head()  # Display the first few rows\n\n\n\n5.1 Conditions\nConditions based on the values in the DataFrame columns:\n\nSingle Condition: Selecting transactions greater than a specified amount:\n\n\ncondition1 = df['Transaction_Amount'] &gt; 0\n\n\nMultiple Conditions: Using logical operators to combine conditions:\n\n\nAND Condition: Selecting rows where the transaction amount is positive and the interest rate is less than 0.1:\n\n\ncondition2 = (df['Transaction_Amount'] &gt; 0) & (df['Interest_Rate'] &lt; 0.1)\n\n\nOR Condition: Selecting rows where the transaction amount is positive or the interest rate is less than 0.05:\n\n\ncondition3 = (df['Transaction_Amount'] &gt; 0) | (df['Interest_Rate'] &lt; 0.05)\n\n\nCondition on All Values: Checking for all positive values in the DataFrame:\n\n\ncondition4 = df &gt; 0\n\n\n\n5.2 Conditional Selection\nCondition-based selection of data from the DataFrame.\n\nSelect rows where Transaction_Amount is greater than 0:\n\n\npositive_transactions = df[df['Transaction_Amount'] &gt; 0]\nprint (positive_transactions)\n\n\ncondition1\n\n\nSelect rows where Transaction_Amount is positive and Interest_Rate is less than 0.1:\n\n\nfiltered_transactions = df[(df['Transaction_Amount'] &gt; 0) & (df['Interest_Rate'] &lt; 0.1)]\nprint (filtered_transactions)\n\n\ndf[condition2]\n\n\nSelect rows where either Transaction_Amount is positive or Interest_Rate is less than 0.05:\n\n\nselected_transactions = df[(df['Transaction_Amount'] &gt; 0) | (df['Interest_Rate'] &lt; 0.05)]\n\n\nSelect all positive values from the DataFrame:\n\n\ndf[df &gt; 0]"
  },
  {
    "objectID": "lectures/lecture_08/data_manipulation.html#checkpoint-3",
    "href": "lectures/lecture_08/data_manipulation.html#checkpoint-3",
    "title": "Lecture 08 - Data Manipulation (Pandas)",
    "section": "🚦Checkpoint",
    "text": "🚦Checkpoint\nTask: 1. Create a DataFrame with columns Age, Income from\n    data = {\n        'Age': [25, 35, 45, 50],\n        'Income': [40000, 60000, 70000, 30000]\n    }\n\nSelect rows where Age &gt; 30 and Income &gt; 50000."
  },
  {
    "objectID": "lectures/lecture_08/data_manipulation.html#concatenation-join-merge",
    "href": "lectures/lecture_08/data_manipulation.html#concatenation-join-merge",
    "title": "Lecture 08 - Data Manipulation (Pandas)",
    "section": "6. Concatenation, Join, Merge",
    "text": "6. Concatenation, Join, Merge\nData manipulation often involves the need to combine multiple datasets.\n\nInitialization\n\nloan_data = pd.DataFrame({\n    'Customer_ID': ['A001', 'A002', 'A003', 'A004'],\n    'Loan_Amount': [10000, 20000, 15000, 25000]\n})\n\ncredit_scores = pd.DataFrame({\n    'Customer_ID': ['A002', 'A004', 'A005'],\n    'Credit_Score': [720, 680, 710]\n})\n\n\nloan_data\n\n\ncredit_scores\n\n\n\n6.1 Concatenation\nConcatenation or appending means adding rows from one DataFrame to another.\n\n# Concatenating the DataFrames\npd.concat([loan_data, credit_scores], sort=False)\n\n\nRemember that when concatenating, the index values are maintained unless specified otherwise. They can be reset ignore_index=True (more on this here).\n\n\npd.concat([loan_data, credit_scores], ignore_index=True, sort=False)\n\n\n\n6.2 Join\nJoining allows to combine two DataFrames based on their indices. - It is similar to SQL joins - useful when combining datasets with matching shared keys.\nLet’s join the loan_data and credit_scores using Customer_ID.\n\n# Setting the 'Customer_ID' column as index for join\nloan_data.set_index('Customer_ID', inplace=True)\ncredit_scores.set_index('Customer_ID', inplace=True)\n\n\n# Performing a left join\nloan_data.join(credit_scores, how='left')\n\nJoin methods\nThere are 4 different approaches to join DataFrames.\nEach approach leads to a different behavior with regard to how index values and the corresponding data rows are handled:\n\n\n\n\n\n\n\nJoin Method\nDescription\n\n\n\n\nleft\nPreserves index values from the left DataFrame.\n\n\nright\nPreserves index values from the right DataFrame.\n\n\ninner\nPreserves index values found in both DataFrames.\n\n\nouter\nPreserves all index values from both DataFrames.\n\n\n\n\n# Different types of joins\nloan_data.join(credit_scores, how='right')\n\n\nloan_data.join(credit_scores, how='inner')\n\n\nloan_data.join(credit_scores, how='outer')\n\n\n\n6.3 Merge\nMerging DataFrames is similar to joining except it can be achieved on specific columns instead of only indeces. - Useful when financial datasets have overlapping columns.\n\n# Resetting index for merging\nloan_data.reset_index(inplace=True)\ncredit_scores.reset_index(inplace=True)\n\n\n# Merging based on the 'Customer_ID' column\npd.merge(loan_data, credit_scores, on='Customer_ID', how='inner')\n\nAs for joins, mergers can be done with the four different options: - left - right - inner - outer\n\n# Merge with outer join\npd.merge(loan_data, credit_scores, on='Customer_ID', how='outer')\n\nMerging can also be done using different columns from each DataFrame - left_on - right_on\n\n# Sample DataFrame for loan data\nloan_data = pd.DataFrame({\n    'Loan_ID': ['L001', 'L002', 'L003', 'L004'],\n    'Amount': [5000, 7000, 8000, 6000],\n    'Branch_ID': ['B001', 'B002', 'B003', 'B004']\n})\n\n# Sample DataFrame for branch data\nbranch_data = pd.DataFrame({\n    'Branch_Name': ['Main Branch', 'East Branch', 'West Branch', 'North Branch'],\n    'Manager': ['John', 'Sally', 'Mike', 'Anna'],\n    'ID': ['B001', 'B002', 'B003', 'B005']  # Different name for Branch_ID column\n})\n\n# Merging using different columns from each DataFrame\n# Merging on loan_data['Branch_ID'] and branch_data['ID']\nmerged_df = pd.merge(loan_data, branch_data, left_on='Branch_ID', right_on='ID', how='outer')\n\nprint(merged_df)"
  },
  {
    "objectID": "lectures/lecture_08/data_manipulation.html#checkpoint-4",
    "href": "lectures/lecture_08/data_manipulation.html#checkpoint-4",
    "title": "Lecture 08 - Data Manipulation (Pandas)",
    "section": "🚦Checkpoint",
    "text": "🚦Checkpoint\nTask: 1. Create two DataFrames, one with Customer_ID and Loan_Amount and another with Customer_ID and Credit_Score from\n    loan_data = pd.DataFrame({\n    'Customer_ID': ['A001', 'A002', 'A003'],\n    'Loan_Amount': [10000, 15000, 20000]\n    })\n\n    credit_data = pd.DataFrame({\n        'Customer_ID': ['A001', 'A002', 'A004'],\n        'Credit_Score': [720, 650, 700]\n    })\n\nMerge the two DataFrames."
  },
  {
    "objectID": "lectures/lecture_08/lecture_08.html",
    "href": "lectures/lecture_08/lecture_08.html",
    "title": "Lecture 08 - Data Manipulation",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_08/lecture_08.html#lecture-material",
    "href": "lectures/lecture_08/lecture_08.html#lecture-material",
    "title": "Lecture 08 - Data Manipulation",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_08/lecture_08.html#recording",
    "href": "lectures/lecture_08/lecture_08.html#recording",
    "title": "Lecture 08 - Data Manipulation",
    "section": "Recording",
    "text": "Recording\n\n1. Intro\n\n \n\n\n\n2. The DataFrame Class\n\n \n\n\n\n3. Basic Operations\n\n \n\n\n\n4. The Series Class\n\n \n\n\n\n5. GroupBy Methods\n\n \n\n\n \n\n\n\n6. Complex Selection\n\n \n\n\n\n7. Concatenate, Join & Merge"
  },
  {
    "objectID": "lectures/lecture_08/lecture_08.html#problem-sets",
    "href": "lectures/lecture_08/lecture_08.html#problem-sets",
    "title": "Lecture 08 - Data Manipulation",
    "section": "Problem sets",
    "text": "Problem sets\n\nJupyter notebook (.ipynb)\nSolutions (.pdf)"
  },
  {
    "objectID": "lectures/lecture_06/libraries.html",
    "href": "lectures/lecture_06/libraries.html",
    "title": "Lecture 06 - Libraries",
    "section": "",
    "text": "Python libraries are collections of modules and functions that provide additional functionality, allowing to perform complex tasks with minimal code.\nIn this notebook covers: - Why Python libraries are important - How to install and import libraries - Key Python libraries used in banking and finance - pandas for data manipulation - numpy for numerical computations - matplotlib and seaborn for data visualization - datetime for date and time manipulation"
  },
  {
    "objectID": "lectures/lecture_06/libraries.html#overview",
    "href": "lectures/lecture_06/libraries.html#overview",
    "title": "Lecture 06 - Libraries",
    "section": "",
    "text": "Python libraries are collections of modules and functions that provide additional functionality, allowing to perform complex tasks with minimal code.\nIn this notebook covers: - Why Python libraries are important - How to install and import libraries - Key Python libraries used in banking and finance - pandas for data manipulation - numpy for numerical computations - matplotlib and seaborn for data visualization - datetime for date and time manipulation"
  },
  {
    "objectID": "lectures/lecture_06/libraries.html#why-use-python-libraries",
    "href": "lectures/lecture_06/libraries.html#why-use-python-libraries",
    "title": "Lecture 06 - Libraries",
    "section": "1. Why Use Python Libraries?",
    "text": "1. Why Use Python Libraries?\nPython libraries allow to: - Reuse code that has been tested and optimized by others - Perform complex tasks with just a few lines of code - Simplify workflow by providing tools tailored to specific tasks\n\nExample: Using a Library vs. Writing Code from Scratch\n\n# Without using a library\n# Calculate the square root of a number (writing the logic from scratch)\ndef sqrt(number):\n    return number ** 0.5\n\nprint(\"Square root of 16 (without library):\", sqrt(16))\n\n\n# Using a library (numpy)\nimport numpy as np\nprint(\"Square root of 16 (using numpy):\", np.sqrt(16))"
  },
  {
    "objectID": "lectures/lecture_06/libraries.html#installing-and-importing-libraries",
    "href": "lectures/lecture_06/libraries.html#installing-and-importing-libraries",
    "title": "Lecture 06 - Libraries",
    "section": "2. Installing and Importing Libraries",
    "text": "2. Installing and Importing Libraries\nTo use a library, it needs to be installed (if it’s not already installed) and be imported it into the current Python environment.\n\n2.1 Installing Libraries\n\nUsing pip, the Python package installer. For example:\n\npip install pandas numpy matplotlib seaborn\n\nUsing the anaconda suite to install manually.\n\n\n\n2.2 Importing Libraries\nOnce installed, libraries can be imported into the environment using import (...as):\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns"
  },
  {
    "objectID": "lectures/lecture_06/libraries.html#key-python-libraries-for-data-science-in-finance",
    "href": "lectures/lecture_06/libraries.html#key-python-libraries-for-data-science-in-finance",
    "title": "Lecture 06 - Libraries",
    "section": "3. Key Python Libraries for Data Science in Finance",
    "text": "3. Key Python Libraries for Data Science in Finance\n\n3.1 numpy for Numerical Computations\nnumpy is the foundational package for numerical computing in Python. It is particularly useful for handling large arrays and matrices of numeric data.\n\nimport numpy as np\n\n# Example: Calculating compound interest using numpy\nprincipal = 1000  # Initial amount\nrate = 0.05  # Interest rate\ntime = 10  # Number of years\n\n# Calculate the future value\nfuture_value = principal * np.power(1 + rate, time)\nprint(\"Future Value after 10 years:\", future_value)\n\n\n\n3.2 pandas for Data Manipulation\npandas is a powerful library for data manipulation and analysis. It works with structured data, such as CSV files, databases, and Excel spreadsheets.\n\nimport pandas as pd\n\n# Example: Reading a CSV file containing transaction data\ntransactions = pd.DataFrame({\n    'Date': ['2023-08-01', '2023-08-02', '2023-08-03'],\n    'Description': ['Deposit', 'Withdrawal', 'Deposit'],\n    'Amount': [1000, -200, 500]\n})\n\n# Display the first few rows of the DataFrame\nprint(transactions.head())\nprint (\"\\n\")\n# Calculating the total balance after transactions\ntransactions['Balance'] = transactions['Amount'].cumsum()\nprint(transactions)\n\n\n\n3.3 matplotlib and seaborn for Data Visualization\nmatplotlib and seaborn are powerful libraries for creating visualizations. matplotlib provides a flexible foundation, while seaborn simplifies the creation of more complex plots.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Example: Visualizing the account balances over time\nsns.lineplot(x='Date', y='Balance', data=transactions)\nplt.title(\"Account Balance Over Time\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Balance\")\nplt.xticks(rotation=45)\nplt.show()\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Sample Data: Tips Dataset (comes built-in with seaborn)\ndata = sns.load_dataset(\"tips\")\n\n# Create a rich visualization using Seaborn's relplot\nsns.set_theme(style=\"whitegrid\")  # Set theme for aesthetics\nplot = sns.relplot(\n    data=data, \n    x=\"total_bill\", \n    y=\"tip\", \n    hue=\"day\", \n    style=\"time\", \n    size=\"size\",\n    palette=\"viridis\", \n    kind=\"scatter\", \n    aspect=1.5,\n    height=6\n)\n\n# Add labels and a title\nplot.set_axis_labels(\"Total Bill ($)\", \"Tip ($)\")\nplot.fig.suptitle(\"Tips vs. Total Bill by Day and Time\", fontsize=16, weight='bold')\n\n# Show the plot\nplt.show()\n\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load the built-in 'iris' dataset from seaborn\niris = sns.load_dataset(\"iris\")\n\n# Create a pairplot with rich formatting\nsns.set(style=\"ticks\", palette=\"pastel\")\n# pairplot() visualizes pairwise relationships in a dataset, making it great for exploratory data analysis.\nplot = sns.pairplot(\n    iris, \n    hue=\"species\",  # Color by species type\n    kind=\"reg\",     # Add regression lines to show trends\n    diag_kind=\"kde\",  # Use KDE plots on the diagonal for a smoother distribution\n    markers=[\"o\", \"s\", \"D\"],  # Use different markers for each species\n    height=2.5\n)\n\n# Add a main title and adjust spacing\nplot.fig.suptitle(\"Pairplot of Iris Dataset with Regression Lines\", fontsize=16, weight='bold')\nplot.fig.subplots_adjust(top=0.95)\n\n# Display the plot\nplt.show()\n\n\n\n3.4 datetime for Date and Time Manipulation\nThe datetime module allows you to work with dates and times.\n\nfrom datetime import datetime\n\n# Example: Calculating the number of days between two dates\ndate_format = \"%Y-%m-%d\"\nstart_date = datetime.strptime(\"2023-08-01\", date_format)\nend_date = datetime.strptime(\"2023-08-10\", date_format)\n\ndays_between = (end_date - start_date).days\nprint(f\"Days between {start_date.date()} and {end_date.date()}: {days_between}\")"
  },
  {
    "objectID": "lectures/lecture_01/lecture_01.html",
    "href": "lectures/lecture_01/lecture_01.html",
    "title": "Lecture 01 - Introduction to Python",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_01/lecture_01.html#lecture-material",
    "href": "lectures/lecture_01/lecture_01.html#lecture-material",
    "title": "Lecture 01 - Introduction to Python",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_01/lecture_01.html#recording",
    "href": "lectures/lecture_01/lecture_01.html#recording",
    "title": "Lecture 01 - Introduction to Python",
    "section": "Recording",
    "text": "Recording\n\n1. Motivation\n\n \n\n\n\n2. Setting up the environment\n\n \n\n\n\n3. Overview of the Python environment"
  },
  {
    "objectID": "lectures/lecture_07/lecture_07.html",
    "href": "lectures/lecture_07/lecture_07.html",
    "title": "Lecture 07 - Numerical Computing",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_07/lecture_07.html#lecture-material",
    "href": "lectures/lecture_07/lecture_07.html#lecture-material",
    "title": "Lecture 07 - Numerical Computing",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_07/lecture_07.html#recording",
    "href": "lectures/lecture_07/lecture_07.html#recording",
    "title": "Lecture 07 - Numerical Computing",
    "section": "Recording",
    "text": "Recording\n\n1. Intro\n\n \n\n\n\n2. NumPy Arrays\n\n \n\n\n\n3. Structured Arrays, Vectorized Programming & Random Number Generator\n\n \n\n\n\n4. Applications"
  },
  {
    "objectID": "lectures/lecture_07/lecture_07.html#problem-sets",
    "href": "lectures/lecture_07/lecture_07.html#problem-sets",
    "title": "Lecture 07 - Numerical Computing",
    "section": "Problem sets",
    "text": "Problem sets\n\nJupyter notebook (.ipynb)\nSolutions (.pdf)"
  },
  {
    "objectID": "lectures/lecture_07/lecture_07_problem_set.html",
    "href": "lectures/lecture_07/lecture_07_problem_set.html",
    "title": "Numerical Computing (NumPy) - Problem set",
    "section": "",
    "text": "Create a 3D array with dimensions \\(3 \\times 3 \\times 3\\) filled with random integers between 1 and 100. 1. Replace all values that are divisible by 3 with -1. 2. Calculate the mean value for each of the three 2D layers in the 3D array.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_07/lecture_07_problem_set.html#exercise-1-manipulating-a-3d-array",
    "href": "lectures/lecture_07/lecture_07_problem_set.html#exercise-1-manipulating-a-3d-array",
    "title": "Numerical Computing (NumPy) - Problem set",
    "section": "",
    "text": "Create a 3D array with dimensions \\(3 \\times 3 \\times 3\\) filled with random integers between 1 and 100. 1. Replace all values that are divisible by 3 with -1. 2. Calculate the mean value for each of the three 2D layers in the 3D array.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_07/lecture_07_problem_set.html#exercise-2-boolean-indexing-and-filtering",
    "href": "lectures/lecture_07/lecture_07_problem_set.html#exercise-2-boolean-indexing-and-filtering",
    "title": "Numerical Computing (NumPy) - Problem set",
    "section": "Exercise 2: Boolean Indexing and Filtering",
    "text": "Exercise 2: Boolean Indexing and Filtering\nGiven an array of random integers between 1 and 50 (size 20): 1. Identify all elements that are prime numbers. 2. Replace all prime numbers with 0.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_07/lecture_07_problem_set.html#exercise-3-array-manipulation-and-reshaping",
    "href": "lectures/lecture_07/lecture_07_problem_set.html#exercise-3-array-manipulation-and-reshaping",
    "title": "Numerical Computing (NumPy) - Problem set",
    "section": "Exercise 3: Array Manipulation and Reshaping",
    "text": "Exercise 3: Array Manipulation and Reshaping\nCreate a 1D NumPy array of size 30 filled with random integers between 10 and 100. Perform the following: 1. Reshape the array into a \\(5 \\times 6\\) matrix. 2. Compute the sum of the values in each row. 3. Compute the sum of the values in each column.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_07/lecture_07_problem_set.html#exercise-4-matrix-determinant-and-inverse",
    "href": "lectures/lecture_07/lecture_07_problem_set.html#exercise-4-matrix-determinant-and-inverse",
    "title": "Numerical Computing (NumPy) - Problem set",
    "section": "Exercise 4: Matrix Determinant and Inverse",
    "text": "Exercise 4: Matrix Determinant and Inverse\nGenerate a \\(4 \\times 4\\) matrix of random integers between 1 and 10. 1. Calculate the determinant of the matrix. 2. If the determinant is non-zero, compute its inverse. 3. Verify that the inverse and the original matrix product result in an identity matrix.\nUse functions: - np.linalg.det() - np.linalg.inv() - np.dot()\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_07/lecture_07_problem_set.html#exercise-5-simulating-an-ornstein-uhlenbeck-process",
    "href": "lectures/lecture_07/lecture_07_problem_set.html#exercise-5-simulating-an-ornstein-uhlenbeck-process",
    "title": "Numerical Computing (NumPy) - Problem set",
    "section": "Exercise 5: Simulating an Ornstein-Uhlenbeck Process",
    "text": "Exercise 5: Simulating an Ornstein-Uhlenbeck Process\nSimulate an Ornstein-Uhlenbeck process, which is used in finance to model mean-reverting processes such as interest rates. The formula is given by:\n\\[\nX_{t+1} = X_t + \\theta (\\mu - X_t) \\Delta t + \\sigma \\sqrt{\\Delta t} \\cdot Z_t\n\\]\nWhere: - \\(X_t\\) is the value of the process at time step \\(t\\). - \\(\\theta\\) is the speed of mean reversion (how fast the process reverts to the mean). - \\(\\mu\\) is the long-term mean to which the process reverts. - \\(\\sigma\\) is the volatility or standard deviation of the process. - \\(\\Delta t\\) is the time step size (in this case, 0.01). - \\(Z_t\\) is a random normal variable (\\(Z_t \\sim N(0, 1)\\)), representing the random noise at each time step.\nBackground information: 1. Mean-reverting drift: \\(\\theta (\\mu - X_t) \\Delta t\\) - This term controls how quickly the process moves back towards the mean \\(\\mu\\). - The strength of this pull towards the mean is determined by \\(\\theta\\), and the distance from the mean is represented by \\(\\mu - X_t\\).\n\nRandom fluctuation: \\(\\sigma \\sqrt{\\Delta t} \\cdot Z_t\\)\n\nThis term represents the stochastic component of the process, introducing random fluctuations.\n\\(\\sigma\\) controls the magnitude of these fluctuations, while \\(\\sqrt{\\Delta t}\\) ensures the appropriate scaling over time steps.\n\n\nThus, at each time step \\(t\\), the process evolves according to this combination of mean-reverting behavior and random fluctuation.\nParameter setting for the simulation: - $ = 0.7 $ (mean reversion speed), - $ = 0.05 $ (long-term mean), - $ = 0.15 $ (volatility), - $ dt = 0.01 $ (time step), - initial value $ X_0 = 0.05 $, - simulate for 500 time steps.\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_07/lecture_07_problem_set.html#exercise-6-element-wise-operations-on-multiple-arrays",
    "href": "lectures/lecture_07/lecture_07_problem_set.html#exercise-6-element-wise-operations-on-multiple-arrays",
    "title": "Numerical Computing (NumPy) - Problem set",
    "section": "Exercise 6: Element-Wise Operations on Multiple Arrays",
    "text": "Exercise 6: Element-Wise Operations on Multiple Arrays\nCreate two arrays, A and B, each of size (1000), with random values between 1 and 10. Perform the following operations: 1. Identify the indices where elements of A are larger than the corresponding elements in B. 2. Compute a new array C where C[i] equals the value of A[i] if A[i] &gt; B[i], otherwise it equals the average of A[i] and B[i].\n\n# Your code"
  },
  {
    "objectID": "lectures/lecture_07/lecture_07_problem_set.html#exercise-7-matrix-operations-and-transposing",
    "href": "lectures/lecture_07/lecture_07_problem_set.html#exercise-7-matrix-operations-and-transposing",
    "title": "Numerical Computing (NumPy) - Problem set",
    "section": "Exercise 7: Matrix Operations and Transposing",
    "text": "Exercise 7: Matrix Operations and Transposing\nGiven a \\(4 \\times 4\\) matrix filled with random integers between 1 and 20, perform the following:\n\nTranspose the matrix.\nCompute the sum of the elements in the original matrix.\nCompute the sum of the elements in the transposed matrix.\nVerify if the sum of elements in the original and transposed matrix are equal."
  },
  {
    "objectID": "lectures/lecture_07/lecture_07_problem_set.html#exercise-8-advanced-matrix-operations-and-broadcasting",
    "href": "lectures/lecture_07/lecture_07_problem_set.html#exercise-8-advanced-matrix-operations-and-broadcasting",
    "title": "Numerical Computing (NumPy) - Problem set",
    "section": "Exercise 8: Advanced Matrix Operations and Broadcasting",
    "text": "Exercise 8: Advanced Matrix Operations and Broadcasting\nGiven two matrices A and B with dimensions \\(3 \\times 3\\) filled with random integers between 1 and 10:\n\nAdd the two matrices together using broadcasting.\nMultiply the two matrices element-wise.\nCompute the matrix product of A and B using matrix multiplication.\nSubtract the transpose of matrix B from matrix A ."
  },
  {
    "objectID": "lectures/lecture_07/lecture_07_problem_set.html#exercise-9-function-application-with-vectorization",
    "href": "lectures/lecture_07/lecture_07_problem_set.html#exercise-9-function-application-with-vectorization",
    "title": "Numerical Computing (NumPy) - Problem set",
    "section": "Exercise 9: Function Application with Vectorization",
    "text": "Exercise 9: Function Application with Vectorization\nWrite a NumPy-based function that calculates the following for each element of a 1D array:\n\\[f(x) = 3x^2 + 2x - 5\\]\n\nCreate a 1D array of size 20 with random integers between -10 and 10.\nApply the function f(x) to each element of the array in a vectorized manner (without using loops).\nReturn the resulting array."
  },
  {
    "objectID": "lectures/lecture_07/lecture_07_problem_set.html#exercise-10-advanced-broadcasting-and-boolean-filtering",
    "href": "lectures/lecture_07/lecture_07_problem_set.html#exercise-10-advanced-broadcasting-and-boolean-filtering",
    "title": "Numerical Computing (NumPy) - Problem set",
    "section": "Exercise 10: Advanced Broadcasting and Boolean Filtering",
    "text": "Exercise 10: Advanced Broadcasting and Boolean Filtering\nGiven a \\(6 \\times 6\\) matrix of random integers between 1 and 100:\n\nWrite a function that finds all the elements divisible by both 3 and 5.\nReplace all such elements with -1 using boolean filtering and broadcasting.\nReturn the modified matrix."
  },
  {
    "objectID": "lectures/lecture_09/input_output.html",
    "href": "lectures/lecture_09/input_output.html",
    "title": "Lecture 09 - Input and Output (I/O) Operations",
    "section": "",
    "text": "Input and output operations (I/O) are essential in programming.\nThey allow programs to - Interact live with users - Take data as input - Display or save the results as output\nThis notebook covers - How to take input from users - How to display output using the print() function - File I/O operations: reading from and writing to files - Handling CSV files with basic file operations - Working with CSV/Excel files using pandas"
  },
  {
    "objectID": "lectures/lecture_09/input_output.html#overview",
    "href": "lectures/lecture_09/input_output.html#overview",
    "title": "Lecture 09 - Input and Output (I/O) Operations",
    "section": "",
    "text": "Input and output operations (I/O) are essential in programming.\nThey allow programs to - Interact live with users - Take data as input - Display or save the results as output\nThis notebook covers - How to take input from users - How to display output using the print() function - File I/O operations: reading from and writing to files - Handling CSV files with basic file operations - Working with CSV/Excel files using pandas"
  },
  {
    "objectID": "lectures/lecture_09/input_output.html#live-inputs",
    "href": "lectures/lecture_09/input_output.html#live-inputs",
    "title": "Lecture 09 - Input and Output (I/O) Operations",
    "section": "2. Live inputs",
    "text": "2. Live inputs\n\n2.1 The input() function\nThe input() function allows the user to provide input to the program while running by returning the input as a string.\n\n# Example: Asking for user input\nname = input(\"What is your name? \")\nprint(\"Hello, \" + name + \"!\")\n\n\n\n2.2 Casting inputs\nResults from input() can be casted from string to other data types (int, float, etc.).\n\n# Example: Taking a number as input\nage = int(input(\"How old are you? \"))  # Convert input to an integer\nprint(\"You are\", age, \"years old.\")\nprint (\"You were born in \", 2025 - age)\n\n\n# Example: Taking a float as input\nbalance = float(input(\"Enter your account balance: \"))\nprint(\"Your balance is $\", balance)\n\n\n\n2.3 Multiple inputs\nWhen multiple inputs are entered, they are returned in one line. They can be then separated into separate items using split().\n\n# Example: Taking multiple inputs\nfirst_name, last_name = input(\"Enter your first and last name: \").split()\nprint(\"Hello, \" + first_name + \" \" + last_name)"
  },
  {
    "objectID": "lectures/lecture_09/input_output.html#live-output",
    "href": "lectures/lecture_09/input_output.html#live-output",
    "title": "Lecture 09 - Input and Output (I/O) Operations",
    "section": "3. Live output",
    "text": "3. Live output\n\n3.1 The print() function\nThe print() function displays outputs in the prompt terminal.\n\n# Example: Basic output using print()\nprint(\"Hello, world!\")\n\n\n\n3.2 Printing variables and expressions\nThe print() handles variables and expressions.\n\n# Example: Printing variables\nname = \"Alice\"\nage = 25\nprint(\"Name:\", name, \"Age:\", age)\n\n\nString formatting\nPython provides several ways to format outputs as a combination of strings and variables.\n\nUsing commas:\n  print(\"string\", variable, \"string\", etc.)\n\n\n# Example: Using commas\nprint(\"Your balance is\", balance, \"dollars.\")\n\n\nUsing f-strings (available in Python 3.6+):\n  print (f\"string {variable}\")\n\n\n# Example: Using f-strings\nprint(f\"Hello, {name}. You are {age} years old.\")\n\n\nUsing the format() method:\n  print (\"string {}, {}\".format(variable1, variable2))\n\n\n# Example: Using format()\nprint(\"Hello, {}. You are {} years old.\".format(name, age))"
  },
  {
    "objectID": "lectures/lecture_09/input_output.html#file-input-and-output-file-io",
    "href": "lectures/lecture_09/input_output.html#file-input-and-output-file-io",
    "title": "Lecture 09 - Input and Output (I/O) Operations",
    "section": "4. File input and output (File I/O)",
    "text": "4. File input and output (File I/O)\nPrograms can read from files and write to files.\n\n4.1 Opening files\nBefore reading from or writing to a file, a file object must be created. The open() function opens files and creates access in Python.\n    open (name, mode)\n\nThe name (or path) of the file\nThe access mode (e.g., 'r' for reading, 'w' for writing, 'a' for appending)\n\nNote: opened files must then be closed with .close() to clear the access.\n\nfile_path = \"Data/09/\"\nfile_name = \"example.txt\"\nfile = open(file_path + file_name, \"r\")  # Open the file in read mode\n\n\n\n4.2 Reading from\nSeveral methods exist for reading file contents, such as .read(), .readline(), and .readlines().\n\nread(): Reads the entire file.\n\n\ncontent = file.read()  # Read the entire file\nprint(content)\nfile.close()  # Close the file after reading\n\n\ncontent\n\n\nreadline(): Reads one line at a time.\n\n\nfile = open(file_path + file_name, \"r\")\nline = file.readline()\nwhile line:\n    print(line.strip())  # Remove newline characters\n    line = file.readline()\nfile.close()\n\n\nreadlines(): Reads all lines and returns them as a list.\n\n\nlines\n\n\nfile = open(file_path + file_name, \"r\")\nlines = file.readlines()\nfor line in lines:\n    print(line.strip())\nfile.close()\n\n\n\n4.3 with for file handling\nTo avoid misusing file access (opening and closing), the with statement handles files more efficiently by automatically closing the file after the block of code is executed.\n    with expression as variable:\n        # Code block that uses the resource (e.g., a file or connection)\n\n# Example: Using 'with' to handle files\nwith open(file_path + file_name, \"r\") as file:\n    content = file.read()\n    print(content)\n# No need to explicitly close the file; it is done automatically\n\n\n\n4.4 Writing to\nWriting data to a file is done using the write() or writelines() methods. - The 'w' (write) mode overwrites the existing content. - The 'a' (append) mode writes at the end of the file.\n\nWrite mode m:\n\n\n# Example: Writing to a file\nfile_name = \"new_file.txt\"\nwith open(file_path + file_name, \"w\") as file: # Open file in write mode\n    file.write(\"This is the first line.\\n\")\n    file.write(\"This is the second line.\\n\")\n\n\n# checking\nwith open(file_path + file_name, \"r\") as file: # Open file in write mode\n    print(file.read())\n\n\nAppend mode a:\n\n\n# Example: Writing to a file\nfile_name = \"new_file.txt\"\nwith open(file_path + file_name, \"a\") as file: # Open file in write mode\n    file.write(\"This is the first line.\\n\")\n    file.write(\"This is the second line.\\n\")\n    file.write(\"This is an additional line.\\n\")\n\n\n# checking\nwith open(file_path + file_name, \"r\") as file: # Open file in write mode\n    print(file.read())"
  },
  {
    "objectID": "lectures/lecture_09/input_output.html#csv-files",
    "href": "lectures/lecture_09/input_output.html#csv-files",
    "title": "Lecture 09 - Input and Output (I/O) Operations",
    "section": "5. .csv files",
    "text": "5. .csv files\nCSV (Comma-Separated Values) files are the standard storing format for tabular data. - The firt line contains the name of columns. - Each line is a row where cells are separated by ,.\nExample: \"csv_example.csv\"\n    Name,Age,Balance\n    Alice,30,1000.50\n    Bob,25,1500.75\n    Charlie,35,2000.25\n    Diana,28,1800.60\n    Eve,22,1200.00\n\n5.1 with Python\nHandling .csv files from Python can be done using the csv module.\n\nimport csv\n\n\nReading from\nReading a csv file is done using the csv.reader() method.\n\nimport csv\n# Example: Reading a CSV file\nfile_path = \"Data/09/\"\ncsv_file_name = 'csv_example.csv'\nwith open(file_path + csv_file_name, 'r') as file:\n    csv_reader = csv.reader(file)\n    for row in csv_reader:\n        print(row)\n\ncsv files can also be directly read as dict objects using the csv.DictRead() method.\n\n# Example: Reading a CSV file with headers\nwith open(file_path + csv_file_name, 'r') as file:\n    csv_reader = csv.DictReader(file)\n    for row in csv_reader:\n        print(f\"{row['Name']} is {row['Age']} years old.\")\n\n\n\nWriting to\nWriting data to a csv file is done by 1. Creating a csv.writer() object with the output file. 2. Inserting rows with .writerow()\n\nw mode\n\n\n# Example: Writing to a CSV file\ncsv_output_file_name = 'csv_output_example.csv'\nwith open(file_path + csv_output_file_name, 'w', newline='') as file:\n    csv_writer = csv.writer(file)\n    csv_writer.writerow(['Name', 'Age', 'Balance'])\n    csv_writer.writerow(['Alice', '30', '1000.50'])\n    csv_writer.writerow(['Bob', '25', '1500.75'])\n\n\na mode\n\n\ncsv_output_file_name = 'csv_output_example.csv'\nwith open(file_path + csv_output_file_name, 'a', newline='') as file:\n    csv_writer = csv.writer(file)\n    csv_writer.writerow(['Name', 'Age', 'Balance'])\n    csv_writer.writerow(['Charlie', '35', '2000.25'])\n    csv_writer.writerow(['Eve', '22', '1200.00'])\n\n\nwith open(file_path + csv_output_file_name, 'r') as file:\n    csv_reader = csv.DictReader(file)\n    for row in csv_reader:\n        print(f\"{row['Name']} is {row['Age']} years old.\")\n\n\n\n\n5.2 with pandas\nPandas simplifies reading, writing, and analyzing data, especially with csv files.\n\nimport pandas as pd\n\n\nReading from\nReading a csv file is done using the pd.read_csv() method.\n    pd.read_csv(...)\nCheck method documentation (huge!).\nKey parameters: - filepath_or_buffer: The path to the file you want to read. - delimiter or sep: The character that separates values (default is a comma). - header: Row number to use as the column names. - names: A list of column names to use. - index_col: Column(s) to set as index. - skiprows: Number of rows to skip at the start of the file.\n\ncsv_file_name = 'csv_example.csv'\ndf = pd.read_csv(file_path + csv_file_name)\ndf\n\nExample with Parameters\n\n# Customizing CSV reading\ndf = pd.read_csv(file_path + csv_file_name, delimiter=\",\", header=0, index_col=\"Name\")\ndf.head()\n\n\n\nWriting to\nSaving a DataFrame to a csv file is done using the pd.to_csv() method.\n\n# Example: Writing DataFrame to a CSV file\ndf_file_name = 'df_output_example.csv'\ndf.to_csv(file_path + df_file_name, index=False)  # `index=False` to exclude row indices"
  },
  {
    "objectID": "lectures/lecture_09/input_output.html#excel-files",
    "href": "lectures/lecture_09/input_output.html#excel-files",
    "title": "Lecture 09 - Input and Output (I/O) Operations",
    "section": "6. Excel files",
    "text": "6. Excel files\nExcel files are commonly used for data storage and transfer.\nPandas makes it easy to write and read these files.\n\n6.1 Writing to\nPandas writes DataFrames to Excel files using the to_excel() method.\n    pd.to_excel(...)\nCheck method documentation (huge!).\nKey parameters: - excel_writer: This is the path to the Excel file (“output.xlsx”) or an ExcelWriter object if saving multiple sheets to a single file. - sheet_name: The name of the sheet where the DataFrame will be saved. Default is “Sheet1”. - na_rep: Defines how missing values (NaN) should appear in the Excel file (e.g., na_rep=“N/A”). - columns: List of column names to write; writes all columns by default. - header: If True, includes column headers; set to False to exclude. - index: If True, includes the DataFrame’s index; if False, omits it. - startrow and startcol: Define the starting cell (row and column) for writing data.\n\nBasic example of writing to Excel\nNote: The to_excel() method requires the openpyxl library for .xlsx files (install with !pip install openpyxl if necessary).\n\nimport pandas as pd\nimport openpyxl\n\n# Sample DataFrame\ndata = {\n    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n    \"Age\": [25, 30, 35],\n    \"Balance\": [1000.50, 1500.75, 1200.30]\n}\ndf = pd.DataFrame(data)\n\n# Writing the DataFrame to an Excel file\nfile_path = \"Data/09/\"\nexcel_output_name = \"excel_output_example.xlsx\"\ndf.to_excel(file_path + excel_output_name, index=False)  # `index=False` excludes row indices\n\n\n\nWriting multiple sheets to an Excel File\nThe ExcelWriter class allows to save multiple DataFrames to different sheets within the same Excel file.\n\n# Create additional sample DataFrames\ndata2 = {\n    \"Product\": [\"Widget A\", \"Widget B\", \"Widget C\"],\n    \"Price\": [20.5, 45.3, 30.0]\n}\ndf2 = pd.DataFrame(data2)\n\nwith pd.ExcelWriter(file_path + excel_output_name) as writer:\n    df.to_excel(writer, sheet_name=\"Customer Data\", index=False)\n    df2.to_excel(writer, sheet_name=\"Product Data\", index=False)\n\n\n\nSpecifying columns and formatting\nCustomizing which columns to write and add formatting options like headers are also possible.\n\n# Writing selected columns only\nexcel_output_2_name = \"excel_output_selected_columns.xlsx\"\ndf.to_excel(file_path + excel_output_2_name, columns=[\"Name\", \"Balance\"], index=False, header=True)\n\n\n\n\n6.2 Reading from an Excel file\nReading a xlsx file is done using the pd.read_excel() method.\n    pd.read_excel()\nCheck method documentation (huge!) - sheet_name: Name or index of the sheet to read. - header, names, index_col: Similar to read_csv(). - usecols: Specifies columns to load.\n\n# Reading an Excel file\ndf = pd.read_excel(file_path + excel_output_name, sheet_name=\"Customer Data\")\ndf.head()\n\nExample: Reading a specific sheet with column selection\n\n# Reading specific columns from an Excel sheet\ndf = pd.read_excel(file_path + excel_output_name, sheet_name=\"Product Data\", usecols=['Product'])\ndf.head()"
  },
  {
    "objectID": "lectures/lecture_09/input_output.html#checkpoint",
    "href": "lectures/lecture_09/input_output.html#checkpoint",
    "title": "Lecture 09 - Input and Output (I/O) Operations",
    "section": "🚦Checkpoint",
    "text": "🚦Checkpoint\n\nReading, Manipulating, and Saving Data with pandas\nGoal: In this exercise, you’ll read the CSV file, manipulate the data using pandas, and save the modified data back to a CSV file.\n    file_name = \"checkpoint_stock_data_large.csv\"\n\nImport data and inspect in DataFrame\nTask 1: Filter out all rows where the stock price is greater than USD 2000.\nTask 2: Add a new column called Value which is calculated as Price * Volume.\nTask 3: Group the data by the Stock column and calculate the average price for each stock.\nSave the manipulated DataFrame to a new CSV file."
  },
  {
    "objectID": "lectures/lecture_10/lecture_10.html#lecture-material",
    "href": "lectures/lecture_10/lecture_10.html#lecture-material",
    "title": "Lecture 10 - Network Analytics",
    "section": "Lecture Material",
    "text": "Lecture Material\n\nJupyter notebook (.ipynb)\n\nData: .zip"
  },
  {
    "objectID": "lectures/lecture_10/lecture_10.html#problem-sets",
    "href": "lectures/lecture_10/lecture_10.html#problem-sets",
    "title": "Lecture 10 - Network Analytics",
    "section": "Problem sets",
    "text": "Problem sets\n\nJupyter notebook (.ipynb)\n\nData: .zip\nSolutions (.pdf)"
  },
  {
    "objectID": "lectures/lecture_10/network_slides_2025.html",
    "href": "lectures/lecture_10/network_slides_2025.html",
    "title": "Part 1: Network Analysis - Overview",
    "section": "",
    "text": "Network analysis is the study of relationships and interactions between objects.\nIt’s a way to map and explore how items (people, companies, cities, computers etc.) are connected and how information, money, or influence flows between them.\nit is a interdisciplinary approach: widely used across various fields, powerful in economics and finance.\n\nMany complex systems can be visualized as networks. Examples:\n\nFacebook analyzes how people are connected to suggest friends.\nBanks use networks to see how money flows between institutions.\nBiologists map protein interactions to understand diseases."
  },
  {
    "objectID": "lectures/lecture_10/network_slides_2025.html#visualize-the-network",
    "href": "lectures/lecture_10/network_slides_2025.html#visualize-the-network",
    "title": "Part 1: Network Analysis - Overview",
    "section": "1. Visualize the network",
    "text": "1. Visualize the network\nFirst of all, we are going to import the dataset with pandas and visualize it.\n\nimport pandas as pd\n\nfile_path = \"ownership.txt\"  # Path to the file\n\n# Load the data into a pandas DataFrame\ndf = pd.read_csv(file_path, sep=\" \", header=None, names=[\"u\", \"v\"])\n\n# Print the first rows of the DataFrame\nprint(df.head())\n\n   u    v\n0  0  130\n1  0    8\n2  0  138\n3  0   11\n4  0   14\n\n\nSince we talk about shareholdership, the network is directed. Each row represents a shareholding relationship between two companies: - Column “u”: The company that owns shares (the owner). - Column “v”: The company that is owned (the owned entity).\nEach edge (u -&gt; v) indicates that company u holds shares in company v. For example, in the first row, company 0 owns shares in company 130, and graphically this consists in an arrow originating from node labeled “0” and pointing to node labeled “130”. There is no column identifying the strength of the relationships (namely, the share of ownership), hence the network is directed but unweighted. Now we can visualize the network.\n\n# Create a list of edges\nedges = []\nwith open(file_path, 'r') as f:\n    for line in f:\n        u, v = line.split()             # Each line has two numbers representing an edge (u -&gt; v)\n        edges.append((int(u), int(v)))  # Define the edge (int() because we have integers)\n\n# Create a empty directed graph and then add edges\nG = nx.DiGraph()\nG.add_edges_from(edges)\n\n# Visualize the graph method 1: simple way\nplt.figure(figsize=(8, 6))\nnx.draw(G, with_labels=True, node_color='lightblue', node_size=300, arrows=True)\nplt.title(\"Ownership Network\")\nplt.show()\n\n\n\n\n\n\n\n\nnx.draw is the simplest way in which you can visualize your graph, but there are more. For instance: - draw_circular - draw_spectral - draw_random - draw_spring"
  },
  {
    "objectID": "lectures/lecture_10/network_slides_2025.html#macro-structure-analysis",
    "href": "lectures/lecture_10/network_slides_2025.html#macro-structure-analysis",
    "title": "Part 1: Network Analysis - Overview",
    "section": "2. Macro-structure analysis",
    "text": "2. Macro-structure analysis\nThe macro-structure analysis investigates the network as a whole. Examines properties like: - Overall connectivity and density - Network topology (hubs, clustering, small-world): how the connections are distributed across the system - System-level vulnerability to cascades\nAnswers questions such as: How resilient is the system as a whole? How fast could a shock spread?\nWe proceed by inspecting the size of the network: - Number of Nodes (Companies): total number of distinct companies in the dataset - Number of Links (Shareholding Relationships): total number of edges or links between the companies, showing how many shareholding relationships exist in the network. This gives an idea of the scale and complexity.\n\nnodes = G.number_of_nodes()  # Number of nodes\nedges = G.number_of_edges()  # Number of edges\n\nprint(f\"Number of nodes: {nodes}\")\nprint(f\"Number of links: {edges}\")\n\nNumber of nodes: 139\nNumber of links: 1071\n\n\nDensity shows the proportion of actual connections to possible connections. A low density suggests a sparse network, typical in shareholdership networks where not all companies own shares in one another.\n\ndensity = nx.density(G)\nprint(\"Density:\", density)\n\nDensity: 0.05583359399436972\n\n\nA density of 0.0558 in your network indicates that only about 5.8% of all possible connections between companies actually exist. This suggests that the network is relatively sparse, not every company owns shares in every other company. This is not a surprising result: high interconnectedness is rare in corporate networks, as companies tend to invest in targeted partnerships.\nThe diameter is the longest shortest path between any two nodes. A small diameter means any node can be reached quickly from any other. This metrics helps to understand the speed of propagation in the network.\n\ndiameter = nx.diameter(G)\nprint(\"Diameter:\", diameter)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[2], line 1\n----&gt; 1 diameter = nx.diameter(G)\n      2 print(\"Diameter:\", diameter)\n\nNameError: name 'nx' is not defined\n\n\n\nThis error occurs because the diameter of a directed graph is only defined if the graph is strongly connected — that is, there is a path from every node to every other node. If the graph is not strongly connected, some node pairs are unreachable, so the shortest path length is infinite, and the diameter is undefined.\nA solution is to compute the diameter only for the strongly connected component (SCC) of the graph, if that is sufficiently big, i.e. representative of the whole graph. Hence we first find the SCC:\n\nscc = list(nx.strongly_connected_components(G))\nprint(\"Number of Strongly Connected Components:\", len(scc))\n\nNumber of Strongly Connected Components: 139\n\n\nThe number of SCCs equals the total number of nodes. This indicates that each company is isolated in terms of reciprocal ownership. In simpler terms, no two companies mutually own shares in each other. This network structure suggests that ownership is hierarchical rather than reciprocal. Companies may have directed ownership ties without mutual or cyclic ownership, which is common in corporate structures where ownership flows in one direction (from parent to subsidiary)."
  },
  {
    "objectID": "lectures/lecture_10/network_slides_2025.html#micro-structure-analysis",
    "href": "lectures/lecture_10/network_slides_2025.html#micro-structure-analysis",
    "title": "Part 1: Network Analysis - Overview",
    "section": "3. Micro-structure analysis",
    "text": "3. Micro-structure analysis\nThe micro-structure analysis investigates the characteristics of nodes and edges. Examines properties like: - How many connections a node has - How strongly it is connected - Its position in the network\nAnswers questions such as: Which institutions are most important? Who could trigger or absorb shocks?\nThe degree of a node is the number of connections a node has with the network. When the network is directed, we distinguish between: - in degree: total number of ingoing links - out degree: total number of outgoing links\nThese metrics help identify which companies are the most connected in terms of ownership. - Companies with high in-degree are widely owned by other companies, potentially signifying highly valued or influential companies. - Companies with high out-degree own shares in many other companies, likely indicating holding companies or major investors.\nUsually we sort the nodes according to the metrics and print the top 5 or 10.\n\nin_degrees = G.in_degree()\nout_degrees = G.out_degree()\n\nprint(\"In-Degree (Top 5):\", sorted(in_degrees, key=lambda x: x[1], reverse=True)[:5])\nprint(\"Out-Degree (Top 5):\", sorted(out_degrees, key=lambda x: x[1], reverse=True)[:5])\n\nIn-Degree (Top 5): [(138, 49), (71, 45), (115, 44), (99, 41), (78, 36)]\nOut-Degree (Top 5): [(8, 52), (71, 46), (0, 37), (57, 34), (16, 32)]\n\n\nInterpret the results in the following way: - node 138 has an in-degree of 49, meaning 49 other companies own shares in company 138. Namely, more than a third of the companies in the network own shares in this company. - node 8 has an out-degree of 52, meaning it owns shares in 52 other companies.\nWe can calculate the average degree by summing the in or out degrees of each node and dividing for the total number of nodes in the network.\n\navg_degree = sum(dict(G.in_degree()).values()) / G.number_of_nodes()\nprint(\"Average Degree:\", avg_degree)\n\nAverage Degree: 7.705035971223022\n\n\nWe can plot the degree distribution of the network in the following way:\n\ndegrees = [deg for _, deg in G.degree()]\n\nplt.figure(figsize=(7, 4))\nplt.hist(degrees, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\nplt.xlabel('Degree')\nplt.ylabel('Frequency')\nplt.title('Degree Distribution of the Network')\nplt.show()\n\n\n\n\n\n\n\n\nThe distribution is right-skewed, with a few nodes having a high degree and the majority of nodes having a low degree (close to zero).\nWe can understand what is the role and the position of the nodes in the network by computing the centrality indices.\n\ndegree centrality = it measures the centrality of a node by the number of direct connections it has. It reflects the influence of a node within the network. It is interpreted as a percentage.\nbetweenness centrality = it measures how often a node appears on the shortest path between pairs of other nodes. It reflects a node’s role as a bridge or connector. Its maximum depends on the structure of the network, hence it is always relatively interpreted.\ncloseness centrality = it is calculated based on the average length of the shortest path from the node to all other nodes. It reflects how close a node is to all other nodes in the network. It takes value between 0 and 1.\n\n\ndegree_centrality = nx.degree_centrality(G)\ncloseness_centrality = nx.closeness_centrality(G)\nbetweenness_centrality = nx.betweenness_centrality(G)\n\ntop_degree = sorted(nx.degree_centrality(G).items(), key=lambda x: x[1], reverse=True)[:5]\ntop_betweenness = sorted(nx.betweenness_centrality(G).items(), key=lambda x: x[1], reverse=True)[:5]\ntop_closeness = sorted(nx.closeness_centrality(G).items(), key=lambda x: x[1], reverse=True)[:5]\nprint(\"Top 5 nodes by degree centrality:\", top_degree)\nprint(\"Top 5 nodes by betweenness centrality:\", top_betweenness)\nprint(\"Top 5 nodes by closeness centrality:\", top_closeness)\n\nTop 5 nodes by degree centrality: [(71, 0.6594202898550725), (78, 0.4420289855072464), (8, 0.41304347826086957), (99, 0.39855072463768115), (57, 0.391304347826087)]\nTop 5 nodes by betweenness centrality: [(71, 0.0573599290824362), (8, 0.014212430000835176), (81, 0.012253964472742632), (78, 0.012181031922025251), (85, 0.0111383467195495)]\nTop 5 nodes by closeness centrality: [(138, 0.491343517430474), (115, 0.412617220801364), (121, 0.40018115942028987), (99, 0.3639571518588532), (131, 0.35144927536231885)]\n\n\n\nCompany 71 has the highest degree centrality, of approximately 0.66, meaning it is directly connected to approximately 66% of other nodes, either through owning them or being owned by them.\nIt’s also the company with the highest betweenness centrality, indicating it plays a significant role as a bridge within the network, even though the value is very low, a confirmation of the direct ownership structure of the network. The network as a whole relies on direct ownership relationships rather than intermediary connections.\nIt doesn’t show up anyway on the top 5 of the closeness centrality index, suggesting that while it has many direct connections, it doesn’t have quick access to all other companies within the network.\nCompany 138, on the other hand, is the one with highest closeness centrality, while it doesn’t seem to be strongly connected and a strong connector in the network.\n\nWe can compute a scatter plot of the indices and plot the distribution of the degree centrality.\n\ntop_degree_nodes = [node for node, _ in top_degree]\ntop_betweenness_nodes = [node for node, _ in top_betweenness]\ntop_closeness_nodes = [node for node, _ in top_closeness]\n\n# Plot each centrality measure as a scatter plot\nfig, ax = plt.subplots(1, 3, figsize=(18, 6))\n\n# Degree Centrality \nax[0].scatter(degree_centrality.keys(), degree_centrality.values(), color='lightgray', label='All Nodes')\nax[0].scatter(top_degree_nodes, [degree_centrality[node] for node in top_degree_nodes], color='salmon', label='Top 5')\nax[0].set_title(\"Degree Centrality\")\nax[0].set_xlabel(\"Node\")\nax[0].set_ylabel(\"Degree\")\n\n# Closeness Centrality\nax[1].scatter(closeness_centrality.keys(), closeness_centrality.values(), color='lightgray', label='All Nodes')\nax[1].scatter(top_closeness_nodes, [closeness_centrality[node] for node in top_closeness_nodes], color='lightgreen', label='Top 5')\nax[1].set_title(\"Closeness Centrality\")\nax[1].set_xlabel(\"Node\")\nax[1].set_ylabel(\"Closeness\")\n\n# Betweenness Centrality\nax[2].scatter(betweenness_centrality.keys(), betweenness_centrality.values(), color='lightgray', label='All Nodes')\nax[2].scatter(top_betweenness_nodes, [betweenness_centrality[node] for node in top_betweenness_nodes], color='royalblue', label='Top 5')\nax[2].set_title(\"Betweenness Centrality\")\nax[2].set_xlabel(\"Node\")\nax[2].set_ylabel(\"Betweenness\")\n\n# Adding legends and layout adjustments\nfor a in ax:\n    a.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nA few nodes have significantly higher values of Degree Centrality\nHalf of the nodes has low Closeness Centrality while the other half has an high value\nBetweenness Centrality plot is sparse"
  },
  {
    "objectID": "lectures/lecture_10/network_slides_2025.html#topology",
    "href": "lectures/lecture_10/network_slides_2025.html#topology",
    "title": "Part 1: Network Analysis - Overview",
    "section": "4. Topology",
    "text": "4. Topology\nThe topology of a network tells us how connections are distributed across the nodes of the represented system.\nWe can look if the network presents a specific structure.\nFor instance, as many other financial networks, our network can have a core-periphery structure. A core-periphery structure consists of:\n\nA core of nodes that are highly interconnected with each other and midly interconnected with the other nodes.\nA periphery of nodes that mostly connect to the core, not to each other.\n\nThe following code shows how to find the core of the network (if it exists) and visualize it:\n\nk_core = nx.k_core(G)  # find the core\n\ncore_nodes = set(k_core.nodes())\nperiphery_nodes = set(G.nodes()) - core_nodes\n\nprint(f\"Number of core nodes: {len(core_nodes)}\")\nprint(f\"Number of periphery nodes: {len(periphery_nodes)}\")\n\n# plot the graph to visualize the structure\nplt.figure(figsize=(10, 8))\npos = nx.spring_layout(G, seed=42)\n\nnx.draw_networkx_nodes(G, pos, nodelist=core_nodes, node_color='orangered', label='Core Nodes', node_size=300)           # core nodes are in bigger size\nnx.draw_networkx_nodes(G, pos, nodelist=periphery_nodes, node_color='royalblue', label='Periphery Nodes', node_size=100) # periphery nodes in small size \nnx.draw_networkx_labels(G, pos, font_size=8)                                                                             # label for the nodes\nnx.draw_networkx_edges(G, pos, alpha=0.5)\n\nplt.title(\"Core-Periphery Structure\")\nplt.legend()\nplt.show()\n\nNumber of core nodes: 24\nNumber of periphery nodes: 115\n\n\n\n\n\n\n\n\n\nIt exists a well defined core of the network of 24 nodes, while the others are more peripherical. To conclude, in this network it is possible to distinguish betwene a core and periphery, some nodes are more important, powerful, influent than others.\nWe can verify the robustness of the core-periphery structure hypothesis, first of all by verifying that the core nodes have higher degree centrality than the periphery nodes. We do a scatter plot to verify this graphically.\n\ndegree_centrality = nx.degree_centrality(G)\n\ncore_nodes = list(k_core.nodes()) \nperiphery_nodes = [node for node in G.nodes() if node not in core_nodes]\n\ncore_centrality = [degree_centrality[node] for node in core_nodes]\nperiphery_centrality = [degree_centrality[node] for node in periphery_nodes]\n\nplt.figure(figsize=(6, 4))\nplt.scatter(periphery_nodes, periphery_centrality, color='royalblue', label='Periphery Nodes', alpha=0.6, s=50)  # periphery\nplt.scatter(core_nodes, core_centrality, color='orangered', label='Core Nodes', alpha=0.7, s=80)                 # core\n\nplt.xlabel(\"Node\")\nplt.ylabel(\"Degree Centrality\")\nplt.title(\"Degree Centrality of Core vs. Periphery Nodes\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nThe core nodes consistently exhibit higher degree centrality.\nAnother verification we can do is to compare this result with what we would find in a randomized network. Hypothesis: the CP structure is a specific feature of my network. If it’s not, then any network shows this structure. Namely, if I pick a random network, that will also show a CP structure.\nWe can compute 1000 (or more) randomized network of the same size (number of nodes + number of edges) of our network, calculate for each node, in each network, its degree centrality, then for each node we take the average across the 1000 results and see if the scatter plot is significantly different from the one of our network. The Erdős-Rényi model creats random graphs which represent a solid baseline to study real networks. The model starts with a set of N nodes and then it adds randomly the set of edges defined.\n\n# Parameters\nnum_nodes = 139\nnum_edges = 1071\nnum_randomizations = 1000\n\n# Dictionary to accumulate degree centralities for each node\navg_degree_centrality_random = {node: 0 for node in range(num_nodes)}\n\n# Random graphs + degree centrality for each node in each graph\nfor _ in range(num_randomizations):\n    random_graph = nx.gnm_random_graph(num_nodes, num_edges, directed=True) # generate a random graph with Erdős-Rényi model\n    degree_centrality_random = nx.degree_centrality(random_graph)\n    for node, centrality in degree_centrality_random.items():               # store the degree centrality for each node\n        avg_degree_centrality_random[node] += centrality\n\navg_degree_centrality_random = {node: centrality / num_randomizations for node, centrality in avg_degree_centrality_random.items()}\n\n# Scatter plot\nnodes = list(avg_degree_centrality_random.keys())\naverage_centralities = list(avg_degree_centrality_random.values())\n\nplt.figure(figsize=(6, 4))\nplt.scatter(nodes, average_centralities, color='purple', alpha=0.7, s=50)\nplt.xlabel(\"Node\")\nplt.ylabel(\"Average Degree Centrality\")\nplt.title(\"Average Degree Centrality in 1000 Random Graphs\")\nplt.show()\n\n\n\n\n\n\n\n\nAs you can see, nodes have pretty much the same value of degree centrality, which is generally not high. We can see the networks are kind of uniform in terms of links distribution. We can’t see concentration."
  },
  {
    "objectID": "lectures/lecture_11/lecture_11.html",
    "href": "lectures/lecture_11/lecture_11.html",
    "title": "Lecture 11 - Time Series",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_11/lecture_11.html#lecture-material",
    "href": "lectures/lecture_11/lecture_11.html#lecture-material",
    "title": "Lecture 11 - Time Series",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_11/lecture_11.html#recording",
    "href": "lectures/lecture_11/lecture_11.html#recording",
    "title": "Lecture 11 - Time Series",
    "section": "Recording",
    "text": "Recording\n\n1. Intro\n\n \n\n\n\n2. Data Inspection\n\n \n\n\n\n3. Rolling Statistics\n\n \n\n\n\n4. Correlations\n\n \n\n\n\n5. High Frequency Data"
  },
  {
    "objectID": "lectures/lecture_11/lecture_11.html#problem-sets",
    "href": "lectures/lecture_11/lecture_11.html#problem-sets",
    "title": "Lecture 11 - Time Series",
    "section": "Problem sets",
    "text": "Problem sets\n\nJupyter notebook (.ipynb)"
  },
  {
    "objectID": "lectures/lecture_11/lecture_11_problem_sets.html",
    "href": "lectures/lecture_11/lecture_11_problem_sets.html",
    "title": "Time Series Analysis - Problem set",
    "section": "",
    "text": "For this problem, use datasets according to the following format:\n    file_path = \"historical-crypto/\"\n    file_name = \"coin_***.csv\"\nEach dataset contains historical data on listed crypto tokens.\n\n\nUsing the provided datasets, - Assemble a single dataframe close price information across all crypto tokens. - Construct another dataframe where the timeseries coverage is the same for every token. - Conduct a basic data inspection - Display the first and last few rows and generate summary statistics, including mean, median, standard deviation, and min/max values for each time series in the dataset.\n\n\n\n\nCreate time series plots for each asset in the dataset to observe trends\nResample the data to monthly intervals, displaying only the closing values for each interval.\nPlot the resampled data.\n\n\n\n\nFor the 3 assets with highest prices in the dataset: - Calculate a 30-day rolling window for the mean, standard deviation, minimum, and maximum values. - Plot the original time series with these rolling statistics overlaid to observe how the statistics capture trends over time.\n\n\n\n\nUsing a single asset, implement a basic trading strategy using the two Simple Moving Averages (SMAs): a short-term 20-day SMA and a long-term 100-day SMA.\nIdentify the crossover points and visualize the results.\nDetermine whether a trading position (long/short) would have been profitable by the end of the time frame.\n\n\n\n\nChoose two assets in the dataset: - Calculate the daily log returns for each - Generate a scatter plot showing their correlation. - Run an OLS regression and plot the line on top of the scatter plot. - Calculate the Pearson correlation coefficient and interpret the strength and direction of the relationship."
  },
  {
    "objectID": "lectures/lecture_11/lecture_11_problem_sets.html#problem-1-basic-data-inspection-and-summary-statistics",
    "href": "lectures/lecture_11/lecture_11_problem_sets.html#problem-1-basic-data-inspection-and-summary-statistics",
    "title": "Time Series Analysis - Problem set",
    "section": "",
    "text": "Using the provided datasets, - Assemble a single dataframe close price information across all crypto tokens. - Construct another dataframe where the timeseries coverage is the same for every token. - Conduct a basic data inspection - Display the first and last few rows and generate summary statistics, including mean, median, standard deviation, and min/max values for each time series in the dataset."
  },
  {
    "objectID": "lectures/lecture_11/lecture_11_problem_sets.html#problem-2-time-series-visualization-and-resampling",
    "href": "lectures/lecture_11/lecture_11_problem_sets.html#problem-2-time-series-visualization-and-resampling",
    "title": "Time Series Analysis - Problem set",
    "section": "",
    "text": "Create time series plots for each asset in the dataset to observe trends\nResample the data to monthly intervals, displaying only the closing values for each interval.\nPlot the resampled data."
  },
  {
    "objectID": "lectures/lecture_11/lecture_11_problem_sets.html#problem-3-rolling-statistics-calculation",
    "href": "lectures/lecture_11/lecture_11_problem_sets.html#problem-3-rolling-statistics-calculation",
    "title": "Time Series Analysis - Problem set",
    "section": "",
    "text": "For the 3 assets with highest prices in the dataset: - Calculate a 30-day rolling window for the mean, standard deviation, minimum, and maximum values. - Plot the original time series with these rolling statistics overlaid to observe how the statistics capture trends over time."
  },
  {
    "objectID": "lectures/lecture_11/lecture_11_problem_sets.html#problem-4-simple-moving-averages-sma-crossover-strategy",
    "href": "lectures/lecture_11/lecture_11_problem_sets.html#problem-4-simple-moving-averages-sma-crossover-strategy",
    "title": "Time Series Analysis - Problem set",
    "section": "",
    "text": "Using a single asset, implement a basic trading strategy using the two Simple Moving Averages (SMAs): a short-term 20-day SMA and a long-term 100-day SMA.\nIdentify the crossover points and visualize the results.\nDetermine whether a trading position (long/short) would have been profitable by the end of the time frame."
  },
  {
    "objectID": "lectures/lecture_11/lecture_11_problem_sets.html#problem-5-correlation-analysis-between-two-assets",
    "href": "lectures/lecture_11/lecture_11_problem_sets.html#problem-5-correlation-analysis-between-two-assets",
    "title": "Time Series Analysis - Problem set",
    "section": "",
    "text": "Choose two assets in the dataset: - Calculate the daily log returns for each - Generate a scatter plot showing their correlation. - Run an OLS regression and plot the line on top of the scatter plot. - Calculate the Pearson correlation coefficient and interpret the strength and direction of the relationship."
  },
  {
    "objectID": "lectures/lecture_02/lecture_02.html",
    "href": "lectures/lecture_02/lecture_02.html",
    "title": "Lecture 02 - Data Types and Structure",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_02/lecture_02.html#lecture-material",
    "href": "lectures/lecture_02/lecture_02.html#lecture-material",
    "title": "Lecture 02 - Data Types and Structure",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_02/lecture_02.html#recording",
    "href": "lectures/lecture_02/lecture_02.html#recording",
    "title": "Lecture 02 - Data Types and Structure",
    "section": "Recording",
    "text": "Recording\n\n1. Types\n\n \n\n\n\n2. Structures"
  },
  {
    "objectID": "lectures/lecture_02/lecture_02.html#problem-sets",
    "href": "lectures/lecture_02/lecture_02.html#problem-sets",
    "title": "Lecture 02 - Data Types and Structure",
    "section": "Problem sets",
    "text": "Problem sets\n\nJupyter notebook (.ipynb)\nSolutions (.pdf)"
  },
  {
    "objectID": "lectures/lecture_05/lecture_05.html",
    "href": "lectures/lecture_05/lecture_05.html",
    "title": "Lecture 05 - Object Oriented Programming",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_05/lecture_05.html#lecture-material",
    "href": "lectures/lecture_05/lecture_05.html#lecture-material",
    "title": "Lecture 05 - Object Oriented Programming",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_05/lecture_05.html#recording",
    "href": "lectures/lecture_05/lecture_05.html#recording",
    "title": "Lecture 05 - Object Oriented Programming",
    "section": "Recording",
    "text": "Recording\n\n1. Intro\n\n \n\n\n\n2. Basics\n\n \n\n\n\n3. Inheritance\n\n \n\n\n\n4. Overriding"
  },
  {
    "objectID": "lectures/lecture_05/lecture_05.html#problem-sets",
    "href": "lectures/lecture_05/lecture_05.html#problem-sets",
    "title": "Lecture 05 - Object Oriented Programming",
    "section": "Problem sets",
    "text": "Problem sets\n\nJupyter notebook (.ipynb)\nSolutions (.pdf)"
  },
  {
    "objectID": "lectures/lecture_05/lecture_05_problem_sets.html",
    "href": "lectures/lecture_05/lecture_05_problem_sets.html",
    "title": "Object-Oriented Programming - Problem set",
    "section": "",
    "text": "Problem 1: Create a Book Class\nDefine a Book class with the following attributes: - title (string) - author (string) - pages (integer)\nCreate a method called description() that prints the details of the book in the following format:\n\"&lt;Title&gt; by &lt;Author&gt; has &lt;Pages&gt; pages.\"\n\n# your code\n\n\n\nProblem 2: Create a Rectangle Class\nDefine a Rectangle class with attributes: - length - width\nAdd methods to: - Calculate the area of the rectangle. - Calculate the perimeter of the rectangle.\nCreate a few rectangle objects and call these methods to display their area and perimeter.\n\n# your code\n\n\n\nProblem 3: Create a Circle Class\nDefine a Circle class with a single attribute: - radius\nAdd a method called circumference() that calculates and returns the circumference of the circle (2 * π * radius). Use math.pi for the value of π.\n\n# your code\n\n\n\nProblem 4: Implement a Person Class with Multiple Methods\nCreate a Person class with the following attributes: - name - age - occupation\nAdd methods to: - introduce(): Prints a personalized introduction message: \"Hi, my name is &lt;Name&gt;, and I am a &lt;Occupation&gt;.\" - is_adult(): Returns True if the person is 18 or older, and False otherwise.\n\n# your code\n\n\n\nProblem 5: Create a Library Class\nDefine a Library class that stores a collection of Book objects (from Problem 1). Implement methods to: - Add a new book to the library. - Remove a book from the library using the book title. - List all books currently in the library.\n\n# your code\n\n\n\nProblem 6: Create a BankAccount and CheckingAccount Class Using Inheritance\n\nCreate a BankAccount class with attributes:\n\naccount_holder\nbalance\n\nAdd methods to:\n\ndeposit(amount): Adds money to the account.\nwithdraw(amount): Subtracts money if balance is sufficient; otherwise, prints “Insufficient funds.”\n\nCreate a CheckingAccount class that inherits from BankAccount and has an additional attribute:\n\ntransaction_fee\n\n\nOverride the withdraw() method to include a transaction fee for each withdrawal.\n\n\nProblem 7: Implement a Vehicle and Car Class Using Inheritance\n\nCreate a Vehicle class with attributes:\n\nmake\nmodel\nyear\n\nAdd a method called display_info() that prints the details of the vehicle.\nCreate a Car class that inherits from Vehicle and adds:\n\nfuel_type (e.g., “Petrol” or “Electric”)\n\n\nOverride the display_info() method to include the fuel type in the printed details.\n\n# your code\n\n\n\nProblem 8: Create a Product Class with Inheritance\nCreate a Product base class that represents a generic product in a store. The class should have the following attributes:\n\nname (string)\nprice (float)\n\nCreate two child classes that inherit from Product: 1. Electronics: This class should have an additional attribute called warranty_years (integer). 2. Clothing: This class should have an additional attribute called size (string).\nImplement methods in the base class and child classes as follows: - The base Product class should have a method called display() that prints the product’s name and price. - Each child class should override the display() method to include its additional attributes.\n\nExample of the output format\n&gt;&gt;&gt; electronics = Electronics(\"Smartphone\", 699.99, 2)\n&gt;&gt;&gt; clothing = Clothing(\"T-shirt\", 19.99, \"M\")\n&gt;&gt;&gt; electronics.display()\nProduct: Smartphone, Price: $699.99, Warranty: 2 years\n&gt;&gt;&gt; clothing.display()\nProduct: T-shirt, Price: $19.99, Size: M\n\n# your code\n\n\n\n\nProblem 9: Create a Team Class with Aggregation\nCreate a Player class with attributes: - name - position - number\nCreate a Team class that contains a list of Player objects. Implement methods to: - Add a player. - Remove a player using the player’s name. - Display the list of all players on the team.\n\n# your code\n\n\n\nProblem 10: Polymorphism with a Shape Class Hierarchy\nCreate a Shape parent class with a method draw(). Define two child classes: - Circle class with a draw() method that prints “Drawing a circle.” - Square class with a draw() method that prints “Drawing a square.”\nCreate a list of Shape objects (some Circle and some Square), and use a loop to call draw() on each object, demonstrating polymorphism.\n\n# your code"
  },
  {
    "objectID": "lectures/lecture_04/functions.html",
    "href": "lectures/lecture_04/functions.html",
    "title": "Lecture 04 - Functions",
    "section": "",
    "text": "Functions are a key concept in programming that allow to reuse code, make programs more modular, and simplify complex tasks.\nIn Python, functions are defined using the def keyword.\nThis notebook covers: - Definition and calls - Parameters and arguments - Return values - Scope of variables - Built-in vs. user-defined functions - Functional and anonymous programming"
  },
  {
    "objectID": "lectures/lecture_04/functions.html#overview",
    "href": "lectures/lecture_04/functions.html#overview",
    "title": "Lecture 04 - Functions",
    "section": "",
    "text": "Functions are a key concept in programming that allow to reuse code, make programs more modular, and simplify complex tasks.\nIn Python, functions are defined using the def keyword.\nThis notebook covers: - Definition and calls - Parameters and arguments - Return values - Scope of variables - Built-in vs. user-defined functions - Functional and anonymous programming"
  },
  {
    "objectID": "lectures/lecture_04/functions.html#basics-of-functions",
    "href": "lectures/lecture_04/functions.html#basics-of-functions",
    "title": "Lecture 04 - Functions",
    "section": "1. Basics of Functions",
    "text": "1. Basics of Functions\n\n1.1 Definition and calls\nIn Python, a function is defined using the def keyword followed by the function name and parentheses ().\nOnce implemented, the function is called using the name and parantheses.\nAs long as the function is not called, nothing happens (no output).\n\n# Example of a simple function\ndef greet_bank_customer():\n    print(\"Welcome to ABC Bank!\")\n\n\n# Call the function\ngreet_bank_customer()\n\n\n\n1.2 Arguments\nFunctions can accept inputs, known as arguments or parameters, which are passed into the function using the parentheses.\n\n# Function to calculate simple interest\ndef calculate_simple_interest(principal, rate, time):\n    interest = principal * rate * time / 100\n    print(f\"The interest is: {interest}\")\n\n\n# Call the function with arguments\ncalculate_simple_interest(1000, 5, 2)  # Principal = 1000, Rate = 5%, Time = 2 years\n\n\n\n1.3 Return Values\nFunctions can return a value which can be assigned to an external variable. This obtains from the return statement.\n\n# Function to calculate and return compound interest\ndef calculate_compound_interest(principal, rate, time):\n    amount = principal * (1 + rate/100)**time\n    interest = amount - principal\n    return interest\n\n\n# Call the function and store the result\ncompound_interest = calculate_compound_interest(1000, 5, 2)\nprint(\"The compound interest is:\", compound_interest)\n\n\n\n1.4 Variable Scope\nVariables defined inside a function are local to that function and cannot be accessed outside of it.\nThis is called the scope of a variable.\n\ndef calculate_balance():\n    balance = 5000  # Local variable\n    print(\"Balance inside the function:\", balance)\n\n\ncalculate_balance()\n\n\nprint(balance)  # This will raise an error because balance is not accessible outside the function\n\n\n\n1.5 Built-in vs. User-defined Functions\nPython provides many built-in functions like print(), len(), sum(), etc.\nUser-defined functions can also be used to extend and improve such functions.\n\ntransactions = [100, -50, 200, -100]\ntotal = sum(transactions)\nprint(\"Total balance after transactions:\", total)\n\n\ndef calculate_npv(cash_flows, discount_rate):\n    npv = sum(cf / (1 + discount_rate) ** t for t, cf in enumerate(cash_flows, 1))\n    return npv\n\ncash_flows = [-1000, 200, 300, 400, 500]\nprint(\"Net Present Value:\", calculate_npv(cash_flows, 0.05))"
  },
  {
    "objectID": "lectures/lecture_04/functions.html#functional-programming",
    "href": "lectures/lecture_04/functions.html#functional-programming",
    "title": "Lecture 04 - Functions",
    "section": "2. Functional programming",
    "text": "2. Functional programming\nFunctional programming is a style of programming that treats computation as the evaluation of functions, just like in mathematics.\n\nData is kept unchanged rather than modified\n\nFunctions are written as pure functions: the same input always produces the same output, with no hidden effects\n\nHigher-order functions: can be passed to other functions or returned as results\n\nPython supports functional programming features, making it easy to apply functional programming techniques.\n\ngood practice: Avoiding loops as much as possible and making full use of list comprehensions and functional programming techniques.\n\n\nMath vs. Python Example\nMathematics:\n\\[\nf(x) = x^2\n\\]\n\nInput \\(2 \\rightarrow 4\\)\nInput \\(3 \\rightarrow 9\\)\n\nPython:\ndef f(x):\n    return x**2\n\nf(2)  # 4\nf(3)  # 9\n\n\n2.1 Pure function\nA pure function is a function that: - Always produces the same output given the same input. - Has no side effects (e.g., modifying external variables, changing mutable data, etc.).\nExample of a Pure Function:\n\ndef add(a, b):\n    return a + b\n\nThis function always returns the sum of a and b without modifying anything outside the function.\nNon-Pure Function (with side effects):\n\ntotal = 0\n\ndef add_to_total(amount):\n    global total\n    total += amount\n    return total\n\nThis function modifies the global variable total, which is considered a side effect and makes it a non-pure function.\n\n\n2.2 Higher-order function\nA higher-order function is a function that takes one or more functions as arguments or returns a function as its result.\nExample of a Higher-Order Function:\n\ndef apply_twice(func, value):\n    return func(func(value))\n\ndef double(x):\n    return x * 2\n\nprint(apply_twice(double, 5))\n\n\n\n2.3 Anonymous Functions (lambda)\nIn Python, lambda functions are anonymous functions that can have any number of arguments but only one expression.\nLambdas are useful for short functions without explicit definitions.\nLambda Function Syntax:\nlambda arguments: expression\n\nadd = lambda a, b: a + b\nprint(add(3, 4))  # Output: 7\n\n\n# Lambda function for multiplication\nmultiply = lambda x, y: x * y\nprint(multiply(4, 2))  # Output: 8\n\n\n# Lambda function with if-else to check if a number is even or odd\neven_or_odd = lambda x: 'even' if x % 2 == 0 else 'odd'\nprint(even_or_odd(4))  # Output: even\nprint(even_or_odd(7))  # Output: odd\n\n\n# Convert a string to uppercase using lambda\nto_upper = lambda s: s.upper()\nprint(to_upper('hello'))  # Output: HELLO\n\n\n# Lambda function to calculate the maximum of three numbers\nmax_of_three = lambda a, b, c: a if (a &gt; b and a &gt; c) else (b if b &gt; c else c)\nprint(max_of_three(10, 20, 15))  # Output: 20\n\n\n\n2.4 Functional Programming Tools in Python\nPython provides several built-in functions that are useful in functional programming\n\nmap()\nApplies a given function to each item of an iterable (like a list) and returns a map object.\n\nnumbers = [1, 2, 3, 4, 5]\nsquared_map = map(lambda x: x ** 2, numbers)\nsquared = list(squared_map)\nprint(squared)  \nprint (squared_map)\n\n\n\nfilter()\nFilters items in an iterable based on a given function and returns an iterator.\n\nnumbers = [1, 2, 3, 4, 5, 6]\nevens_iterator = filter(lambda x: x % 2 == 0, numbers)\nevens = list(evens_iterator)\nprint(evens) \nprint(evens_iterator)\n\nNote: iterators in Python are exhausted after one use. Once converted to a list using list(evens_iterator), the iterator is consumed and cannot be used again.\n\n\nreduce()\nPerforms a rolling computation to sequential pairs of values in a list. It requires importing from the functools module.\n\nfrom functools import reduce\n\nnumbers = [1, 2, 3, 4]\nresult = reduce(lambda a, b: a * b, numbers)\n# Step 1: 1 * 2 = 2\n# Step 2: 2 * 3 = 6\n# Step 3: 6 * 4 = 24\nprint(result)  \n\n\n\nzip()\nCombines two or more iterables into a single iterable of tuples.\n\nnames = ['Alice', 'Bob', 'Charlie']\nscores = [85, 90, 95]\n\nzipped = list(zip(names, scores))\nprint(zipped)\n\n\n\nsorted()\nLambda functions can be used to define custom sorting behavior when using sorted().\n\n# Sort a list of tuples based on the second element (using lambda)\npairs = [(1, 'one'), (2, 'two'), (3, 'three'), (4, 'four')]\nsorted_pairs = sorted(pairs, key=lambda pair: pair[1])\nprint(sorted_pairs)\n\n\n\nList Comprehension\nAlthough list comprehension is not purely functional, it is closely aligned with functional programming ideas as it allows to create new lists in a concise way.\n\nsquares = [x ** 2 for x in range(5)]\nprint(squares)  # Output: [0, 1, 4, 9, 16]\n\n\n\nDictionaries\nLambda functions can be used to get custom behavior when working with dictionaries, like finding the maximum or minimum key.\n\n# Find the key with the highest value in a dictionary\nscores = {'Alice': 85, 'Bob': 90, 'Charlie': 88}\nhighest_scorer = max(scores, key=lambda k: scores[k])\nprint(highest_scorer)  # Output: Bob\n\nNote: max() and dict:\n1.max(scores): Finds the maximum key (default behavior).\n2.max(scores.values()): Finds the maximum value.\n3.max(scores, key=lambda k: scores[k]): Finds the key corresponding to the maximum value."
  },
  {
    "objectID": "lectures/lecture_03/lecture_03.html",
    "href": "lectures/lecture_03/lecture_03.html",
    "title": "Lecture 03 - Control structures",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_03/lecture_03.html#lecture-material",
    "href": "lectures/lecture_03/lecture_03.html#lecture-material",
    "title": "Lecture 03 - Control structures",
    "section": "",
    "text": "Notebook\n\nJupyter notebook (.ipynb)\nPage (HTML notebook)\n\nSlides\n\nReveal.js\nPDF"
  },
  {
    "objectID": "lectures/lecture_03/lecture_03.html#recording",
    "href": "lectures/lecture_03/lecture_03.html#recording",
    "title": "Lecture 03 - Control structures",
    "section": "Recording",
    "text": "Recording\n\n1. Intro\n\n \n\n\n\n2. If\n\n \n\n\n\n3. while\n\n \n\n\n\n4. for"
  },
  {
    "objectID": "lectures/lecture_03/lecture_03.html#problem-sets",
    "href": "lectures/lecture_03/lecture_03.html#problem-sets",
    "title": "Lecture 03 - Control structures",
    "section": "Problem sets",
    "text": "Problem sets\n\nJupyter notebook (.ipynb)\nSolutions (.pdf)"
  },
  {
    "objectID": "lectures/lecture_03/control_structures.html",
    "href": "lectures/lecture_03/control_structures.html",
    "title": "Lecture 03 - Control Structures",
    "section": "",
    "text": "Control structures are essential in programming: they allow to control the flow of the code.\nIn Python, the primary control structures are if, while, and for loops. These structures are crucial in decision-making processes and repetitive tasks.\nThis notebook covers: - if statements - while loops for repeated execution based on a condition - for loops for iterating over sequences - Counter-based loops - List comprehension"
  },
  {
    "objectID": "lectures/lecture_03/control_structures.html#overview",
    "href": "lectures/lecture_03/control_structures.html#overview",
    "title": "Lecture 03 - Control Structures",
    "section": "",
    "text": "Control structures are essential in programming: they allow to control the flow of the code.\nIn Python, the primary control structures are if, while, and for loops. These structures are crucial in decision-making processes and repetitive tasks.\nThis notebook covers: - if statements - while loops for repeated execution based on a condition - for loops for iterating over sequences - Counter-based loops - List comprehension"
  },
  {
    "objectID": "lectures/lecture_03/control_structures.html#the-if-statement",
    "href": "lectures/lecture_03/control_structures.html#the-if-statement",
    "title": "Lecture 03 - Control Structures",
    "section": "1. The if Statement",
    "text": "1. The if Statement\nThe if statement executes a block of code only if a certain condition is True.\nSuch conditional statements consider the specific value of a variable at the time of execution and determine the outcome based on a logical operation.\n\nStructure\n    If CONDITON HOLDS:\n        OUTCOME 1\n    Elif OTHER CONDITION HOLDS:\n        OUTCOME 2\n    Else:\n        OUTCOME 3\nNote: check the tabs\n\n# Example: withdrawal\nbalance = 500\nwithdrawal_amount = 800\n\nif balance &gt;= withdrawal_amount:\n    balance -= withdrawal_amount\n    print(f\"Withdrawal successful! New balance: {balance}\")\nelse:\n    print(\"Insufficient funds.\")   \n\n\n# Input values\nsavings = float(input(\"Enter your savings amount in dollars: \"))\nmonthly_income = float(input(\"Enter your monthly income in dollars: \"))\ndebt = float(input(\"Enter your debt amount in dollars: \"))\n\n# Applying the conditions using if, elif, and else statements\nif savings &gt; 50000 and debt == 0:\n    print(\"You should invest in stocks.\")\nelif debt &gt; 0 and savings &gt; 20000 and monthly_income &gt; 4000:\n    print(\"You should pay off debt aggressively.\")\nelif savings &lt; 20000 and debt &gt; 10000:\n    print(\"You should save more and minimize spending.\")\nelse:\n    print(\"You should create a budget and build an emergency fund.\")"
  },
  {
    "objectID": "lectures/lecture_03/control_structures.html#the-while-loop",
    "href": "lectures/lecture_03/control_structures.html#the-while-loop",
    "title": "Lecture 03 - Control Structures",
    "section": "2. The while Loop",
    "text": "2. The while Loop\nThe while loop repeats a block of code as long as a specified condition is true.\n\n2.1 Structure\n    While CONDITION HOLDS:\n        ACTION(s)\n\n# Example: Simulating a simple ATM withdrawal process\nbalance = 1000\nwithdrawal_attempts = 0\nwithdrawal_amount = 200\n\nwhile balance &gt; 0 and withdrawal_attempts &lt; 3:\n    if balance &gt;= withdrawal_amount:\n        balance -= withdrawal_amount\n        print(f\"Withdrawal successful! New balance: {balance}\")\n    else:\n        print(\"Insufficient funds.\")\n    withdrawal_attempts += 1\n\n\n\n2.2 When using a while loop:\n\nLoop Condition and Termination: Ensure the loop has a valid exit condition that will eventually become False.\n\n\ncount = 0\nwhile count &lt; 5:  # Loop will terminate when count reaches 5\n    print(f\"Count is {count}\")\n    count += 1\n\nIf the loop condition (e.g., count &lt; 5) is never met, the loop will not stop naturally.\n\nUpdate Loop Variable: Ensure the variable controlling the loop is updated to prevent infinite loops.|\n\n\nbalance = 1000\nmonthly_payment = 200\n\nwhile balance &gt; 0:\n    balance -= monthly_payment  # Update balance each iteration\n    print(f\"Remaining balance: ${balance}\")\n\n\nThe balance is reduced each time until it reaches zero, terminating the loop.\n\n\nBreak and Exit Conditions: Use break to exit early when certain conditions are met.\n\n\nwhile True:\n    user_input = input(\"Type 'exit' to stop: \")\n    if user_input == 'exit':\n        print(\"Exiting the loop.\")\n        break\n\n\nThe loop terminates immediately when the user types 'exit'.\n\n\nEfficiency and Performance: Avoid heavy computations inside the loop to maintain performance.\n\n\nn = 1000000\ni = 0\nwhile i &lt; n:\n    i += 1  # Efficient loop, only counting\n# Avoid putting expensive operations here\nprint(f\"Loop completed {n} iterations.\")\n\n\nThe loop is efficient and avoids unnecessary complex calculations inside.\n\n\nEdge Case Handling: Plan for edge cases by adding safety conditions, such as a maximum number of iterations.\n\n\nloan_balance = 5000\nmonthly_payment = 300\nmax_months = 60  # Safety condition to prevent infinite loop\nmonths = 0\n\nwhile loan_balance &gt; 0 and months &lt; max_months:\n    loan_balance -= monthly_payment\n    months += 1\n    if loan_balance &lt; 0:\n        loan_balance = 0\n        break\n\nprint(f\"Loan repaid in {months} months.\")\n\n\nThe loop stops if either the loan is repaid or the maximum number of months is reached.\n\n\n\n2.3 Full example: Loan Repayment Simulation\nSet-up: A user takes out a loan of \\(\\$ 100,000\\) with an annual interest rate of 5%. The user makes fixed monthly payments of \\(\\$ 1,500\\).\nGoal:\n\nCalculate how many months it will take to pay off the loan.\nTrack how much total interest is paid by the time the loan is fully repaid.\n\nTo consider: In this example, we simulate the process of repaying a loan with monthly payments.\nThe goal is to calculate how long it will take to fully repay the loan, considering:\n\nA principal loan amount.\nA fixed monthly payment.\nA monthly interest rate (compound interest).\n\nWe use a while loop to simulate the monthly loan repayment process until the loan is fully repaid. The loop keeps running as long as the loan balance is greater than zero.\n\n# Loan parameters\nprincipal = 100000  # Initial loan amount in dollars\nannual_interest_rate = 0.05  # 5% annual interest\nmonthly_payment = 1500  # Monthly payment in dollars\n\n\n# Calculated monthly interest rate\nmonthly_interest_rate = annual_interest_rate / 12\n\n\n# Initialize variables\nloan_balance = principal  # Remaining loan balance starts as the principal\ntotal_interest_paid = 0  # Track the total interest paid\nmonths = 0  # Track the number of months needed to repay the loan\n\n\n# Loop until the loan is repaid\nwhile loan_balance &gt; 0:\n    # Calculate interest for the current month\n    monthly_interest = loan_balance * monthly_interest_rate\n    total_interest_paid += monthly_interest\n\n    # Update loan balance by subtracting the monthly payment (minus the interest portion)\n    loan_balance = loan_balance + monthly_interest - monthly_payment\n\n    # Increment the number of months\n    months += 1\n\n    # If the loan balance becomes less than the monthly payment in the final month,\n    # pay off the remaining balance and break the loop\n    if loan_balance &lt; monthly_payment:\n        total_interest_paid += loan_balance * monthly_interest_rate  # Final month's interest\n        loan_balance = 0  # Set the balance to 0\n        months += 1  # Add the final month\n\n\n# Output the result\nprint(f\"It will take {months} months to repay the loan.\")\nprint(f\"Total interest paid over the life of the loan: ${total_interest_paid:.2f}\")"
  },
  {
    "objectID": "lectures/lecture_03/control_structures.html#the-for-loop",
    "href": "lectures/lecture_03/control_structures.html#the-for-loop",
    "title": "Lecture 03 - Control Structures",
    "section": "3. The for Loop",
    "text": "3. The for Loop\nThe for loop is used to iterate over a sequence (like a list, tuple, string, etc.) and execute a block of code for each item in the sequence.\n\n3.1 Structure\n    For ITEM in ITERABLE:\n        ACTION(s)\n\nitem: This is a variable that takes the value of each element in the sequence on every iteration.\niterable: This is any Python object that can return one item at a time, like lists, tuples, strings, ranges, etc.\n\nHow It Works\n\nThe for loop goes through each item in the iterable one by one.\nOn each iteration, the item variable is assigned the next value in the sequence, and the block of code inside the loop is executed.\nThis continues until all items in the iterable have been processed.\n\n\nfruits = ['apple', 'banana', 'cherry']\n\nfor fruit in fruits:\n    print(fruit)\n\n\n\n3.2 Looping over lists, dictionnaries and strings\n\nl = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\nfor element in l[2:5]:\n    print (element ** 2)\n\n\nd = {\n    \"program\": \"Master of Business Administration\",\n    \"year\": 2025,\n    \"number_of_students\": 42,\n    \"average_age\": 22,\n    \"specializations\": [\"Finance\", \"Marketing\", \"Data Science\", \"Strategy\"]\n}\nfor item in d.items():\n    print (item)\n\n\nfor value in d.values():\n    print (type(value))\n\n\n# Example: Calculating the total balance from a list of transactions\ntransactions = [100, -50, 200, -75, 150]\ntotal_balance = 0\n\nfor transaction in transactions:\n    total_balance += transaction\n\nprint(\"Total balance after all transactions:\", total_balance)\n\n\n# Looping over strings\nmessage = \"Hello\"\n\nfor char in message:\n    print(char)\n\n\n\n3.3 Counter-based looping\nThe range() function is often used in for loops when you need to loop a specific number of times or generate a sequence of numbers.\n\nr = range(0, 8, 1)\nr\n\n\nlist(r)\n\n\ntype (r)\n\n\nfor i in range(5):\n    print(i)\n\n\nrange(5) generates a sequence of numbers from 0 to 4.\nOn each iteration, the variable i takes the value of the next number in the range.\n\n\nfor i in range(2,5):\n    print (l[i] ** 2)\n\n\n\n3.4 Nested for loops\nfor loops can be nested to iterate over multi-dimensional data structures like lists of lists or matrices:\n\nmatrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n\nfor row in matrix:\n    for item in row:\n        print(item, end=\" \")\n    print()  # Newline after each row\n\nIn this case: - The first line: for row in [[1, 2], [3, 4], [5, 6]] iterates over each row of the matrix. - The second line: for item in row iterates over each item in the row. - The item expression adds the individual elements to the new list.\n\n\n3.5 break and continue and else\n\nbreak: Exits the loop prematurely when a certain condition is met.\ncontinue: Skips the current iteration and moves on to the next iteration.\nelse: Executes after the loop completes normally (i.e., when the loop is not terminated by a break statement).\n\n\nfor num in range(1, 10):\n    if num == 5:\n        break  # Exit the loop when num equals 5\n    print(num)\n\n\nfor num in range(1, 6):\n    if num == 3:\n        continue  # Skip the iteration when num equals 3\n    print(num)\n\n\nfor num in range(1, 5):\n    print(num)\nelse:\n    print(\"Loop completed.\")\n\n\n# If the loop is interrupted by a break, the else block is not executed:\nfor num in range(1, 5):\n    if num == 3:\n        break\n    print(num)\nelse:\n    print(\"Loop completed.\")\n\n\n\n3.6 Looping and conditioning\n\nfor i in range (1,10):\n    if i % 2 == 0:\n        print (i, 'is even')\n    elif i % 3 == 0:\n        print (i, 'is a multiple of 3')\n    else:\n        print (i, 'is odd')\n\n\n\n3.7 List comprehension\nList comprehension is a concise way to create lists in Python. It combines a for loop and optional conditions into a single line of code, allowing to generate lists quickly and efficiently.\nIt is not only shorter but often more readable and efficient computationally than traditional for loops when dealing with list generation.\n\nBasic Syntax of List Comprehension\nnew_list = [expression for item in iterable if condition]\n\nexpression: The value to append to the new list.\nitem: The variable representing each element in the iterable (e.g., list, string, or range).\niterable: Any sequence or collection being iterated over (e.g., a list, tuple, string, or range).\ncondition: (Optional) A filter that includes only certain elements from the iterable. The condition is an if statement.\n\n\n#  Traditional `for` Loop:\nnumbers = [1, 2, 3, 4, 5]\nsquares = []\n\nfor number in numbers:\n    squares.append(number ** 2)\n\nprint(squares)\n\n\n# Equivalent List Comprehension:\nsquares = [number ** 2 for number in [1, 2, 3, 4, 5]]\nprint(squares)\n\nIn this case: - The for number in [1, 2, 3, 4, 5] part is the iteration. - The number ** 2 part is the expression that generates the square of each number.\n\n\nList comprehesions with condition\nif statement can be included in a list comprehension to filter elements.\n\n# Traditional `for` Loop with Condition:\nnumbers = [1, 2, 3, 4, 5, 6]\nevens = []\n\nfor number in numbers:\n    if number % 2 == 0:\n        evens.append(number)\n\nprint(evens)\n\n\n# Equivalent list comprehension with condition:\nevens = [number for number in [1, 2, 3, 4, 5, 6] if number % 2 == 0]\nprint(evens)\n\n\n# List comprehension with multiple conditions\nfiltered_numbers = [number for number in range(1, 21) if number % 2 == 0 and number % 3 == 0]\nprint(filtered_numbers)\n\n\n\nList comprehension with function calls\nFunction calls can be used in the expression part of a list comprehension.\n\ndef square(number):\n    return number ** 2\n\n\nnumbers = [1, 2, 3, 4, 5]\nsquares = [square(number) for number in numbers]\n\n\n\nDictionary with list comprehension\nList comprehensions can be used to create dictionaries using the dict() constructor.\n\nnames = ['Alice', 'Bob', 'Charlie']\nname_length_dict = {name: len(name) for name in names}\n\nprint(name_length_dict)\n\n\n\nWhen to use list comprehensions\n\nConciseness: Generate lists quickly and concisely.\nReadability: For simple iterations, list comprehension is often more readable than multiple lines of for loops.\nEfficiency: List comprehensions are more efficient than traditional loops due to optimizations in Python’s internal implementation.\n\n\n\nWhen Not to Use List Comprehension\n\nComplex Logic: If the logic inside the list comprehension becomes too complex (e.g., multiple if conditions, nested loops), it may become less readable. In such cases, traditional loops may be clearer.\nSide Effects: List comprehensions should not be used if the logic involves side effects (e.g., modifying external variables or data structures), as they are primarily designed for list generation, not process flow control."
  }
]